{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"go-elevenlabs","text":"<p>A Go SDK for the ElevenLabs AI Audio API.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Text-to-Speech - Generate natural-sounding speech from text</li> <li>Speech-to-Text - Transcribe audio with speaker diarization</li> <li>Speech-to-Speech - Voice conversion to transform any voice</li> <li>Voice Selection - Access pre-made and cloned voices</li> <li>Sound Effects - Generate sound effects from text descriptions</li> <li>Music Composition - Generate music from text prompts</li> <li>Projects (Studio) - Create long-form content with chapters</li> <li>Pronunciation Dictionaries - Ensure correct pronunciation of technical terms</li> <li>Dubbing - Translate audio/video to other languages</li> </ul>"},{"location":"#real-time-services","title":"Real-Time Services","text":"<ul> <li>WebSocket TTS - Low-latency streaming text-to-speech for LLM integration</li> <li>WebSocket STT - Real-time speech-to-text with partial results</li> <li>Twilio Integration - Phone call integration for voice agents</li> <li>Phone Numbers - Manage phone numbers for conversational AI</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>go get github.com/agentplexus/go-elevenlabs\n</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"io\"\n    \"os\"\n\n    elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n)\n\nfunc main() {\n    // Create client (uses ELEVENLABS_API_KEY env var)\n    client, _ := elevenlabs.NewClient()\n    ctx := context.Background()\n\n    // Generate speech\n    audio, _ := client.TextToSpeech().Simple(ctx,\n        \"21m00Tcm4TlvDq8ikWAM\",  // Voice ID\n        \"Hello, welcome to ElevenLabs!\")\n\n    // Save to file\n    f, _ := os.Create(\"output.mp3\")\n    defer f.Close()\n    io.Copy(f, audio)\n}\n</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":"<p>This SDK is particularly well-suited for:</p> <ul> <li>Voice Agents - Build conversational AI agents with real-time TTS/STT</li> <li>Phone Integration - Create voice bots with Twilio phone calls</li> <li>Online Courses - Generate professional narration for Udemy, LMS platforms</li> <li>Audiobooks - Create chapter-organized audio content</li> <li>Podcasts - Produce consistent, high-quality audio</li> <li>Video Production - Add voiceovers and sound effects</li> <li>LLM Applications - Stream text from LLMs directly to speech</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting Started - Installation and setup</li> <li>Services - API service documentation</li> <li>Guides - Use case guides</li> <li>Examples - Code examples</li> </ul>"},{"location":"#license","title":"License","text":"<p>MIT License - see LICENSE for details.</p>"},{"location":"examples/","title":"Examples","text":"<p>Complete working examples for common use cases.</p>"},{"location":"examples/#basic-usage","title":"Basic Usage","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"io\"\n    \"log\"\n    \"os\"\n\n    elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n)\n\nfunc main() {\n    client, err := elevenlabs.NewClient()\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    ctx := context.Background()\n\n    // List voices\n    voices, _ := client.Voices().List(ctx)\n    fmt.Printf(\"Found %d voices\\n\", len(voices))\n\n    // Generate speech\n    if len(voices) &gt; 0 {\n        audio, _ := client.TextToSpeech().Simple(ctx,\n            voices[0].VoiceID,\n            \"Hello from go-elevenlabs!\")\n\n        f, _ := os.Create(\"hello.mp3\")\n        defer f.Close()\n        io.Copy(f, audio)\n    }\n}\n</code></pre>"},{"location":"examples/#text-to-speech-with-options","title":"Text-to-Speech with Options","text":"<pre><code>resp, err := client.TextToSpeech().Generate(ctx, &amp;elevenlabs.TTSRequest{\n    VoiceID: \"21m00Tcm4TlvDq8ikWAM\",\n    Text:    \"Hello with custom settings!\",\n    ModelID: \"eleven_multilingual_v2\",\n    VoiceSettings: &amp;elevenlabs.VoiceSettings{\n        Stability:       0.6,\n        SimilarityBoost: 0.8,\n        Style:           0.1,\n        SpeakerBoost:    true,\n    },\n    OutputFormat: \"mp3_44100_192\",\n})\nif err != nil {\n    log.Fatal(err)\n}\n\nf, _ := os.Create(\"custom.mp3\")\ndefer f.Close()\nio.Copy(f, resp.Audio)\n</code></pre>"},{"location":"examples/#sound-effects","title":"Sound Effects","text":"<pre><code>// Simple sound effect\nthunder, _ := client.SoundEffects().Simple(ctx, \"thunder and rain storm\")\n\n// With options\nsfx, _ := client.SoundEffects().Generate(ctx, &amp;elevenlabs.SoundEffectRequest{\n    Text:            \"spaceship engine humming\",\n    DurationSeconds: 10,\n    PromptInfluence: 0.5,\n    Loop:            true,\n})\n\n// Looping background\nambience, _ := client.SoundEffects().GenerateLoop(ctx,\n    \"peaceful forest with birds\", 30)\n</code></pre>"},{"location":"examples/#pronunciation-dictionary","title":"Pronunciation Dictionary","text":"<pre><code>// From a map (simplest)\ndict, _ := client.Pronunciation().CreateFromMap(ctx, \"Tech Terms\", map[string]string{\n    \"API\":     \"A P I\",\n    \"kubectl\": \"kube control\",\n    \"nginx\":   \"engine X\",\n})\n\n// From JSON file\ndict, _ := client.Pronunciation().CreateFromJSON(ctx, \"Terms\", \"terms.json\")\n\n// With full options\nrules := elevenlabs.PronunciationRules{\n    {Grapheme: \"API\", Alias: \"A P I\"},\n    {Grapheme: \"nginx\", Phoneme: \"\u02c8\u025bnd\u0292\u026an\u02c8\u025bks\"},\n}\n\ndict, _ := client.Pronunciation().Create(ctx, &amp;elevenlabs.CreatePronunciationDictionaryRequest{\n    Name:        \"Custom Terms\",\n    Description: \"Technical vocabulary\",\n    Rules:       rules,\n    Language:    \"en-US\",\n})\n</code></pre>"},{"location":"examples/#projects-long-form-content","title":"Projects (Long-form Content)","text":"<pre><code>// Create project\nproject, _ := client.Projects().Create(ctx, &amp;elevenlabs.CreateProjectRequest{\n    Name:                    \"My Audiobook\",\n    DefaultModelID:          \"eleven_multilingual_v2\",\n    DefaultParagraphVoiceID: \"21m00Tcm4TlvDq8ikWAM\",\n    DefaultTitleVoiceID:     \"21m00Tcm4TlvDq8ikWAM\",\n})\n\n// List chapters\nchapters, _ := client.Projects().ListChapters(ctx, project.ProjectID)\n\n// Convert project to audio\nclient.Projects().Convert(ctx, project.ProjectID)\n\n// Download completed audio\nsnapshots, _ := client.Projects().ListSnapshots(ctx, project.ProjectID)\nif len(snapshots) &gt; 0 {\n    reader, _ := client.Projects().DownloadSnapshotArchive(ctx,\n        project.ProjectID, snapshots[0].ProjectSnapshotID)\n\n    f, _ := os.Create(\"audiobook.zip\")\n    io.Copy(f, reader)\n    f.Close()\n}\n</code></pre>"},{"location":"examples/#dubbing","title":"Dubbing","text":"<pre><code>// Create dubbing job\ndub, _ := client.Dubbing().Create(ctx, &amp;elevenlabs.DubbingRequest{\n    SourceURL:      \"https://example.com/video.mp4\",\n    TargetLanguage: \"es\",\n    Name:           \"Video - Spanish\",\n})\n\n// Poll for completion\nfor {\n    status, _ := client.Dubbing().GetStatus(ctx, dub.DubbingID)\n    if status.Status == \"dubbed\" {\n        break\n    }\n    time.Sleep(30 * time.Second)\n}\n\n// Download dubbed file\naudio, _ := client.Dubbing().GetDubbedFile(ctx, dub.DubbingID, \"es\")\nf, _ := os.Create(\"video_spanish.mp4\")\nio.Copy(f, audio)\nf.Close()\n</code></pre>"},{"location":"examples/#usage-monitoring","title":"Usage Monitoring","text":"<pre><code>// Check subscription\nsub, _ := client.User().GetSubscription(ctx)\n\nfmt.Printf(\"Tier: %s\\n\", sub.Tier)\nfmt.Printf(\"Used: %d / %d\\n\", sub.CharacterCount, sub.CharacterLimit)\nfmt.Printf(\"Remaining: %d\\n\", sub.CharactersRemaining())\n\n// Pre-generation check\nfunc checkAndGenerate(client *elevenlabs.Client, text string) error {\n    sub, _ := client.User().GetSubscription(context.Background())\n    if sub.CharactersRemaining() &lt; len(text) {\n        return errors.New(\"insufficient characters\")\n    }\n    // Proceed with generation...\n    return nil\n}\n</code></pre>"},{"location":"examples/#error-handling","title":"Error Handling","text":"<pre><code>audio, err := client.TextToSpeech().Simple(ctx, voiceID, text)\nif err != nil {\n    if elevenlabs.IsRateLimitError(err) {\n        log.Println(\"Rate limited, waiting...\")\n        time.Sleep(time.Minute)\n        // Retry...\n    } else if elevenlabs.IsUnauthorizedError(err) {\n        log.Fatal(\"Invalid API key\")\n    } else if elevenlabs.IsNotFoundError(err) {\n        log.Fatal(\"Voice not found\")\n    } else {\n        log.Fatalf(\"Error: %v\", err)\n    }\n}\n</code></pre>"},{"location":"examples/#course-generation-workflow","title":"Course Generation Workflow","text":"<pre><code>func generateCourse() {\n    client, _ := elevenlabs.NewClient()\n    ctx := context.Background()\n\n    // 1. Set up pronunciation\n    client.Pronunciation().CreateFromMap(ctx, \"Course Terms\", map[string]string{\n        \"API\": \"A P I\",\n        \"SDK\": \"S D K\",\n    })\n\n    // 2. Generate intro\n    intro, _ := client.SoundEffects().Simple(ctx, \"professional course intro\")\n    saveAudio(intro, \"intro.mp3\")\n\n    // 3. Generate chapters\n    chapters := []string{\n        \"Welcome to this course...\",\n        \"In this chapter...\",\n    }\n\n    for i, text := range chapters {\n        audio, _ := client.TextToSpeech().Simple(ctx, voiceID, text)\n        saveAudio(audio, fmt.Sprintf(\"chapter%d.mp3\", i+1))\n    }\n}\n\nfunc saveAudio(r io.Reader, filename string) {\n    f, _ := os.Create(filename)\n    defer f.Close()\n    io.Copy(f, r)\n}\n</code></pre>"},{"location":"examples/#more-examples","title":"More Examples","text":"<p>See the examples directory in the repository for complete working examples.</p>"},{"location":"api/client/","title":"Client API Reference","text":""},{"location":"api/client/#client","title":"Client","text":"<p>The main client for interacting with the ElevenLabs API.</p>"},{"location":"api/client/#constructor","title":"Constructor","text":"<pre><code>func NewClient(opts ...Option) (*Client, error)\n</code></pre> <p>Creates a new client with optional configuration.</p> <p>Options:</p> Option Description <code>WithAPIKey(key string)</code> Set API key <code>WithBaseURL(url string)</code> Set base URL <code>WithHTTPClient(client *http.Client)</code> Set HTTP client <code>WithTimeout(timeout time.Duration)</code> Set request timeout <p>Example:</p> <pre><code>client, err := elevenlabs.NewClient(\n    elevenlabs.WithAPIKey(\"your-api-key\"),\n    elevenlabs.WithTimeout(5 * time.Minute),\n)\n</code></pre>"},{"location":"api/client/#service-accessors","title":"Service Accessors","text":"Method Returns Description <code>TextToSpeech()</code> <code>*TextToSpeechService</code> Text-to-speech operations <code>Voices()</code> <code>*VoicesService</code> Voice management <code>Models()</code> <code>*ModelsService</code> Model listing <code>History()</code> <code>*HistoryService</code> Generation history <code>User()</code> <code>*UserService</code> User/subscription info <code>Dubbing()</code> <code>*DubbingService</code> Video dubbing <code>SoundEffects()</code> <code>*SoundEffectsService</code> Sound effect generation <code>Pronunciation()</code> <code>*PronunciationService</code> Pronunciation dictionaries <code>Projects()</code> <code>*ProjectsService</code> Studio projects <code>API()</code> <code>*api.Client</code> Raw ogen client"},{"location":"api/client/#constants","title":"Constants","text":"<pre><code>const Version = \"0.1.0\"\nconst DefaultBaseURL = \"https://api.elevenlabs.io\"\nconst DefaultModelID = \"eleven_multilingual_v2\"\n</code></pre>"},{"location":"api/client/#texttospeechservice","title":"TextToSpeechService","text":""},{"location":"api/client/#generate","title":"Generate","text":"<pre><code>func (s *TextToSpeechService) Generate(ctx context.Context, req *TTSRequest) (*TTSResponse, error)\n</code></pre> <p>Generate speech with full control over options.</p>"},{"location":"api/client/#simple","title":"Simple","text":"<pre><code>func (s *TextToSpeechService) Simple(ctx context.Context, voiceID, text string) (io.Reader, error)\n</code></pre> <p>Generate speech with default settings.</p>"},{"location":"api/client/#voicesservice","title":"VoicesService","text":""},{"location":"api/client/#list","title":"List","text":"<pre><code>func (s *VoicesService) List(ctx context.Context) ([]*Voice, error)\n</code></pre>"},{"location":"api/client/#get","title":"Get","text":"<pre><code>func (s *VoicesService) Get(ctx context.Context, voiceID string) (*Voice, error)\n</code></pre>"},{"location":"api/client/#getsettings","title":"GetSettings","text":"<pre><code>func (s *VoicesService) GetSettings(ctx context.Context, voiceID string) (*VoiceSettings, error)\n</code></pre>"},{"location":"api/client/#getdefaultsettings","title":"GetDefaultSettings","text":"<pre><code>func (s *VoicesService) GetDefaultSettings(ctx context.Context) (*VoiceSettings, error)\n</code></pre>"},{"location":"api/client/#soundeffectsservice","title":"SoundEffectsService","text":""},{"location":"api/client/#generate_1","title":"Generate","text":"<pre><code>func (s *SoundEffectsService) Generate(ctx context.Context, req *SoundEffectRequest) (*SoundEffectResponse, error)\n</code></pre>"},{"location":"api/client/#simple_1","title":"Simple","text":"<pre><code>func (s *SoundEffectsService) Simple(ctx context.Context, description string) (io.Reader, error)\n</code></pre>"},{"location":"api/client/#generateloop","title":"GenerateLoop","text":"<pre><code>func (s *SoundEffectsService) GenerateLoop(ctx context.Context, description string, durationSeconds float64) (io.Reader, error)\n</code></pre>"},{"location":"api/client/#pronunciationservice","title":"PronunciationService","text":""},{"location":"api/client/#list_1","title":"List","text":"<pre><code>func (s *PronunciationService) List(ctx context.Context, opts *PronunciationDictionaryListOptions) (*PronunciationDictionaryListResponse, error)\n</code></pre>"},{"location":"api/client/#get_1","title":"Get","text":"<pre><code>func (s *PronunciationService) Get(ctx context.Context, dictionaryID string) (*PronunciationDictionary, error)\n</code></pre>"},{"location":"api/client/#create","title":"Create","text":"<pre><code>func (s *PronunciationService) Create(ctx context.Context, req *CreatePronunciationDictionaryRequest) (*PronunciationDictionary, error)\n</code></pre>"},{"location":"api/client/#createfromjson","title":"CreateFromJSON","text":"<pre><code>func (s *PronunciationService) CreateFromJSON(ctx context.Context, name, jsonFilePath string) (*PronunciationDictionary, error)\n</code></pre>"},{"location":"api/client/#createfrommap","title":"CreateFromMap","text":"<pre><code>func (s *PronunciationService) CreateFromMap(ctx context.Context, name string, rules map[string]string) (*PronunciationDictionary, error)\n</code></pre>"},{"location":"api/client/#removerules","title":"RemoveRules","text":"<pre><code>func (s *PronunciationService) RemoveRules(ctx context.Context, dictionaryID string, ruleStrings []string) error\n</code></pre>"},{"location":"api/client/#rename","title":"Rename","text":"<pre><code>func (s *PronunciationService) Rename(ctx context.Context, dictionaryID, newName string) error\n</code></pre>"},{"location":"api/client/#archive","title":"Archive","text":"<pre><code>func (s *PronunciationService) Archive(ctx context.Context, dictionaryID string) error\n</code></pre>"},{"location":"api/client/#projectsservice","title":"ProjectsService","text":""},{"location":"api/client/#list_2","title":"List","text":"<pre><code>func (s *ProjectsService) List(ctx context.Context) ([]*Project, error)\n</code></pre>"},{"location":"api/client/#create_1","title":"Create","text":"<pre><code>func (s *ProjectsService) Create(ctx context.Context, req *CreateProjectRequest) (*Project, error)\n</code></pre>"},{"location":"api/client/#update","title":"Update","text":"<pre><code>func (s *ProjectsService) Update(ctx context.Context, projectID string, req *UpdateProjectRequest) error\n</code></pre>"},{"location":"api/client/#delete","title":"Delete","text":"<pre><code>func (s *ProjectsService) Delete(ctx context.Context, projectID string) error\n</code></pre>"},{"location":"api/client/#convert","title":"Convert","text":"<pre><code>func (s *ProjectsService) Convert(ctx context.Context, projectID string) error\n</code></pre>"},{"location":"api/client/#listchapters","title":"ListChapters","text":"<pre><code>func (s *ProjectsService) ListChapters(ctx context.Context, projectID string) ([]*Chapter, error)\n</code></pre>"},{"location":"api/client/#convertchapter","title":"ConvertChapter","text":"<pre><code>func (s *ProjectsService) ConvertChapter(ctx context.Context, projectID, chapterID string) error\n</code></pre>"},{"location":"api/client/#deletechapter","title":"DeleteChapter","text":"<pre><code>func (s *ProjectsService) DeleteChapter(ctx context.Context, projectID, chapterID string) error\n</code></pre>"},{"location":"api/client/#listsnapshots","title":"ListSnapshots","text":"<pre><code>func (s *ProjectsService) ListSnapshots(ctx context.Context, projectID string) ([]*ProjectSnapshot, error)\n</code></pre>"},{"location":"api/client/#downloadsnapshotarchive","title":"DownloadSnapshotArchive","text":"<pre><code>func (s *ProjectsService) DownloadSnapshotArchive(ctx context.Context, projectID, snapshotID string) (io.Reader, error)\n</code></pre>"},{"location":"api/client/#helper-functions","title":"Helper Functions","text":""},{"location":"api/client/#pronunciationrules","title":"PronunciationRules","text":"<pre><code>func LoadRulesFromJSON(filename string) (PronunciationRules, error)\nfunc ParseRulesFromJSON(data []byte) (PronunciationRules, error)\nfunc RulesFromMap(m map[string]string) PronunciationRules\n\nfunc (rules PronunciationRules) ToPLS(language string) ([]byte, error)\nfunc (rules PronunciationRules) ToPLSString(language string) (string, error)\nfunc (rules PronunciationRules) SavePLS(filename, language string) error\nfunc (rules PronunciationRules) Graphemes() []string\nfunc (rules PronunciationRules) String() string\n</code></pre>"},{"location":"api/client/#voicesettings","title":"VoiceSettings","text":"<pre><code>func DefaultVoiceSettings() *VoiceSettings\n</code></pre> <p>Returns default voice settings (Stability: 0.5, SimilarityBoost: 0.75).</p>"},{"location":"api/coverage/","title":"API Coverage","text":"<p>This page documents the ElevenLabs API coverage in this Go SDK.</p> <p>Total API Methods: 204 SDK Status: Core functionality covered, advanced features in progress</p>"},{"location":"api/coverage/#coverage-summary","title":"Coverage Summary","text":"Category API Methods SDK Coverage Text-to-Speech 4 \u2713 Full WebSocket TTS 1 \u2713 Full Speech-to-Text 2 \u2713 Full WebSocket STT 1 \u2713 Full Speech-to-Speech 2 \u2713 Full Voices 9 \u2713 Full Models 1 \u2713 Full History 5 \u2713 Full User 1 \u2713 Full Sound Effects 1 \u2713 Full Forced Alignment 1 \u2713 Full Audio Isolation 2 \u2713 Full Text-to-Dialogue 4 \u2713 Full Voice Design 8 \u2713 Partial Music 5 \u2713 Full Pronunciation 6 \u2713 Full Projects (Studio) 14 \u2713 Partial Dubbing 14 \u2713 Partial Phone / Twilio 7 \u2713 Partial Professional Voice Cloning 12 \u2717 Not covered Voice Library 5 \u2717 Not covered Conversational AI 26 \u2717 Not covered Knowledge Base / RAG 15 \u2717 Not covered Workspace Management 20 \u2717 Not covered MCP / Tools 5 \u2717 Not covered Audio Native 3 \u2717 Not covered Transcription 4 \u2717 Not covered Miscellaneous 6 \u2717 Not covered"},{"location":"api/coverage/#covered-apis","title":"Covered APIs","text":""},{"location":"api/coverage/#text-to-speech-4-methods","title":"Text-to-Speech (4 methods) \u2713","text":"<p>Full coverage of text-to-speech functionality.</p> Method SDK Support <code>TextToSpeechFull</code> \u2713 <code>TextToSpeech().Generate()</code> <code>TextToSpeechStream</code> \u2713 <code>TextToSpeech().GenerateStream()</code> <code>TextToSpeechFullWithTimestamps</code> \u2713 <code>TextToSpeech().GenerateWithTimestamps()</code> <code>TextToSpeechStreamWithTimestamps</code> \u2713 <code>TextToSpeech().GenerateStreamWithTimestamps()</code>"},{"location":"api/coverage/#websocket-tts-1-method","title":"WebSocket TTS (1 method) \u2713","text":"<p>Real-time text-to-speech streaming via WebSocket for low-latency voice synthesis.</p> Method SDK Support <code>TextToSpeechWebSocket</code> \u2713 <code>WebSocketTTS().Connect()</code> <p>Key Features:</p> <ul> <li>Stream text to speech in real-time (ideal for LLM output)</li> <li>Low-latency audio generation with configurable optimization</li> <li>Word-level timing alignment</li> <li>SSML parsing support</li> </ul>"},{"location":"api/coverage/#speech-to-text-2-methods","title":"Speech-to-Text (2 methods) \u2713","text":"<p>Full coverage of transcription functionality.</p> Method SDK Support <code>SpeechToText</code> \u2713 <code>SpeechToText().Transcribe()</code> <code>Transcribe</code> \u2713 <code>SpeechToText().TranscribeURL()</code>"},{"location":"api/coverage/#websocket-stt-1-method","title":"WebSocket STT (1 method) \u2713","text":"<p>Real-time speech-to-text streaming via WebSocket for live transcription.</p> Method SDK Support <code>SpeechToTextWebSocket</code> \u2713 <code>WebSocketSTT().Connect()</code> <p>Key Features:</p> <ul> <li>Stream audio for real-time transcription</li> <li>Partial (interim) results for responsive UIs</li> <li>Word-level timing with confidence scores</li> <li>Automatic language detection</li> </ul>"},{"location":"api/coverage/#speech-to-speech-2-methods","title":"Speech-to-Speech (2 methods) \u2713","text":"<p>Voice conversion - transform speech from one voice to another.</p> Method SDK Support <code>SpeechToSpeechFull</code> \u2713 <code>SpeechToSpeech().Convert()</code> <code>SpeechToSpeechStream</code> \u2713 <code>SpeechToSpeech().ConvertStream()</code> <p>Key Features:</p> <ul> <li>Convert voice while preserving speech content</li> <li>Background noise removal option</li> <li>Seed audio for consistent conversions</li> <li>Configurable voice settings</li> </ul>"},{"location":"api/coverage/#voices-9-methods","title":"Voices (9 methods) \u2713","text":"<p>Full coverage of voice management.</p> Method SDK Support <code>GetVoices</code> \u2713 <code>Voices().List()</code> <code>GetVoiceByID</code> \u2713 <code>Voices().Get()</code> <code>AddVoice</code> \u2713 <code>Voices().Add()</code> <code>EditVoice</code> \u2713 <code>Voices().Edit()</code> <code>DeleteVoice</code> \u2713 <code>Voices().Delete()</code> <code>GetVoiceSettings</code> \u2713 <code>Voices().GetSettings()</code> <code>EditVoiceSettings</code> \u2713 <code>Voices().EditSettings()</code> <code>GetVoiceSettingsDefault</code> \u2713 <code>Voices().GetDefaultSettings()</code> <code>GetUserVoicesV2</code> \u2713 <code>Voices().ListUserVoices()</code>"},{"location":"api/coverage/#models-1-method","title":"Models (1 method) \u2713","text":"Method SDK Support <code>GetModels</code> \u2713 <code>Models().List()</code>"},{"location":"api/coverage/#history-5-methods","title":"History (5 methods) \u2713","text":"Method SDK Support <code>GetSpeechHistory</code> \u2713 <code>History().List()</code> <code>GetSpeechHistoryItemByID</code> \u2713 <code>History().Get()</code> <code>DeleteSpeechHistoryItem</code> \u2713 <code>History().Delete()</code> <code>DownloadSpeechHistoryItems</code> \u2713 <code>History().Download()</code> <code>GetAudioFullFromSpeechHistoryItem</code> \u2713 <code>History().GetAudio()</code>"},{"location":"api/coverage/#user-1-method","title":"User (1 method) \u2713","text":"Method SDK Support <code>GetUserInfo</code> \u2713 <code>User().Get()</code>"},{"location":"api/coverage/#sound-effects-1-method","title":"Sound Effects (1 method) \u2713","text":"Method SDK Support <code>SoundGeneration</code> \u2713 <code>SoundEffects().Generate()</code>"},{"location":"api/coverage/#forced-alignment-1-method","title":"Forced Alignment (1 method) \u2713","text":"Method SDK Support <code>ForcedAlignment</code> \u2713 <code>ForcedAlignment().Align()</code>"},{"location":"api/coverage/#audio-isolation-2-methods","title":"Audio Isolation (2 methods) \u2713","text":"Method SDK Support <code>AudioIsolation</code> \u2713 <code>AudioIsolation().Isolate()</code> <code>AudioIsolationStream</code> \u2713 <code>AudioIsolation().IsolateStream()</code>"},{"location":"api/coverage/#text-to-dialogue-4-methods","title":"Text-to-Dialogue (4 methods) \u2713","text":"Method SDK Support <code>TextToDialogue</code> \u2713 <code>TextToDialogue().Generate()</code> <code>TextToDialogueStream</code> \u2713 <code>TextToDialogue().GenerateStream()</code> <code>TextToDialogueFullWithTimestamps</code> \u2713 <code>TextToDialogue().GenerateWithTimestamps()</code> <code>TextToDialogueStreamWithTimestamps</code> \u2713 Planned"},{"location":"api/coverage/#voice-design-8-methods-partial","title":"Voice Design (8 methods) - Partial \u2713","text":"Method SDK Support <code>GenerateRandomVoice</code> \u2713 <code>VoiceDesign().GeneratePreview()</code> <code>CreateVoiceOld</code> \u2713 <code>VoiceDesign().SaveVoice()</code> <code>CreateVoice</code> \u2717 Not covered <code>TextToVoice</code> \u2717 Not covered <code>TextToVoiceDesign</code> \u2717 Not covered <code>TextToVoicePreviewStream</code> \u2717 Not covered <code>TextToVoiceRemix</code> \u2717 Not covered <code>GetGenerateVoiceParameters</code> \u2717 Not covered"},{"location":"api/coverage/#music-5-methods","title":"Music (5 methods) \u2713","text":"<p>Full coverage of music generation and stem separation.</p> Method SDK Support <code>Generate</code> \u2713 <code>Music().Generate()</code> <code>StreamCompose</code> \u2713 <code>Music().GenerateStream()</code> <code>ComposeDetailed</code> \u2713 <code>Music().GenerateDetailed()</code> <code>ComposePlan</code> \u2713 <code>Music().GeneratePlan()</code> <code>SeparateSongStems</code> \u2713 <code>Music().SeparateStems()</code>"},{"location":"api/coverage/#pronunciation-6-methods","title":"Pronunciation (6 methods) \u2713","text":"<p>Full coverage of pronunciation dictionary management.</p> Method SDK Support <code>AddFromFile</code> \u2713 <code>Pronunciation().Create()</code> <code>GetPronunciationDictionariesMetadata</code> \u2713 <code>Pronunciation().List()</code> <code>GetPronunciationDictionaryMetadata</code> \u2713 <code>Pronunciation().Get()</code> <code>PatchPronunciationDictionary</code> \u2713 <code>Pronunciation().Rename()</code>, <code>Pronunciation().Archive()</code> <code>RemoveRules</code> \u2713 <code>Pronunciation().RemoveRules()</code> <code>GetPronunciationDictionaryVersionPls</code> \u2713 <code>Pronunciation().GetVersionPLS()</code>, <code>Pronunciation().DownloadLatestPLS()</code> <p>Note</p> <p><code>UpdatePronunciationDictionaries</code> is a Projects API method that associates dictionaries with a project, not a pronunciation dictionary method.</p>"},{"location":"api/coverage/#projects-studio-14-methods-partial","title":"Projects / Studio (14 methods) - Partial \u2713","text":"Method SDK Support <code>AddProject</code> \u2713 <code>Projects().Create()</code> <code>GetProjects</code> \u2713 <code>Projects().List()</code> <code>DeleteProject</code> \u2713 <code>Projects().Delete()</code> <code>ConvertProjectEndpoint</code> \u2713 <code>Projects().Convert()</code> <code>EditProject</code> \u2717 Not covered <code>EditProjectContent</code> \u2717 Not covered <code>GetChapters</code> \u2717 Not covered <code>ConvertChapterEndpoint</code> \u2717 Not covered <code>DeleteChapterEndpoint</code> \u2717 Not covered <code>GetChapterSnapshots</code> \u2717 Not covered <code>GetChapterSnapshotEndpoint</code> \u2717 Not covered <code>GetProjectSnapshots</code> \u2717 Not covered <code>GetProjectSnapshotEndpoint</code> \u2717 Not covered <code>StreamProjectSnapshotArchiveEndpoint</code> \u2717 Not covered"},{"location":"api/coverage/#dubbing-14-methods-partial","title":"Dubbing (14 methods) - Partial \u2713","text":"Method SDK Support <code>CreateDubbing</code> \u2713 <code>Dubbing().Create()</code> <code>DeleteDubbing</code> \u2713 <code>Dubbing().Delete()</code> <code>GetDubbingResource</code> \u2713 <code>Dubbing().GetStatus()</code> <code>Dub</code> \u2717 Not covered <code>AddLanguage</code> \u2717 Not covered <code>CreateSpeaker</code> \u2717 Not covered <code>UpdateSpeaker</code> \u2717 Not covered <code>GetSpeakerAudio</code> \u2717 Not covered <code>GetSimilarVoicesForSpeaker</code> \u2717 Not covered <code>StartSpeakerSeparation</code> \u2717 Not covered <code>CreateClip</code> \u2717 Not covered <code>DeleteSegment</code> \u2717 Not covered <code>UpdateSegmentLanguage</code> \u2717 Not covered <code>MigrateSegments</code> \u2717 Not covered"},{"location":"api/coverage/#phone-twilio-7-methods-partial","title":"Phone / Twilio (7 methods) - Partial \u2713","text":"<p>Phone call and Twilio integration for conversational AI agents.</p> Method SDK Support <code>RegisterTwilioCall</code> \u2713 <code>Twilio().RegisterCall()</code> <code>HandleTwilioOutboundCall</code> \u2713 <code>Twilio().OutboundCall()</code> <code>HandleSipTrunkOutboundCall</code> \u2713 <code>Twilio().SIPOutboundCall()</code> <code>ListPhoneNumbersRoute</code> \u2713 <code>PhoneNumbers().List()</code> <code>GetPhoneNumberRoute</code> \u2713 <code>PhoneNumbers().Get()</code> <code>UpdatePhoneNumberRoute</code> \u2713 <code>PhoneNumbers().Update()</code> <code>DeletePhoneNumberRoute</code> \u2713 <code>PhoneNumbers().Delete()</code> <p>Key Features:</p> <ul> <li>Register incoming Twilio calls with ElevenLabs agents</li> <li>Initiate outbound calls via Twilio or SIP trunks</li> <li>Manage phone numbers associated with agents</li> <li>Dynamic variables and prompt overrides per call</li> </ul>"},{"location":"api/coverage/#not-covered-apis","title":"Not Covered APIs","text":""},{"location":"api/coverage/#professional-voice-cloning-pvc-12-methods","title":"Professional Voice Cloning - PVC (12 methods)","text":"<p>Professional-grade voice cloning with training.</p> Method Description <code>CreatePvcVoice</code> Create a PVC voice <code>EditPvcVoice</code> Edit PVC voice settings <code>AddPvcVoiceSamples</code> Add training samples <code>DeletePvcVoiceSample</code> Delete a sample <code>EditPvcVoiceSample</code> Edit sample metadata <code>GetPvcSampleAudio</code> Get sample audio <code>GetPvcSampleSpeakers</code> Get detected speakers <code>GetPvcSampleVisualWaveform</code> Get waveform visualization <code>GetPvcVoiceCaptcha</code> Get verification captcha <code>VerifyPvcVoiceCaptcha</code> Verify captcha <code>RequestPvcManualVerification</code> Request manual verification <code>RunPvcVoiceTraining</code> Start voice training"},{"location":"api/coverage/#voice-library-5-methods","title":"Voice Library (5 methods)","text":"<p>Community voice discovery and sharing.</p> Method Description <code>GetLibraryVoices</code> Browse community voices <code>GetSimilarLibraryVoices</code> Find similar voices <code>AddSharingVoice</code> Add a shared voice to your library <code>ShareResourceEndpoint</code> Share a resource <code>UnshareResourceEndpoint</code> Unshare a resource"},{"location":"api/coverage/#conversational-ai-26-methods","title":"Conversational AI (26 methods)","text":"<p>AI agents and conversational interfaces.</p> Method Description <code>GetAgentsRoute</code> List agents <code>DeleteAgentRoute</code> Delete an agent <code>DuplicateAgentRoute</code> Duplicate an agent <code>PostAgentAvatarRoute</code> Upload agent avatar <code>GetAgentLinkRoute</code> Get shareable agent link <code>GetAgentKnowledgeBaseSize</code> Get KB size <code>GetAgentKnowledgeBaseSummariesRoute</code> Get KB summaries <code>GetAgentLlmExpectedCostCalculation</code> Estimate LLM costs <code>CreateAgentResponseTestRoute</code> Create response test <code>GetAgentResponseTestRoute</code> Get test results <code>UpdateAgentResponseTestRoute</code> Update test <code>GetAgentResponseTestsSummariesRoute</code> Get test summaries <code>DeleteConversationRoute</code> Delete conversation <code>GetConversationHistoriesRoute</code> List conversations <code>GetConversationAudioRoute</code> Get conversation audio <code>GetConversationSignedLink</code> Get signed link <code>PostConversationFeedbackRoute</code> Submit feedback <code>CreateBatchCall</code> Create batch call job <code>GetBatchCall</code> Get batch call status <code>CancelBatchCall</code> Cancel batch call <code>RetryBatchCall</code> Retry failed calls <code>GetWorkspaceBatchCalls</code> List workspace batch calls <code>GetLiveCount</code> Get live call count <code>GetLivekitToken</code> Get LiveKit token <code>ListChatResponseTestsRoute</code> List chat tests <code>DeleteChatResponseTestRoute</code> Delete chat test"},{"location":"api/coverage/#knowledge-base-rag-15-methods","title":"Knowledge Base / RAG (15 methods)","text":"<p>Document management and retrieval-augmented generation.</p> Method Description <code>AddDocumentationToKnowledgeBase</code> Add documentation <code>CreateFileDocumentRoute</code> Create from file <code>CreateTextDocumentRoute</code> Create from text <code>CreateURLDocumentRoute</code> Create from URL <code>DeleteKnowledgeBaseDocument</code> Delete document <code>GetDocumentationFromKnowledgeBase</code> Get documentation <code>GetDocumentationChunkFromKnowledgeBase</code> Get chunk <code>GetKnowledgeBaseContent</code> Get KB content <code>GetKnowledgeBaseListRoute</code> List knowledge bases <code>UpdateDocumentRoute</code> Update document <code>GetOrCreateRagIndexes</code> Get/create RAG indexes <code>GetRagIndexes</code> List RAG indexes <code>GetRagIndexOverview</code> Get index overview <code>DeleteRagIndex</code> Delete index <code>RagIndexStatus</code> Get index status"},{"location":"api/coverage/#whatsapp-integration-6-methods","title":"WhatsApp Integration (6 methods)","text":"<p>WhatsApp call and messaging integration.</p> Method Description <code>GetWhatsappAccount</code> Get WhatsApp account <code>ListWhatsappAccounts</code> List accounts <code>ImportWhatsappAccount</code> Import account <code>UpdateWhatsappAccount</code> Update account <code>DeleteWhatsappAccount</code> Delete account <code>WhatsappOutboundCall</code> Make WhatsApp call"},{"location":"api/coverage/#workspace-management-20-methods","title":"Workspace Management (20 methods)","text":"<p>Team, permissions, and workspace settings.</p> Method Description <code>SearchGroups</code> Search user groups <code>AddMember</code> Add group member <code>RemoveMember</code> Remove member <code>InviteUser</code> Invite user <code>InviteUsersBulk</code> Bulk invite <code>DeleteInvite</code> Delete invitation <code>UpdateWorkspaceMember</code> Update member <code>CreateSecretRoute</code> Create secret <code>GetSecretsRoute</code> List secrets <code>UpdateSecretRoute</code> Update secret <code>DeleteSecretRoute</code> Delete secret <code>GetWorkspaceServiceAccounts</code> List service accounts <code>CreateServiceAccountAPIKey</code> Create API key <code>EditServiceAccountAPIKey</code> Edit API key <code>DeleteServiceAccountAPIKey</code> Delete API key <code>GetServiceAccountAPIKeysRoute</code> List API keys <code>GetSettingsRoute</code> Get settings <code>UpdateSettingsRoute</code> Update settings <code>GetDashboardSettingsRoute</code> Get dashboard settings <code>UpdateDashboardSettingsRoute</code> Update dashboard"},{"location":"api/coverage/#webhooks-4-methods","title":"Webhooks (4 methods)","text":"Method Description <code>CreateWorkspaceWebhookRoute</code> Create webhook <code>GetWorkspaceWebhooksRoute</code> List webhooks <code>EditWorkspaceWebhookRoute</code> Edit webhook <code>DeleteWorkspaceWebhookRoute</code> Delete webhook"},{"location":"api/coverage/#mcp-tools-5-methods","title":"MCP / Tools (5 methods)","text":"<p>Model Context Protocol and tool integrations.</p> Method Description <code>DeleteMcpServerRoute</code> Delete MCP server <code>ListMcpServerToolsRoute</code> List MCP tools <code>GetMcpToolConfigOverrideRoute</code> Get tool config <code>DeleteToolRoute</code> Delete tool <code>GetToolDependentAgentsRoute</code> Get dependent agents"},{"location":"api/coverage/#audio-native-3-methods","title":"Audio Native (3 methods)","text":"<p>Audio Native project embedding.</p> Method Description <code>CreateAudioNativeProject</code> Create project <code>AudioNativeProjectUpdateContentEndpoint</code> Update content <code>GetAudioNativeProjectSettingsEndpoint</code> Get settings"},{"location":"api/coverage/#transcription-4-methods","title":"Transcription (4 methods)","text":"<p>Advanced transcription features.</p> Method Description <code>GetTranscriptByID</code> Get transcript <code>DeleteTranscriptByID</code> Delete transcript <code>GetDubbedTranscriptFile</code> Get dubbed transcript <code>Translate</code> Translate content"},{"location":"api/coverage/#miscellaneous-6-methods","title":"Miscellaneous (6 methods)","text":"Method Description <code>UsageCharacters</code> Get character usage stats <code>GetSingleUseToken</code> Get single-use token <code>GetResourceMetadata</code> Get resource metadata <code>GetSignedURLDeprecated</code> Get signed URL (deprecated) <code>GetPublicLlmExpectedCostCalculation</code> Public LLM cost calc <code>RedirectToMintlify</code> Redirect to docs"},{"location":"api/coverage/#contributing","title":"Contributing","text":"<p>Want to help expand SDK coverage? Contributions are welcome! Priority areas:</p> <ol> <li>Conversational AI Agents - Agent management and conversation APIs</li> <li>Voice Library - Community voice discovery and sharing</li> <li>Professional Voice Cloning - Premium voice training features</li> <li>Knowledge Base / RAG - Document management for agent context</li> </ol> <p>See the Contributing Guide for details.</p>"},{"location":"api/errors/","title":"Errors","text":"<p>Error types and handling for the ElevenLabs SDK.</p>"},{"location":"api/errors/#error-types","title":"Error Types","text":""},{"location":"api/errors/#validationerror","title":"ValidationError","text":"<p>Returned when request validation fails before making an API call.</p> <pre><code>type ValidationError struct {\n    Field   string\n    Message string\n}\n</code></pre> <p>Example:</p> <pre><code>audio, err := client.TextToSpeech().Simple(ctx, \"\", \"Hello\")\nif err != nil {\n    var valErr *elevenlabs.ValidationError\n    if errors.As(err, &amp;valErr) {\n        fmt.Printf(\"Validation error on %s: %s\\n\", valErr.Field, valErr.Message)\n        // Output: Validation error on voice_id: cannot be empty\n    }\n}\n</code></pre>"},{"location":"api/errors/#apierror","title":"APIError","text":"<p>Returned when the API returns an error response.</p> <pre><code>type APIError struct {\n    StatusCode int\n    Message    string\n    Detail     string\n}\n</code></pre> <p>Example:</p> <pre><code>audio, err := client.TextToSpeech().Simple(ctx, \"invalid-voice\", \"Hello\")\nif err != nil {\n    var apiErr *elevenlabs.APIError\n    if errors.As(err, &amp;apiErr) {\n        fmt.Printf(\"API error %d: %s\\n\", apiErr.StatusCode, apiErr.Message)\n    }\n}\n</code></pre>"},{"location":"api/errors/#sentinel-errors","title":"Sentinel Errors","text":"<pre><code>var ErrEmptyVoiceID = errors.New(\"elevenlabs: voice_id cannot be empty\")\nvar ErrEmptyText    = errors.New(\"elevenlabs: text cannot be empty\")\n</code></pre>"},{"location":"api/errors/#error-helper-functions","title":"Error Helper Functions","text":""},{"location":"api/errors/#isnotfounderror","title":"IsNotFoundError","text":"<pre><code>func IsNotFoundError(err error) bool\n</code></pre> <p>Returns true if the error is a 404 Not Found response.</p> <pre><code>voice, err := client.Voices().Get(ctx, \"nonexistent\")\nif elevenlabs.IsNotFoundError(err) {\n    fmt.Println(\"Voice not found\")\n}\n</code></pre>"},{"location":"api/errors/#isunauthorizederror","title":"IsUnauthorizedError","text":"<pre><code>func IsUnauthorizedError(err error) bool\n</code></pre> <p>Returns true if the error is a 401 Unauthorized response.</p> <pre><code>if elevenlabs.IsUnauthorizedError(err) {\n    fmt.Println(\"Invalid API key\")\n}\n</code></pre>"},{"location":"api/errors/#isratelimiterror","title":"IsRateLimitError","text":"<pre><code>func IsRateLimitError(err error) bool\n</code></pre> <p>Returns true if the error is a 429 Too Many Requests response.</p> <pre><code>if elevenlabs.IsRateLimitError(err) {\n    fmt.Println(\"Rate limited, waiting...\")\n    time.Sleep(time.Minute)\n}\n</code></pre>"},{"location":"api/errors/#error-handling-patterns","title":"Error Handling Patterns","text":""},{"location":"api/errors/#complete-error-handling","title":"Complete Error Handling","text":"<pre><code>audio, err := client.TextToSpeech().Simple(ctx, voiceID, text)\nif err != nil {\n    // Check for validation errors first\n    var valErr *elevenlabs.ValidationError\n    if errors.As(err, &amp;valErr) {\n        return fmt.Errorf(\"invalid request: %s - %s\", valErr.Field, valErr.Message)\n    }\n\n    // Check for specific API errors\n    if elevenlabs.IsUnauthorizedError(err) {\n        return errors.New(\"invalid API key\")\n    }\n    if elevenlabs.IsRateLimitError(err) {\n        return errors.New(\"rate limited, try again later\")\n    }\n    if elevenlabs.IsNotFoundError(err) {\n        return errors.New(\"voice not found\")\n    }\n\n    // Generic API error\n    var apiErr *elevenlabs.APIError\n    if errors.As(err, &amp;apiErr) {\n        return fmt.Errorf(\"API error %d: %s\", apiErr.StatusCode, apiErr.Message)\n    }\n\n    // Unknown error\n    return fmt.Errorf(\"unexpected error: %w\", err)\n}\n</code></pre>"},{"location":"api/errors/#retry-pattern","title":"Retry Pattern","text":"<pre><code>func generateWithRetry(client *elevenlabs.Client, voiceID, text string, maxRetries int) (io.Reader, error) {\n    ctx := context.Background()\n\n    for i := 0; i &lt; maxRetries; i++ {\n        audio, err := client.TextToSpeech().Simple(ctx, voiceID, text)\n        if err == nil {\n            return audio, nil\n        }\n\n        if elevenlabs.IsRateLimitError(err) {\n            backoff := time.Duration(i+1) * 30 * time.Second\n            log.Printf(\"Rate limited, waiting %v...\", backoff)\n            time.Sleep(backoff)\n            continue\n        }\n\n        // Non-retryable error\n        return nil, err\n    }\n\n    return nil, errors.New(\"max retries exceeded\")\n}\n</code></pre>"},{"location":"api/errors/#pre-flight-validation","title":"Pre-flight Validation","text":"<pre><code>func generateSafely(client *elevenlabs.Client, voiceID, text string) (io.Reader, error) {\n    // Validate inputs before API call\n    if voiceID == \"\" {\n        return nil, &amp;elevenlabs.ValidationError{\n            Field:   \"voice_id\",\n            Message: \"cannot be empty\",\n        }\n    }\n    if text == \"\" {\n        return nil, &amp;elevenlabs.ValidationError{\n            Field:   \"text\",\n            Message: \"cannot be empty\",\n        }\n    }\n\n    // Check character limit\n    sub, err := client.User().GetSubscription(context.Background())\n    if err != nil {\n        return nil, err\n    }\n    if sub.CharactersRemaining() &lt; len(text) {\n        return nil, errors.New(\"insufficient characters remaining\")\n    }\n\n    // Safe to proceed\n    return client.TextToSpeech().Simple(context.Background(), voiceID, text)\n}\n</code></pre>"},{"location":"getting-started/configuration/","title":"Configuration","text":""},{"location":"getting-started/configuration/#client-options","title":"Client Options","text":"<p>The client supports several configuration options using functional options pattern.</p>"},{"location":"getting-started/configuration/#api-key","title":"API Key","text":"<pre><code>// From environment variable (default)\nclient, _ := elevenlabs.NewClient()\n\n// Explicitly set\nclient, _ := elevenlabs.NewClient(\n    elevenlabs.WithAPIKey(\"your-api-key\"),\n)\n</code></pre>"},{"location":"getting-started/configuration/#custom-base-url","title":"Custom Base URL","text":"<pre><code>client, _ := elevenlabs.NewClient(\n    elevenlabs.WithBaseURL(\"https://custom-endpoint.example.com\"),\n)\n</code></pre>"},{"location":"getting-started/configuration/#custom-http-client","title":"Custom HTTP Client","text":"<pre><code>httpClient := &amp;http.Client{\n    Timeout: 60 * time.Second,\n    Transport: &amp;http.Transport{\n        MaxIdleConns:        10,\n        IdleConnTimeout:     30 * time.Second,\n    },\n}\n\nclient, _ := elevenlabs.NewClient(\n    elevenlabs.WithHTTPClient(httpClient),\n)\n</code></pre>"},{"location":"getting-started/configuration/#request-timeout","title":"Request Timeout","text":"<pre><code>client, _ := elevenlabs.NewClient(\n    elevenlabs.WithTimeout(5 * time.Minute),  // For long audio generation\n)\n</code></pre>"},{"location":"getting-started/configuration/#multiple-options","title":"Multiple Options","text":"<pre><code>client, _ := elevenlabs.NewClient(\n    elevenlabs.WithAPIKey(\"your-api-key\"),\n    elevenlabs.WithTimeout(3 * time.Minute),\n    elevenlabs.WithBaseURL(\"https://api.elevenlabs.io\"),\n)\n</code></pre>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":"Variable Description <code>ELEVENLABS_API_KEY</code> API key for authentication"},{"location":"getting-started/configuration/#accessing-the-raw-api-client","title":"Accessing the Raw API Client","text":"<p>For advanced use cases not covered by the wrapper, access the underlying ogen-generated client:</p> <pre><code>client, _ := elevenlabs.NewClient()\n\n// Access raw API for advanced operations\nrawClient := client.API()\n\n// Use raw client methods directly\nresp, err := rawClient.SomeAdvancedMethod(ctx, params)\n</code></pre>"},{"location":"getting-started/configuration/#constants","title":"Constants","text":"<pre><code>// SDK version\nelevenlabs.Version  // \"0.1.0\"\n\n// Default base URL\nelevenlabs.DefaultBaseURL  // \"https://api.elevenlabs.io\"\n\n// Recommended model\nelevenlabs.DefaultModelID  // \"eleven_multilingual_v2\"\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Go 1.21 or later</li> <li>An ElevenLabs API key (get one here)</li> </ul>"},{"location":"getting-started/installation/#install-the-sdk","title":"Install the SDK","text":"<pre><code>go get github.com/agentplexus/go-elevenlabs\n</code></pre>"},{"location":"getting-started/installation/#get-your-api-key","title":"Get Your API Key","text":"<ol> <li>Sign up at elevenlabs.io</li> <li>Go to your Profile Settings</li> <li>Copy your API key</li> </ol>"},{"location":"getting-started/installation/#set-up-authentication","title":"Set Up Authentication","text":"<p>The SDK can read your API key from the environment:</p> <pre><code>export ELEVENLABS_API_KEY=your-api-key-here\n</code></pre> <p>Or pass it directly when creating the client:</p> <pre><code>client, err := elevenlabs.NewClient(\n    elevenlabs.WithAPIKey(\"your-api-key-here\"),\n)\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n)\n\nfunc main() {\n    client, err := elevenlabs.NewClient()\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // Check subscription\n    sub, err := client.User().GetSubscription(context.Background())\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    fmt.Printf(\"Connected! Tier: %s, Characters remaining: %d\\n\",\n        sub.Tier, sub.CharactersRemaining())\n}\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Generate your first audio</li> <li>Configuration - Advanced client options</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>This guide will have you generating audio in under 5 minutes.</p>"},{"location":"getting-started/quickstart/#create-a-client","title":"Create a Client","text":"<pre><code>import elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n\n// Uses ELEVENLABS_API_KEY environment variable\nclient, err := elevenlabs.NewClient()\nif err != nil {\n    log.Fatal(err)\n}\n</code></pre>"},{"location":"getting-started/quickstart/#list-available-voices","title":"List Available Voices","text":"<pre><code>ctx := context.Background()\n\nvoices, err := client.Voices().List(ctx)\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, v := range voices {\n    fmt.Printf(\"%s: %s\\n\", v.VoiceID, v.Name)\n}\n</code></pre>"},{"location":"getting-started/quickstart/#generate-speech","title":"Generate Speech","text":""},{"location":"getting-started/quickstart/#simple-method","title":"Simple Method","text":"<pre><code>// Generate speech with default settings\naudio, err := client.TextToSpeech().Simple(ctx,\n    \"21m00Tcm4TlvDq8ikWAM\",  // Voice ID (Rachel)\n    \"Hello, this is a test of the ElevenLabs API.\")\nif err != nil {\n    log.Fatal(err)\n}\n\n// Save to file\nf, _ := os.Create(\"output.mp3\")\ndefer f.Close()\nio.Copy(f, audio)\n</code></pre>"},{"location":"getting-started/quickstart/#with-options","title":"With Options","text":"<pre><code>resp, err := client.TextToSpeech().Generate(ctx, &amp;elevenlabs.TTSRequest{\n    VoiceID: \"21m00Tcm4TlvDq8ikWAM\",\n    Text:    \"Hello with custom settings!\",\n    ModelID: \"eleven_multilingual_v2\",\n    VoiceSettings: &amp;elevenlabs.VoiceSettings{\n        Stability:       0.5,\n        SimilarityBoost: 0.75,\n        Style:           0.2,\n    },\n    OutputFormat: \"mp3_44100_128\",\n})\n</code></pre>"},{"location":"getting-started/quickstart/#generate-sound-effects","title":"Generate Sound Effects","text":"<pre><code>audio, err := client.SoundEffects().Simple(ctx, \"thunder and rain storm\")\nif err != nil {\n    log.Fatal(err)\n}\n\nf, _ := os.Create(\"thunder.mp3\")\ndefer f.Close()\nio.Copy(f, audio)\n</code></pre>"},{"location":"getting-started/quickstart/#check-your-usage","title":"Check Your Usage","text":"<pre><code>sub, err := client.User().GetSubscription(ctx)\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Characters used: %d / %d\\n\",\n    sub.CharacterCount, sub.CharacterLimit)\nfmt.Printf(\"Remaining: %d\\n\", sub.CharactersRemaining())\n</code></pre>"},{"location":"getting-started/quickstart/#complete-example","title":"Complete Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"io\"\n    \"log\"\n    \"os\"\n\n    elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n)\n\nfunc main() {\n    client, err := elevenlabs.NewClient()\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    ctx := context.Background()\n\n    // List voices\n    voices, _ := client.Voices().List(ctx)\n    fmt.Printf(\"Found %d voices\\n\", len(voices))\n\n    // Generate speech using first voice\n    if len(voices) &gt; 0 {\n        audio, err := client.TextToSpeech().Simple(ctx,\n            voices[0].VoiceID,\n            \"Hello from go-elevenlabs!\")\n        if err != nil {\n            log.Fatal(err)\n        }\n\n        f, _ := os.Create(\"hello.mp3\")\n        defer f.Close()\n        n, _ := io.Copy(f, audio)\n        fmt.Printf(\"Saved %d bytes to hello.mp3\\n\", n)\n    }\n}\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration - Custom HTTP clients, timeouts</li> <li>Text-to-Speech - Full TTS documentation</li> <li>Voices - Voice management</li> </ul>"},{"location":"guides/lms-courses/","title":"Creating LMS/Udemy Courses","text":"<p>A complete guide to using go-elevenlabs for creating professional online course audio.</p>"},{"location":"guides/lms-courses/#overview","title":"Overview","text":"<p>This SDK provides everything you need to produce professional course audio:</p> Feature Service Use Case Narration Text-to-Speech Generate voiceovers from scripts Voice Selection Voices Choose the right narrator Course Structure Projects Organize into chapters Technical Terms Pronunciation Handle jargon correctly Sound Effects SoundEffects Intros, transitions Background Music Music Generate custom background tracks Multi-Language Dubbing Translate to other languages Usage Tracking User Monitor character consumption"},{"location":"guides/lms-courses/#workflow","title":"Workflow","text":""},{"location":"guides/lms-courses/#1-set-up-your-project","title":"1. Set Up Your Project","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"log\"\n\n    elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n)\n\nfunc main() {\n    client, err := elevenlabs.NewClient()\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    ctx := context.Background()\n\n    // Check available characters\n    sub, _ := client.User().GetSubscription(ctx)\n    fmt.Printf(\"Characters available: %d\\n\", sub.CharactersRemaining())\n}\n</code></pre>"},{"location":"guides/lms-courses/#2-create-pronunciation-dictionary","title":"2. Create Pronunciation Dictionary","text":"<p>Handle technical terms before generating audio:</p> <pre><code>// terms.json\n[\n  {\"grapheme\": \"API\", \"alias\": \"A P I\"},\n  {\"grapheme\": \"SDK\", \"alias\": \"S D K\"},\n  {\"grapheme\": \"JSON\", \"alias\": \"jay son\"},\n  {\"grapheme\": \"CLI\", \"alias\": \"C L I\"},\n  {\"grapheme\": \"GUI\", \"alias\": \"gooey\"},\n  {\"grapheme\": \"SQL\", \"alias\": \"sequel\"},\n  {\"grapheme\": \"OAuth\", \"alias\": \"oh auth\"},\n  {\"grapheme\": \"nginx\", \"alias\": \"engine X\"},\n  {\"grapheme\": \"kubectl\", \"alias\": \"kube control\"}\n]\n</code></pre> <pre><code>dict, err := client.Pronunciation().CreateFromJSON(ctx, \"Tech Terms\", \"terms.json\")\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"Created dictionary: %s\\n\", dict.ID)\n</code></pre>"},{"location":"guides/lms-courses/#3-select-your-voice","title":"3. Select Your Voice","text":"<pre><code>voices, _ := client.Voices().List(ctx)\n\n// Find a voice suitable for narration\nfor _, v := range voices {\n    fmt.Printf(\"%s: %s\\n\", v.VoiceID, v.Name)\n}\n\n// Popular choices for courses:\n// - Rachel (21m00Tcm4TlvDq8ikWAM): Calm, clear\n// - Antoni (ErXwobaYiN019PkySvjV): Professional, warm\n</code></pre>"},{"location":"guides/lms-courses/#4-generate-chapter-audio","title":"4. Generate Chapter Audio","text":"<pre><code>chapters := []struct {\n    Title   string\n    Script  string\n}{\n    {\n        Title:  \"01-introduction\",\n        Script: \"Welcome to this course on building APIs with Go...\",\n    },\n    {\n        Title:  \"02-setup\",\n        Script: \"In this chapter, we'll set up our development environment...\",\n    },\n}\n\nvoiceID := \"21m00Tcm4TlvDq8ikWAM\"\n\nfor _, ch := range chapters {\n    audio, err := client.TextToSpeech().Generate(ctx, &amp;elevenlabs.TTSRequest{\n        VoiceID: voiceID,\n        Text:    ch.Script,\n        ModelID: \"eleven_multilingual_v2\",\n        VoiceSettings: &amp;elevenlabs.VoiceSettings{\n            Stability:       0.6,  // Slightly more consistent for courses\n            SimilarityBoost: 0.75,\n        },\n    })\n    if err != nil {\n        log.Printf(\"Failed to generate %s: %v\", ch.Title, err)\n        continue\n    }\n\n    filename := fmt.Sprintf(\"%s.mp3\", ch.Title)\n    f, _ := os.Create(filename)\n    io.Copy(f, audio.Audio)\n    f.Close()\n\n    fmt.Printf(\"Generated: %s\\n\", filename)\n}\n</code></pre>"},{"location":"guides/lms-courses/#5-create-sound-effects-music","title":"5. Create Sound Effects &amp; Music","text":"<pre><code>// Intro jingle\nintro, _ := client.SoundEffects().Simple(ctx, \"professional podcast intro with subtle music\")\n\n// Chapter transition\ntransition, _ := client.SoundEffects().Simple(ctx, \"soft whoosh transition sound\")\n\n// Save them\nsaveAudio(intro, \"sfx-intro.mp3\")\nsaveAudio(transition, \"sfx-transition.mp3\")\n\n// Generate background music with the Music service\nbackground, _ := client.Music().Generate(ctx, &amp;elevenlabs.MusicRequest{\n    Prompt:            \"calm ambient background music for educational content\",\n    DurationMs:        300000, // 5 minutes\n    ForceInstrumental: true,\n})\nsaveAudio(background.Audio, \"background-music.mp3\")\n\n// For more control, use composition plans\nplan, _ := client.Music().GeneratePlan(ctx, &amp;elevenlabs.CompositionPlanRequest{\n    Prompt:     \"educational video intro music, friendly and professional\",\n    DurationMs: 10000, // 10 seconds\n})\nintroMusic, _ := client.Music().GenerateDetailed(ctx, &amp;elevenlabs.MusicDetailedRequest{\n    CompositionPlan:   plan,\n    ForceInstrumental: true,\n})\nsaveAudio(introMusic.Audio, \"intro-music.mp3\")\n</code></pre>"},{"location":"guides/lms-courses/#6-using-projects-for-long-form-content","title":"6. Using Projects for Long-Form Content","text":"<p>For complete courses, use the Projects/Studio feature:</p> <pre><code>// Create project\nproject, err := client.Projects().Create(ctx, &amp;elevenlabs.CreateProjectRequest{\n    Name:                    \"Go API Development Course\",\n    Description:             \"Complete guide to building REST APIs in Go\",\n    Language:                \"en\",\n    DefaultModelID:          \"eleven_multilingual_v2\",\n    DefaultParagraphVoiceID: \"21m00Tcm4TlvDq8ikWAM\",\n    DefaultTitleVoiceID:     \"21m00Tcm4TlvDq8ikWAM\",\n    QualityPreset:           \"high\",\n})\n\n// Chapters are added via web UI or content upload\n// Then convert:\nerr = client.Projects().Convert(ctx, project.ProjectID)\n\n// Download when complete\nsnapshots, _ := client.Projects().ListSnapshots(ctx, project.ProjectID)\nif len(snapshots) &gt; 0 {\n    reader, _ := client.Projects().DownloadSnapshotArchive(ctx,\n        project.ProjectID, snapshots[0].ProjectSnapshotID)\n\n    f, _ := os.Create(\"course.zip\")\n    io.Copy(f, reader)\n    f.Close()\n}\n</code></pre>"},{"location":"guides/lms-courses/#7-translate-to-other-languages","title":"7. Translate to Other Languages","text":"<pre><code>// Dub English course to Spanish\ndub, err := client.Dubbing().Create(ctx, &amp;elevenlabs.DubbingRequest{\n    SourceURL:      \"https://storage.example.com/course-intro.mp4\",\n    TargetLanguage: \"es\",\n    Name:           \"Go API Course - Spanish\",\n})\n\n// Wait for completion, then download\n// ...\n</code></pre>"},{"location":"guides/lms-courses/#best-practices","title":"Best Practices","text":""},{"location":"guides/lms-courses/#script-writing","title":"Script Writing","text":"<ol> <li>Write for audio - Use conversational language</li> <li>Spell out acronyms in pronunciation dictionary</li> <li>Add pauses with punctuation (periods, commas)</li> <li>Keep sentences short - Easier to follow</li> </ol>"},{"location":"guides/lms-courses/#voice-settings-for-courses","title":"Voice Settings for Courses","text":"<pre><code>// Recommended settings for educational content\nsettings := &amp;elevenlabs.VoiceSettings{\n    Stability:       0.6,   // More consistent delivery\n    SimilarityBoost: 0.75,  // Natural sound\n    Style:           0.1,   // Minimal style (clearer)\n    SpeakerBoost:    true,  // Enhanced clarity\n}\n</code></pre>"},{"location":"guides/lms-courses/#quality-presets","title":"Quality Presets","text":"Content Type Recommended Preset Preview/Draft <code>standard</code> Final Course <code>high</code> or <code>ultra</code> Podcast <code>high</code> Audiobook <code>ultra</code>"},{"location":"guides/lms-courses/#cost-optimization","title":"Cost Optimization","text":"<pre><code>// Check before generating\nsub, _ := client.User().GetSubscription(ctx)\nscriptLength := len(script)\n\nif sub.CharactersRemaining() &lt; scriptLength {\n    log.Fatal(\"Insufficient characters\")\n}\n\n// For drafts, use shorter clips\n// Only generate full audio for final version\n</code></pre>"},{"location":"guides/lms-courses/#complete-example","title":"Complete Example","text":"<p>See the examples directory for complete working examples.</p> <pre><code>// Full course generation workflow\nfunc generateCourse(client *elevenlabs.Client, courseName string, chapters []Chapter) error {\n    ctx := context.Background()\n\n    // 1. Create pronunciation dictionary\n    dict, err := client.Pronunciation().CreateFromJSON(ctx, courseName+\" Terms\", \"terms.json\")\n    if err != nil {\n        return err\n    }\n    log.Printf(\"Dictionary: %s\", dict.ID)\n\n    // 2. Generate intro sound effect\n    intro, _ := client.SoundEffects().Simple(ctx, \"professional course intro\")\n    saveAudio(intro, \"course-intro.mp3\")\n\n    // 3. Generate each chapter\n    for i, ch := range chapters {\n        log.Printf(\"Generating chapter %d: %s\", i+1, ch.Title)\n\n        audio, err := client.TextToSpeech().Simple(ctx, voiceID, ch.Script)\n        if err != nil {\n            return fmt.Errorf(\"chapter %d: %w\", i+1, err)\n        }\n\n        filename := fmt.Sprintf(\"chapter-%02d.mp3\", i+1)\n        saveAudio(audio, filename)\n    }\n\n    log.Println(\"Course generation complete!\")\n    return nil\n}\n</code></pre>"},{"location":"guides/pronunciation-rules/","title":"Pronunciation Rules Guide","text":"<p>A complete guide to managing pronunciation dictionaries for correct term pronunciation.</p>"},{"location":"guides/pronunciation-rules/#why-pronunciation-rules","title":"Why Pronunciation Rules?","text":"<p>Text-to-Speech engines may mispronounce:</p> Term Without Rules With Rules API \"appy\" \"A P I\" SQL \"squeal\" \"sequel\" nginx \"ningks\" \"engine X\" kubectl \"kub-cuttle\" \"kube control\" OAuth \"oh-ath\" \"oh auth\""},{"location":"guides/pronunciation-rules/#json-based-workflow","title":"JSON-Based Workflow","text":""},{"location":"guides/pronunciation-rules/#1-create-a-rules-file","title":"1. Create a Rules File","text":"<p><code>pronunciation-rules.json</code>:</p> <pre><code>[\n  {\"grapheme\": \"API\", \"alias\": \"A P I\"},\n  {\"grapheme\": \"SDK\", \"alias\": \"S D K\"},\n  {\"grapheme\": \"CLI\", \"alias\": \"C L I\"},\n  {\"grapheme\": \"GUI\", \"alias\": \"gooey\"},\n  {\"grapheme\": \"SQL\", \"alias\": \"sequel\"},\n  {\"grapheme\": \"OAuth\", \"alias\": \"oh auth\"},\n  {\"grapheme\": \"JSON\", \"alias\": \"jay son\"},\n  {\"grapheme\": \"YAML\", \"alias\": \"yammel\"},\n  {\"grapheme\": \"nginx\", \"alias\": \"engine X\"},\n  {\"grapheme\": \"kubectl\", \"alias\": \"kube control\"},\n  {\"grapheme\": \"etcd\", \"alias\": \"et see dee\"},\n  {\"grapheme\": \"gRPC\", \"alias\": \"gee R P C\"}\n]\n</code></pre>"},{"location":"guides/pronunciation-rules/#2-load-and-create-dictionary","title":"2. Load and Create Dictionary","text":"<pre><code>dict, err := client.Pronunciation().CreateFromJSON(ctx,\n    \"Tech Terms\",\n    \"pronunciation-rules.json\")\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Created dictionary %s with %d rules\\n\", dict.ID, dict.RulesCount)\n</code></pre>"},{"location":"guides/pronunciation-rules/#rule-types","title":"Rule Types","text":""},{"location":"guides/pronunciation-rules/#alias-recommended","title":"Alias (Recommended)","text":"<p>Simple text substitution - the easiest approach:</p> <pre><code>{\"grapheme\": \"API\", \"alias\": \"A P I\"}\n</code></pre> <p>The text \"API\" will be replaced with \"A P I\" before TTS processing.</p> <p>Tips for aliases:</p> <ul> <li>Space out letters: <code>\"API\"</code> \u2192 <code>\"A P I\"</code></li> <li>Use phonetic spelling: <code>\"nginx\"</code> \u2192 <code>\"engine X\"</code></li> <li>Break compound words: <code>\"OAuth\"</code> \u2192 <code>\"oh auth\"</code></li> </ul>"},{"location":"guides/pronunciation-rules/#phoneme-advanced","title":"Phoneme (Advanced)","text":"<p>Use IPA (International Phonetic Alphabet) for precise control:</p> <pre><code>{\"grapheme\": \"nginx\", \"phoneme\": \"\u02c8\u025bnd\u0292\u026an\u02c8\u025bks\"}\n</code></pre> <p>When to use phonemes:</p> <ul> <li>When aliases don't produce correct pronunciation</li> <li>For names with unusual pronunciation</li> <li>For non-English words</li> </ul>"},{"location":"guides/pronunciation-rules/#working-with-rules-in-go","title":"Working with Rules in Go","text":""},{"location":"guides/pronunciation-rules/#create-from-map","title":"Create from Map","text":"<pre><code>rules := elevenlabs.RulesFromMap(map[string]string{\n    \"API\":     \"A P I\",\n    \"kubectl\": \"kube control\",\n})\n\ndict, err := client.Pronunciation().Create(ctx, &amp;elevenlabs.CreatePronunciationDictionaryRequest{\n    Name:  \"Quick Terms\",\n    Rules: rules,\n})\n</code></pre>"},{"location":"guides/pronunciation-rules/#load-from-json-file","title":"Load from JSON File","text":"<pre><code>rules, err := elevenlabs.LoadRulesFromJSON(\"terms.json\")\nif err != nil {\n    log.Fatal(err)\n}\n\n// View rules\nfmt.Println(rules.String())\n// Output:\n// API \u2192 A P I\n// kubectl \u2192 kube control\n</code></pre>"},{"location":"guides/pronunciation-rules/#parse-from-json-string","title":"Parse from JSON String","text":"<pre><code>jsonData := `[\n    {\"grapheme\": \"API\", \"alias\": \"A P I\"},\n    {\"grapheme\": \"SDK\", \"alias\": \"S D K\"}\n]`\n\nrules, err := elevenlabs.ParseRulesFromJSON([]byte(jsonData))\n</code></pre>"},{"location":"guides/pronunciation-rules/#generate-pls-xml","title":"Generate PLS XML","text":"<pre><code>rules := elevenlabs.PronunciationRules{\n    {Grapheme: \"API\", Alias: \"A P I\"},\n}\n\n// Get XML string\nxml, err := rules.ToPLSString(\"en-US\")\nfmt.Println(xml)\n\n// Save to file\nerr = rules.SavePLS(\"terms.pls\", \"en-US\")\n</code></pre> <p>Generated PLS:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;lexicon version=\"1.0\"\n         xmlns=\"http://www.w3.org/2005/01/pronunciation-lexicon\"\n         alphabet=\"ipa\" xml:lang=\"en-US\"&gt;\n  &lt;lexeme&gt;\n    &lt;grapheme&gt;API&lt;/grapheme&gt;\n    &lt;alias&gt;A P I&lt;/alias&gt;\n  &lt;/lexeme&gt;\n&lt;/lexicon&gt;\n</code></pre>"},{"location":"guides/pronunciation-rules/#managing-dictionaries","title":"Managing Dictionaries","text":""},{"location":"guides/pronunciation-rules/#list-all-dictionaries","title":"List All Dictionaries","text":"<pre><code>resp, err := client.Pronunciation().List(ctx, nil)\nfor _, d := range resp.Dictionaries {\n    fmt.Printf(\"%s: %s (%d rules)\\n\", d.ID, d.Name, d.RulesCount)\n}\n</code></pre>"},{"location":"guides/pronunciation-rules/#update-a-dictionary","title":"Update a Dictionary","text":"<p>To add new rules, create a new dictionary version (append to your JSON, re-upload).</p>"},{"location":"guides/pronunciation-rules/#remove-specific-rules","title":"Remove Specific Rules","text":"<pre><code>err := client.Pronunciation().RemoveRules(ctx, dictID, []string{\"API\", \"SDK\"})\n</code></pre>"},{"location":"guides/pronunciation-rules/#rename-dictionary","title":"Rename Dictionary","text":"<pre><code>err := client.Pronunciation().Rename(ctx, dictID, \"New Name\")\n</code></pre>"},{"location":"guides/pronunciation-rules/#archive-dictionary","title":"Archive Dictionary","text":"<pre><code>err := client.Pronunciation().Archive(ctx, dictID)\n</code></pre>"},{"location":"guides/pronunciation-rules/#download-pls-file","title":"Download PLS File","text":"<p>Export the dictionary as a PLS (Pronunciation Lexicon Specification) XML file:</p> <pre><code>// Download latest version\npls, err := client.Pronunciation().DownloadLatestPLS(ctx, dictID)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Save to file\nf, _ := os.Create(\"dictionary.pls\")\nio.Copy(f, pls)\nf.Close()\n\n// Or download a specific version\npls, err := client.Pronunciation().GetVersionPLS(ctx, dictID, versionID)\n</code></pre>"},{"location":"guides/pronunciation-rules/#domain-specific-examples","title":"Domain-Specific Examples","text":""},{"location":"guides/pronunciation-rules/#software-development","title":"Software Development","text":"<pre><code>[\n  {\"grapheme\": \"API\", \"alias\": \"A P I\"},\n  {\"grapheme\": \"REST\", \"alias\": \"rest\"},\n  {\"grapheme\": \"GraphQL\", \"alias\": \"graph Q L\"},\n  {\"grapheme\": \"npm\", \"alias\": \"N P M\"},\n  {\"grapheme\": \"pip\", \"alias\": \"pip\"},\n  {\"grapheme\": \"git\", \"alias\": \"git\"},\n  {\"grapheme\": \"GitHub\", \"alias\": \"git hub\"},\n  {\"grapheme\": \"VS Code\", \"alias\": \"V S code\"}\n]\n</code></pre>"},{"location":"guides/pronunciation-rules/#clouddevops","title":"Cloud/DevOps","text":"<pre><code>[\n  {\"grapheme\": \"AWS\", \"alias\": \"A W S\"},\n  {\"grapheme\": \"GCP\", \"alias\": \"G C P\"},\n  {\"grapheme\": \"Azure\", \"alias\": \"azher\"},\n  {\"grapheme\": \"K8s\", \"alias\": \"kubernetes\"},\n  {\"grapheme\": \"CI/CD\", \"alias\": \"C I C D\"},\n  {\"grapheme\": \"DevOps\", \"alias\": \"dev ops\"},\n  {\"grapheme\": \"IaC\", \"alias\": \"I A C\"}\n]\n</code></pre>"},{"location":"guides/pronunciation-rules/#data-science","title":"Data Science","text":"<pre><code>[\n  {\"grapheme\": \"ML\", \"alias\": \"M L\"},\n  {\"grapheme\": \"AI\", \"alias\": \"A I\"},\n  {\"grapheme\": \"NLP\", \"alias\": \"N L P\"},\n  {\"grapheme\": \"GPU\", \"alias\": \"G P U\"},\n  {\"grapheme\": \"TPU\", \"alias\": \"T P U\"},\n  {\"grapheme\": \"PyTorch\", \"alias\": \"pie torch\"},\n  {\"grapheme\": \"TensorFlow\", \"alias\": \"tensor flow\"},\n  {\"grapheme\": \"NumPy\", \"alias\": \"num pie\"}\n]\n</code></pre>"},{"location":"guides/pronunciation-rules/#best-practices","title":"Best Practices","text":"<ol> <li>Version control your JSON - Track changes over time</li> <li>Test pronunciations - Generate sample audio to verify</li> <li>Document unusual rules - Add comments explaining why</li> <li>Organize by domain - Separate dictionaries for different topics</li> <li>Use aliases first - Only use phonemes when necessary</li> <li>Consider context - Same acronym may have different pronunciations</li> </ol>"},{"location":"guides/ttsscript/","title":"TTS Script Authoring","text":"<p>A guide to authoring multilingual TTS scripts using the <code>ttsscript</code> package.</p>"},{"location":"guides/ttsscript/#why-use-ttsscript","title":"Why Use ttsscript?","text":"<p>Instead of storing raw SSML (which is engine-specific and hard to edit), author your scripts in a structured JSON format that:</p> <ul> <li>Supports multiple languages in a single file</li> <li>Handles pronunciations separately from content</li> <li>Can be compiled to any TTS engine format</li> <li>Is easy to edit and version control</li> </ul>"},{"location":"guides/ttsscript/#quick-start","title":"Quick Start","text":""},{"location":"guides/ttsscript/#1-create-a-script-json-file","title":"1. Create a Script JSON File","text":"<pre><code>{\n  \"title\": \"My Course\",\n  \"default_voices\": {\n    \"en\": \"21m00Tcm4TlvDq8ikWAM\",\n    \"es\": \"EXAVITQu4vr4xnSDxMaL\"\n  },\n  \"pronunciations\": {\n    \"API\": {\"en\": \"A P I\", \"es\": \"A P I\"},\n    \"SDK\": {\"en\": \"S D K\", \"es\": \"S D K\"}\n  },\n  \"slides\": [\n    {\n      \"title\": \"Introduction\",\n      \"segments\": [\n        {\n          \"text\": {\n            \"en\": \"Welcome to the API course.\",\n            \"es\": \"Bienvenidos al curso de API.\"\n          },\n          \"pause_after\": \"500ms\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"guides/ttsscript/#2-load-and-compile","title":"2. Load and Compile","text":"<pre><code>import \"github.com/agentplexus/go-elevenlabs/ttsscript\"\n\n// Load script\nscript, err := ttsscript.LoadScript(\"script.json\")\nif err != nil {\n    log.Fatal(err)\n}\n\n// Compile for English\ncompiler := ttsscript.NewCompiler()\nsegments, err := compiler.Compile(script, \"en\")\n</code></pre>"},{"location":"guides/ttsscript/#3-generate-audio","title":"3. Generate Audio","text":"<pre><code>import elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n\nclient, _ := elevenlabs.NewClient()\nformatter := ttsscript.NewElevenLabsFormatter()\njobs := formatter.Format(segments)\n\nfor _, job := range jobs {\n    audio, _ := client.TextToSpeech().Simple(ctx, job.VoiceID, job.Text)\n    // Save audio file...\n}\n</code></pre>"},{"location":"guides/ttsscript/#script-structure","title":"Script Structure","text":""},{"location":"guides/ttsscript/#top-level-fields","title":"Top-Level Fields","text":"Field Type Description <code>title</code> string Script title <code>description</code> string Optional description <code>default_language</code> string Primary language code <code>default_voices</code> map Voice IDs by language <code>pronunciations</code> map Global pronunciation rules <code>slides</code> array Ordered list of slides"},{"location":"guides/ttsscript/#slide-fields","title":"Slide Fields","text":"Field Type Description <code>title</code> string Slide title (for reference) <code>notes</code> string Speaker notes (not rendered) <code>segments</code> array Audio segments"},{"location":"guides/ttsscript/#segment-fields","title":"Segment Fields","text":"Field Type Description <code>text</code> map Text by language code <code>voice</code> map Voice override by language <code>pause_before</code> string Pause before (e.g., \"500ms\") <code>pause_after</code> string Pause after (e.g., \"1s\") <code>emphasis</code> string \"strong\", \"moderate\", \"reduced\" <code>rate</code> string \"slow\", \"medium\", \"fast\", or \"80%\" <code>pitch</code> string \"low\", \"medium\", \"high\", or \"+10%\" <code>pronunciations</code> map Segment-specific pronunciations"},{"location":"guides/ttsscript/#pronunciations","title":"Pronunciations","text":"<p>Pronunciations are applied automatically during compilation:</p> <pre><code>{\n  \"pronunciations\": {\n    \"API\": {\"en\": \"A P I\", \"es\": \"A P I\"},\n    \"kubectl\": {\"en\": \"kube control\"},\n    \"nginx\": {\"en\": \"engine X\"}\n  }\n}\n</code></pre>"},{"location":"guides/ttsscript/#priority-order","title":"Priority Order","text":"<ol> <li>Compiler-level - Added via <code>compiler.AddPronunciation()</code></li> <li>Segment-level - In <code>segment.pronunciations</code></li> <li>Script-level - In <code>script.pronunciations</code></li> </ol> <p>Higher priority overrides lower.</p>"},{"location":"guides/ttsscript/#add-pronunciations-at-runtime","title":"Add Pronunciations at Runtime","text":"<pre><code>compiler := ttsscript.NewCompiler()\ncompiler.AddPronunciation(\"goroutine\", \"en\", \"go routine\")\ncompiler.AddPronunciations(\"en\", map[string]string{\n    \"API\": \"A P I\",\n    \"SDK\": \"S D K\",\n})\n</code></pre>"},{"location":"guides/ttsscript/#output-formats","title":"Output Formats","text":""},{"location":"guides/ttsscript/#elevenlabs","title":"ElevenLabs","text":"<pre><code>formatter := ttsscript.NewElevenLabsFormatter()\njobs := formatter.Format(segments)\n\nfor _, job := range jobs {\n    fmt.Printf(\"Voice: %s\\n\", job.VoiceID)\n    fmt.Printf(\"Text: %s\\n\", job.Text)\n    fmt.Printf(\"Pause after: %dms\\n\", job.PauseAfterMs)\n}\n</code></pre>"},{"location":"guides/ttsscript/#ssml-google-amazon-azure","title":"SSML (Google, Amazon, Azure)","text":"<pre><code>formatter := ttsscript.NewSSMLFormatter()\nssml, err := formatter.FormatScript(script, \"en\")\n// Use with Google Cloud TTS, Amazon Polly, or Azure TTS\n</code></pre> <p>Example SSML output:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;speak version=\"1.1\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en\"&gt;\n  &lt;!-- Slide 1: Introduction --&gt;\n  Welcome to the A P I course.\n  &lt;break time=\"500ms\"/&gt;\n&lt;/speak&gt;\n</code></pre>"},{"location":"guides/ttsscript/#batch-processing","title":"Batch Processing","text":""},{"location":"guides/ttsscript/#generate-manifest","title":"Generate Manifest","text":"<pre><code>config := ttsscript.NewBatchConfig(\"./output\")\nconfig.IncludeLanguageInFilename = true\n\nmanifest := ttsscript.GenerateManifest(jobs, config, \"en\")\n// Returns []ManifestEntry with output filenames\n</code></pre>"},{"location":"guides/ttsscript/#group-by-voice","title":"Group by Voice","text":"<pre><code>groups := formatter.GroupByVoice(jobs)\nfor voiceID, voiceJobs := range groups {\n    // Process all jobs for this voice together\n}\n</code></pre>"},{"location":"guides/ttsscript/#multilingual-workflow","title":"Multilingual Workflow","text":""},{"location":"guides/ttsscript/#1-author-once","title":"1. Author Once","text":"<pre><code>{\n  \"slides\": [{\n    \"segments\": [{\n      \"text\": {\n        \"en\": \"Hello world\",\n        \"es\": \"Hola mundo\",\n        \"fr\": \"Bonjour le monde\"\n      }\n    }]\n  }]\n}\n</code></pre>"},{"location":"guides/ttsscript/#2-compile-for-each-language","title":"2. Compile for Each Language","text":"<pre><code>languages := script.Languages() // [\"en\", \"es\", \"fr\"]\n\nfor _, lang := range languages {\n    segments, _ := compiler.Compile(script, lang)\n    jobs := formatter.Format(segments)\n\n    // Generate audio for this language\n    for _, job := range jobs {\n        audio, _ := client.TextToSpeech().Simple(ctx, job.VoiceID, job.Text)\n        // Save with language suffix\n    }\n}\n</code></pre>"},{"location":"guides/ttsscript/#best-practices","title":"Best Practices","text":"<ol> <li>Version control your scripts - JSON is easy to diff and merge</li> <li>Separate pronunciations - Keep them in the script, not embedded in text</li> <li>Use meaningful slide titles - They appear in comments and manifests</li> <li>Test with one language first - Verify before generating all languages</li> <li>Use consistent pause durations - Create a style guide for your project</li> </ol>"},{"location":"guides/ttsscript/#integration-with-marp","title":"Integration with Marp","text":"<p>For presentations, you can embed TTS annotations in Marp comments:</p> <pre><code>---\nmarp: true\n---\n\n&lt;!--\ntts: Welcome to the presentation.\npause: 500ms\n--&gt;\n\n# Slide Title\n\nContent here...\n</code></pre> <p>Then parse and convert to ttsscript format for audio generation.</p>"},{"location":"releases/v0.1.0/","title":"v0.1.0","text":"<p>Release Date: December 2024</p> <p>Initial release of the ElevenLabs Go SDK.</p>"},{"location":"releases/v0.1.0/#highlights","title":"Highlights","text":"<p>This release provides a comprehensive Go SDK for the ElevenLabs API, built with AI assistance using Claude Opus 4.5 and Claude Code.</p>"},{"location":"releases/v0.1.0/#features","title":"Features","text":""},{"location":"releases/v0.1.0/#core-services","title":"Core Services","text":"<ul> <li>Text-to-Speech - Convert text to natural-sounding speech</li> <li>Simple and advanced generation methods</li> <li>Streaming audio support</li> <li>Timestamp generation for word-level alignment</li> <li> <p>Multiple output formats (MP3, PCM, \u03bc-law)</p> </li> <li> <p>Speech-to-Text - Transcribe audio files</p> </li> <li>File and URL transcription</li> <li> <p>Speaker diarization support</p> </li> <li> <p>Voices - Voice management</p> </li> <li>List, get, add, edit, delete voices</li> <li>Voice settings configuration</li> <li> <p>Default settings retrieval</p> </li> <li> <p>Models - Model information</p> </li> <li> <p>List available models</p> </li> <li> <p>History - Generation history</p> </li> <li>List, get, delete history items</li> <li> <p>Download generated audio</p> </li> <li> <p>User - Account information</p> </li> <li>Get user subscription and usage info</li> </ul>"},{"location":"releases/v0.1.0/#audio-processing","title":"Audio Processing","text":"<ul> <li>Sound Effects - Generate sound effects from text descriptions</li> <li>Audio Isolation - Extract vocals/speech from audio</li> <li>Forced Alignment - Get word-level timestamps</li> <li>Text-to-Dialogue - Generate multi-speaker conversations</li> </ul>"},{"location":"releases/v0.1.0/#content-management","title":"Content Management","text":"<ul> <li>Voice Design - Create custom AI voices</li> <li>Music - Generate music from text prompts</li> <li>Projects (Studio) - Long-form content management</li> <li>Pronunciation - Dictionary management for custom pronunciations</li> <li>Dubbing - Video/audio translation and dubbing</li> </ul>"},{"location":"releases/v0.1.0/#sdk-features","title":"SDK Features","text":"<ul> <li>Functional options pattern for client configuration</li> <li>Automatic API key from environment variable</li> <li>Comprehensive error handling with typed errors</li> <li>Rate limit detection helpers</li> </ul>"},{"location":"releases/v0.1.0/#utility-packages","title":"Utility Packages","text":"<ul> <li><code>ttsscript</code> - TTS script authoring for multilingual content</li> <li><code>voices</code> - Voice constants and metadata</li> </ul>"},{"location":"releases/v0.1.0/#documentation","title":"Documentation","text":"<ul> <li>Comprehensive README with examples</li> <li>MkDocs documentation site</li> <li>API coverage tracking</li> </ul>"},{"location":"releases/v0.1.0/#installation","title":"Installation","text":"<pre><code>go get github.com/grokify/go-elevenlabs\n</code></pre>"},{"location":"releases/v0.1.0/#example","title":"Example","text":"<pre><code>client, _ := elevenlabs.NewClient()\naudio, _ := client.TextToSpeech().Simple(ctx, voiceID, \"Hello world!\")\n</code></pre>"},{"location":"releases/v0.2.0/","title":"v0.2.0","text":"<p>Release Date: December 2024</p> <p>Repository transfer to AgentPlexus organization and documentation improvements.</p>"},{"location":"releases/v0.2.0/#highlights","title":"Highlights","text":"<p>This release transfers the SDK from <code>github.com/grokify/go-elevenlabs</code> to <code>github.com/agentplexus/go-elevenlabs</code> and adds comprehensive MkDocs documentation.</p>"},{"location":"releases/v0.2.0/#breaking-changes","title":"Breaking Changes","text":""},{"location":"releases/v0.2.0/#module-path-change","title":"Module Path Change","text":"<p>The Go module path has changed:</p> <pre><code>// Old import\nimport elevenlabs \"github.com/grokify/go-elevenlabs\"\n\n// New import\nimport elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n</code></pre>"},{"location":"releases/v0.2.0/#migration","title":"Migration","text":"<p>Update your <code>go.mod</code>:</p> <pre><code>go get github.com/agentplexus/go-elevenlabs@latest\n</code></pre> <p>Then update all import statements in your code.</p>"},{"location":"releases/v0.2.0/#changes","title":"Changes","text":""},{"location":"releases/v0.2.0/#repository-transfer","title":"Repository Transfer","text":"<ul> <li>Transferred from <code>grokify/go-elevenlabs</code> to <code>agentplexus/go-elevenlabs</code></li> <li>Updated all internal import paths</li> <li>Updated documentation links and references</li> </ul>"},{"location":"releases/v0.2.0/#documentation","title":"Documentation","text":"<ul> <li>MkDocs Site - Complete documentation site with Material theme</li> <li>28 documentation pages</li> <li>Getting Started guides</li> <li>Service documentation for all 15 services</li> <li>API reference and coverage tracking</li> <li> <p>Utility package documentation</p> </li> <li> <p>Guides Added</p> </li> <li>LMS/Udemy course production guide</li> <li>Pronunciation rules guide</li> <li>TTS script authoring guide</li> </ul>"},{"location":"releases/v0.2.0/#new-features","title":"New Features","text":"<ul> <li><code>cmd/ttsscript</code> - Command-line tool for TTS script processing</li> <li>Compile scripts to audio jobs</li> <li>Generate per-slide or concatenated output</li> <li>Support for multiple output formats</li> </ul>"},{"location":"releases/v0.2.0/#improvements","title":"Improvements","text":"<ul> <li>Enhanced API coverage documentation</li> <li>Added method-level coverage tracking</li> <li>Improved error messages</li> </ul>"},{"location":"releases/v0.2.0/#installation","title":"Installation","text":"<pre><code>go get github.com/agentplexus/go-elevenlabs\n</code></pre>"},{"location":"releases/v0.2.0/#documentation_1","title":"Documentation","text":"<ul> <li>Site: agentplexus.github.io/go-elevenlabs</li> <li>GoDoc: pkg.go.dev/github.com/agentplexus/go-elevenlabs</li> </ul>"},{"location":"releases/v0.3.0/","title":"v0.3.0","text":"<p>Release Date: December 2024</p> <p>Real-time streaming services and phone integration for voice agents.</p>"},{"location":"releases/v0.3.0/#highlights","title":"Highlights","text":"<p>This release adds real-time WebSocket services and Twilio phone integration, enabling the SDK to power conversational AI voice agents.</p>"},{"location":"releases/v0.3.0/#new-services","title":"New Services","text":""},{"location":"releases/v0.3.0/#websocket-tts-real-time-text-to-speech","title":"WebSocket TTS (Real-Time Text-to-Speech)","text":"<p>Low-latency streaming text-to-speech via WebSocket, ideal for LLM integration.</p> <pre><code>conn, _ := client.WebSocketTTS().Connect(ctx, voiceID, &amp;elevenlabs.WebSocketTTSOptions{\n    ModelID:                  \"eleven_turbo_v2_5\",\n    OutputFormat:             \"pcm_16000\",\n    OptimizeStreamingLatency: 3,\n})\ndefer conn.Close()\n\n// Stream text from LLM\nfor text := range llmOutput {\n    conn.SendText(text)\n}\nconn.Flush()\n\n// Receive audio chunks\nfor audio := range conn.Audio() {\n    player.Write(audio)\n}\n</code></pre> <p>Features: - Stream text as it arrives (perfect for LLM output) - Configurable latency optimization (0-4) - Word-level alignment timestamps - SSML parsing support - Multiple output formats (PCM recommended for real-time)</p>"},{"location":"releases/v0.3.0/#websocket-stt-real-time-speech-to-text","title":"WebSocket STT (Real-Time Speech-to-Text)","text":"<p>Live audio transcription via WebSocket with partial results.</p> <pre><code>conn, _ := client.WebSocketSTT().Connect(ctx, &amp;elevenlabs.WebSocketSTTOptions{\n    SampleRate:           16000,\n    EnablePartials:       true,\n    EnableWordTimestamps: true,\n})\ndefer conn.Close()\n\n// Send audio from microphone\ngo func() {\n    for chunk := range micInput {\n        conn.SendAudio(chunk)\n    }\n    conn.EndStream()\n}()\n\n// Receive transcripts\nfor transcript := range conn.Transcripts() {\n    if transcript.IsFinal {\n        fmt.Println(\"Final:\", transcript.Text)\n    }\n}\n</code></pre> <p>Features: - Partial (interim) results for responsive UIs - Word-level timing with confidence scores - Automatic language detection - Multiple audio encodings (PCM, \u03bc-law)</p>"},{"location":"releases/v0.3.0/#speech-to-speech-voice-conversion","title":"Speech-to-Speech (Voice Conversion)","text":"<p>Transform speech from one voice to another while preserving content.</p> <pre><code>resp, _ := client.SpeechToSpeech().Convert(ctx, &amp;elevenlabs.SpeechToSpeechRequest{\n    VoiceID:               targetVoiceID,\n    Audio:                 sourceAudio,\n    RemoveBackgroundNoise: true,\n})\n\n// Simple one-liner\naudio, _ := client.SpeechToSpeech().Simple(ctx, voiceID, audioReader)\n</code></pre> <p>Features: - Voice conversion with content preservation - Background noise removal - Streaming conversion support - Seed audio for consistent style</p>"},{"location":"releases/v0.3.0/#twilio-integration","title":"Twilio Integration","text":"<p>Phone call integration for conversational AI agents.</p> <pre><code>// Register incoming call\nresp, _ := client.Twilio().RegisterCall(ctx, &amp;elevenlabs.TwilioRegisterCallRequest{\n    AgentID: \"your-agent-id\",\n    DynamicVariables: map[string]string{\n        \"caller_name\": callerInfo.Name,\n    },\n})\n// Return resp.TwiML to Twilio\n\n// Make outbound call\ncall, _ := client.Twilio().OutboundCall(ctx, &amp;elevenlabs.TwilioOutboundCallRequest{\n    AgentID:            \"your-agent-id\",\n    AgentPhoneNumberID: \"phone-number-id\",\n    ToNumber:           \"+1234567890\",\n})\n</code></pre> <p>Features: - Incoming call registration with TwiML response - Outbound calls via Twilio - SIP trunk integration - Dynamic variables for prompt injection - First message and system prompt overrides</p>"},{"location":"releases/v0.3.0/#phone-number-management","title":"Phone Number Management","text":"<p>Manage phone numbers for voice agents.</p> <pre><code>numbers, _ := client.PhoneNumbers().List(ctx)\nnumber, _ := client.PhoneNumbers().Get(ctx, phoneID)\nupdated, _ := client.PhoneNumbers().Update(ctx, phoneID, &amp;elevenlabs.UpdatePhoneNumberRequest{\n    Label:   \"Support Line\",\n    AgentID: agentID,\n})\n_ = client.PhoneNumbers().Delete(ctx, phoneID)\n</code></pre>"},{"location":"releases/v0.3.0/#new-dependencies","title":"New Dependencies","text":"<ul> <li><code>github.com/gorilla/websocket v1.5.3</code> - WebSocket support</li> </ul>"},{"location":"releases/v0.3.0/#documentation","title":"Documentation","text":"<ul> <li>4 new service documentation pages</li> <li>Updated API coverage (now ~75 methods covered)</li> <li>New \"Real-Time\" section in documentation navigation</li> <li>Updated README with real-time service examples</li> </ul>"},{"location":"releases/v0.3.0/#api-coverage-update","title":"API Coverage Update","text":"Category Status WebSocket TTS \u2713 Full WebSocket STT \u2713 Full Speech-to-Speech \u2713 Full Phone/Twilio \u2713 Partial (7 methods)"},{"location":"releases/v0.3.0/#use-cases","title":"Use Cases","text":"<p>This release enables building:</p> <ul> <li>Voice Agents - Conversational AI with real-time TTS/STT</li> <li>Phone Bots - Automated phone call handling</li> <li>LLM Voice Apps - Stream LLM output directly to speech</li> <li>Live Transcription - Real-time audio transcription</li> <li>Voice Changers - Real-time voice conversion</li> </ul>"},{"location":"releases/v0.3.0/#installation","title":"Installation","text":"<pre><code>go get github.com/agentplexus/go-elevenlabs@v0.3.0\n</code></pre>"},{"location":"releases/v0.3.0/#upgrade-notes","title":"Upgrade Notes","text":"<p>This release is backward compatible. No changes required for existing code.</p> <p>New features require the <code>gorilla/websocket</code> dependency which is automatically installed.</p>"},{"location":"services/audio-isolation/","title":"Audio Isolation","text":"<p>Extract vocals and speech from audio, removing background noise and music.</p>"},{"location":"services/audio-isolation/#basic-usage","title":"Basic Usage","text":"<pre><code>file, _ := os.Open(\"mixed_audio.mp3\")\ndefer file.Close()\n\nisolated, err := client.AudioIsolation().IsolateFile(ctx, file, \"mixed_audio.mp3\")\nif err != nil {\n    log.Fatal(err)\n}\n\n// Save isolated vocals\noutput, _ := os.Create(\"vocals_only.mp3\")\nio.Copy(output, isolated)\n</code></pre>"},{"location":"services/audio-isolation/#streaming-isolation","title":"Streaming Isolation","text":"<p>For real-time processing:</p> <pre><code>isolated, err := client.AudioIsolation().IsolateStream(ctx, &amp;elevenlabs.AudioIsolationRequest{\n    Audio:    audioReader,\n    Filename: \"audio.mp3\",\n})\n</code></pre>"},{"location":"services/audio-isolation/#full-options","title":"Full Options","text":"<pre><code>isolated, err := client.AudioIsolation().Isolate(ctx, &amp;elevenlabs.AudioIsolationRequest{\n    Audio:    audioFile,\n    Filename: \"podcast_with_music.mp3\",\n})\n</code></pre>"},{"location":"services/audio-isolation/#use-cases","title":"Use Cases","text":""},{"location":"services/audio-isolation/#podcast-cleanup","title":"Podcast Cleanup","text":"<p>Remove background music and enhance speech clarity:</p> <pre><code>// Original podcast has background music\npodcastFile, _ := os.Open(\"podcast_episode.mp3\")\n\n// Extract just the voices\ncleanAudio, err := client.AudioIsolation().IsolateFile(ctx,\n    podcastFile, \"podcast_episode.mp3\")\n\n// Save clean version\noutput, _ := os.Create(\"podcast_clean.mp3\")\nio.Copy(output, cleanAudio)\n</code></pre>"},{"location":"services/audio-isolation/#interview-processing","title":"Interview Processing","text":"<p>Extract speech from noisy interview recordings:</p> <pre><code>// Field interview with ambient noise\ninterviewFile, _ := os.Open(\"street_interview.mp3\")\n\n// Isolate speaker voices\nvoices, err := client.AudioIsolation().IsolateFile(ctx,\n    interviewFile, \"street_interview.mp3\")\n\n// Use clean audio for transcription\nresult, _ := client.SpeechToText().Transcribe(ctx, &amp;elevenlabs.TranscriptionRequest{\n    File:     voices,\n    Filename: \"clean_interview.mp3\",\n})\n</code></pre>"},{"location":"services/audio-isolation/#music-vocal-extraction","title":"Music Vocal Extraction","text":"<p>Extract vocals from songs:</p> <pre><code>songFile, _ := os.Open(\"song.mp3\")\n\nvocals, err := client.AudioIsolation().IsolateFile(ctx, songFile, \"song.mp3\")\n\n// Save isolated vocals\nvocalFile, _ := os.Create(\"vocals.mp3\")\nio.Copy(vocalFile, vocals)\n</code></pre>"},{"location":"services/audio-isolation/#video-audio-cleanup","title":"Video Audio Cleanup","text":"<p>Clean up audio tracks from video:</p> <pre><code>// Extract audio from video (using ffmpeg externally)\n// ffmpeg -i video.mp4 -vn audio.mp3\n\naudioFile, _ := os.Open(\"audio.mp3\")\n\ncleanAudio, err := client.AudioIsolation().IsolateFile(ctx, audioFile, \"audio.mp3\")\n\n// Save and remix back into video\ncleanFile, _ := os.Create(\"clean_audio.mp3\")\nio.Copy(cleanFile, cleanAudio)\n</code></pre>"},{"location":"services/audio-isolation/#pre-processing-for-voice-cloning","title":"Pre-processing for Voice Cloning","text":"<p>Get clean voice samples for cloning:</p> <pre><code>// Sample may have background noise\nsampleFile, _ := os.Open(\"voice_sample.mp3\")\n\n// Clean it up\ncleanSample, err := client.AudioIsolation().IsolateFile(ctx,\n    sampleFile, \"voice_sample.mp3\")\n\n// Use clean sample for voice training\n// (Professional Voice Cloning API)\n</code></pre>"},{"location":"services/audio-isolation/#pipeline-example","title":"Pipeline Example","text":"<p>Combine with other services:</p> <pre><code>// 1. Isolate vocals from noisy audio\nfile, _ := os.Open(\"noisy_recording.mp3\")\nclean, _ := client.AudioIsolation().IsolateFile(ctx, file, \"noisy_recording.mp3\")\n\n// 2. Save to temp file for transcription\ntmpFile, _ := os.CreateTemp(\"\", \"clean-*.mp3\")\nio.Copy(tmpFile, clean)\ntmpFile.Seek(0, 0)\n\n// 3. Transcribe the clean audio\ntranscript, _ := client.SpeechToText().Transcribe(ctx, &amp;elevenlabs.TranscriptionRequest{\n    File:     tmpFile,\n    Filename: \"clean.mp3\",\n})\n\n// 4. Get word-level timestamps\ntmpFile.Seek(0, 0)\nalignment, _ := client.ForcedAlignment().AlignFile(ctx, tmpFile, \"clean.mp3\", transcript.Text)\n</code></pre>"},{"location":"services/audio-isolation/#supported-audio-formats","title":"Supported Audio Formats","text":"<ul> <li>MP3</li> <li>WAV</li> <li>M4A</li> <li>FLAC</li> <li>OGG</li> <li>WEBM</li> </ul>"},{"location":"services/audio-isolation/#best-practices","title":"Best Practices","text":"<ol> <li>Use for noisy recordings - Most effective when there's clear separation between voice and background</li> <li>Chain with transcription - Clean audio produces better transcription results</li> <li>Save original files - Keep originals as isolation is lossy</li> <li>Test on samples first - Results vary based on audio content</li> </ol>"},{"location":"services/dubbing/","title":"Dubbing","text":"<p>Translate and dub audio/video content into other languages while preserving the original speaker's voice characteristics.</p>"},{"location":"services/dubbing/#creating-a-dub","title":"Creating a Dub","text":""},{"location":"services/dubbing/#from-url","title":"From URL","text":"<pre><code>dub, err := client.Dubbing().Create(ctx, &amp;elevenlabs.DubbingRequest{\n    SourceURL:      \"https://example.com/video.mp4\",\n    TargetLanguage: \"es\",  // Spanish\n    Name:           \"My Video - Spanish\",\n})\n</code></pre>"},{"location":"services/dubbing/#request-options","title":"Request Options","text":"Option Description <code>SourceURL</code> URL to video/audio file <code>TargetLanguage</code> Target language code <code>Name</code> Name for the dubbing project <code>SourceLanguage</code> Source language (auto-detected if not set) <code>NumSpeakers</code> Number of speakers (auto-detected if not set) <code>Watermark</code> Add watermark to output <code>StartTime</code> Start time in seconds <code>EndTime</code> End time in seconds"},{"location":"services/dubbing/#checking-status","title":"Checking Status","text":"<pre><code>status, err := client.Dubbing().GetStatus(ctx, dubbingID)\n\nfmt.Printf(\"Status: %s\\n\", status.Status)\nfmt.Printf(\"Target Languages: %v\\n\", status.TargetLanguages)\n</code></pre>"},{"location":"services/dubbing/#dubbing-status-values","title":"Dubbing Status Values","text":"Status Description <code>dubbing</code> In progress <code>dubbed</code> Complete <code>failed</code> Failed"},{"location":"services/dubbing/#downloading-dubbed-audio","title":"Downloading Dubbed Audio","text":"<pre><code>audio, err := client.Dubbing().GetDubbedFile(ctx, dubbingID, \"es\")\nif err != nil {\n    log.Fatal(err)\n}\n\nf, _ := os.Create(\"dubbed_spanish.mp4\")\ndefer f.Close()\nio.Copy(f, audio)\n</code></pre>"},{"location":"services/dubbing/#deleting-a-dub","title":"Deleting a Dub","text":"<pre><code>err := client.Dubbing().Delete(ctx, dubbingID)\n</code></pre>"},{"location":"services/dubbing/#supported-languages","title":"Supported Languages","text":"<p>Common language codes:</p> Code Language <code>en</code> English <code>es</code> Spanish <code>fr</code> French <code>de</code> German <code>it</code> Italian <code>pt</code> Portuguese <code>pl</code> Polish <code>hi</code> Hindi <code>ja</code> Japanese <code>ko</code> Korean <code>zh</code> Chinese"},{"location":"services/dubbing/#workflow-example","title":"Workflow Example","text":"<pre><code>// 1. Create dubbing job\ndub, err := client.Dubbing().Create(ctx, &amp;elevenlabs.DubbingRequest{\n    SourceURL:      \"https://example.com/course-intro.mp4\",\n    TargetLanguage: \"es\",\n    Name:           \"Course Intro - Spanish\",\n})\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Dubbing ID: %s\\n\", dub.DubbingID)\n\n// 2. Poll for completion\nfor {\n    status, _ := client.Dubbing().GetStatus(ctx, dub.DubbingID)\n\n    if status.Status == \"dubbed\" {\n        fmt.Println(\"Dubbing complete!\")\n        break\n    } else if status.Status == \"failed\" {\n        log.Fatal(\"Dubbing failed\")\n    }\n\n    fmt.Printf(\"Status: %s, waiting...\\n\", status.Status)\n    time.Sleep(30 * time.Second)\n}\n\n// 3. Download dubbed file\naudio, _ := client.Dubbing().GetDubbedFile(ctx, dub.DubbingID, \"es\")\nf, _ := os.Create(\"intro_spanish.mp4\")\nio.Copy(f, audio)\nf.Close()\n</code></pre>"},{"location":"services/dubbing/#best-practices","title":"Best Practices","text":"<ol> <li>Check source quality - Better input = better output</li> <li>Specify speaker count - Helps with voice separation</li> <li>Review output - AI dubbing may need manual review</li> <li>Consider cultural context - Some content may need localization beyond translation</li> </ol>"},{"location":"services/forced-alignment/","title":"Forced Alignment","text":"<p>Get precise word-level and character-level timestamps for audio when you already have the transcript.</p>"},{"location":"services/forced-alignment/#basic-usage","title":"Basic Usage","text":"<pre><code>file, _ := os.Open(\"speech.mp3\")\ndefer file.Close()\n\nresult, err := client.ForcedAlignment().AlignFile(ctx, file, \"speech.mp3\",\n    \"The text that was spoken in the audio\")\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, word := range result.Words {\n    fmt.Printf(\"%s: %.2fs - %.2fs\\n\", word.Text, word.Start, word.End)\n}\n</code></pre>"},{"location":"services/forced-alignment/#full-options","title":"Full Options","text":"<pre><code>result, err := client.ForcedAlignment().Align(ctx, &amp;elevenlabs.ForcedAlignmentRequest{\n    File:     audioFile,\n    Filename: \"narration.mp3\",\n    Text:     \"The complete transcript of the audio file\",\n})\n</code></pre>"},{"location":"services/forced-alignment/#response-structure","title":"Response Structure","text":"<pre><code>type ForcedAlignmentResponse struct {\n    Loss       float64              // Overall alignment loss/confidence\n    Words      []AlignmentWord      // Word-level timestamps\n    Characters []AlignmentCharacter // Character-level timestamps\n}\n\ntype AlignmentWord struct {\n    Text  string  // The word\n    Start float64 // Start time in seconds\n    End   float64 // End time in seconds\n    Loss  float64 // Alignment confidence for this word\n}\n\ntype AlignmentCharacter struct {\n    Text  string  // The character\n    Start float64 // Start time in seconds\n    End   float64 // End time in seconds\n}\n</code></pre>"},{"location":"services/forced-alignment/#use-cases","title":"Use Cases","text":""},{"location":"services/forced-alignment/#karaoke-style-subtitles","title":"Karaoke-Style Subtitles","text":"<pre><code>result, err := client.ForcedAlignment().AlignFile(ctx, audioFile, \"song.mp3\", lyrics)\n\n// Highlight words as they're spoken\nfor _, word := range result.Words {\n    fmt.Printf(\"At %.2fs, highlight: %s\\n\", word.Start, word.Text)\n}\n</code></pre>"},{"location":"services/forced-alignment/#video-caption-sync","title":"Video Caption Sync","text":"<pre><code>// Align narration with known script\nresult, err := client.ForcedAlignment().AlignFile(ctx,\n    narrationFile, \"narration.mp3\", script)\n\n// Generate precise captions\nfor _, word := range result.Words {\n    caption := Caption{\n        Text:      word.Text,\n        StartTime: word.Start,\n        EndTime:   word.End,\n    }\n    captions = append(captions, caption)\n}\n</code></pre>"},{"location":"services/forced-alignment/#audiobook-chapter-markers","title":"Audiobook Chapter Markers","text":"<pre><code>// Split transcript into chapters\nchapters := []string{\n    \"Chapter one begins here...\",\n    \"Chapter two continues...\",\n}\n\nvar chapterMarkers []float64\ncurrentPos := 0\n\nresult, err := client.ForcedAlignment().AlignFile(ctx, bookFile, \"book.mp3\", fullText)\n\n// Find chapter start times\nfor _, word := range result.Words {\n    // Check if this word starts a new chapter\n    for i, chapter := range chapters {\n        if strings.HasPrefix(chapter, word.Text) {\n            chapterMarkers = append(chapterMarkers, word.Start)\n        }\n    }\n}\n</code></pre>"},{"location":"services/forced-alignment/#quality-check-for-tts","title":"Quality Check for TTS","text":"<pre><code>// Generate speech\naudio, _ := client.TextToSpeech().Simple(ctx, voiceID, text)\n\n// Save audio\naudioFile, _ := os.CreateTemp(\"\", \"tts-*.mp3\")\nio.Copy(audioFile, audio)\naudioFile.Seek(0, 0)\n\n// Verify alignment\nresult, _ := client.ForcedAlignment().AlignFile(ctx, audioFile, \"tts.mp3\", text)\n\n// Check alignment quality\nif result.Loss &gt; 0.5 {\n    fmt.Println(\"Warning: Poor alignment - audio may not match text well\")\n}\n</code></pre>"},{"location":"services/forced-alignment/#alignment-loss","title":"Alignment Loss","text":"<p>The <code>Loss</code> field indicates alignment confidence:</p> Loss Value Quality 0.0 - 0.1 Excellent alignment 0.1 - 0.3 Good alignment 0.3 - 0.5 Acceptable &gt; 0.5 Poor - check audio/text match"},{"location":"services/forced-alignment/#supported-audio-formats","title":"Supported Audio Formats","text":"<ul> <li>MP3</li> <li>WAV</li> <li>M4A</li> <li>FLAC</li> <li>OGG</li> </ul>"},{"location":"services/forced-alignment/#best-practices","title":"Best Practices","text":"<ol> <li>Ensure text matches audio exactly - Mismatched text will increase loss</li> <li>Use clean audio - Background noise affects alignment accuracy</li> <li>Check the Loss value - High loss indicates poor alignment</li> <li>Use character-level for precise sync - Useful for karaoke effects</li> </ol>"},{"location":"services/history/","title":"History","text":"<p>Access and manage your generated audio history.</p>"},{"location":"services/history/#list-history","title":"List History","text":"<pre><code>resp, err := client.History().List(ctx, nil)\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, item := range resp.Items {\n    fmt.Printf(\"%s: %s (%s)\\n\", item.HistoryItemID, item.Text[:50], item.VoiceID)\n}\n</code></pre>"},{"location":"services/history/#with-pagination","title":"With Pagination","text":"<pre><code>resp, err := client.History().List(ctx, &amp;elevenlabs.HistoryListOptions{\n    PageSize: 20,\n})\n\n// Get next page\nif resp.HasMore {\n    nextResp, _ := client.History().List(ctx, &amp;elevenlabs.HistoryListOptions{\n        PageSize:             20,\n        StartAfterHistoryID: resp.LastHistoryItemID,\n    })\n}\n</code></pre>"},{"location":"services/history/#filter-by-voice","title":"Filter by Voice","text":"<pre><code>resp, err := client.History().List(ctx, &amp;elevenlabs.HistoryListOptions{\n    VoiceID: \"21m00Tcm4TlvDq8ikWAM\",\n})\n</code></pre>"},{"location":"services/history/#history-item-object","title":"History Item Object","text":"Field Description <code>HistoryItemID</code> Unique identifier <code>VoiceID</code> Voice used <code>VoiceName</code> Voice name <code>Text</code> Input text <code>ModelID</code> Model used <code>DateUnix</code> Creation timestamp <code>CharacterCount</code> Characters used <code>ContentType</code> MIME type <code>State</code> Processing state"},{"location":"services/history/#get-a-specific-item","title":"Get a Specific Item","text":"<pre><code>item, err := client.History().Get(ctx, historyItemID)\n</code></pre>"},{"location":"services/history/#download-audio","title":"Download Audio","text":"<pre><code>audio, err := client.History().GetAudio(ctx, historyItemID)\nif err != nil {\n    log.Fatal(err)\n}\n\nf, _ := os.Create(\"downloaded.mp3\")\ndefer f.Close()\nio.Copy(f, audio)\n</code></pre>"},{"location":"services/history/#delete-history-item","title":"Delete History Item","text":"<pre><code>err := client.History().Delete(ctx, historyItemID)\n</code></pre>"},{"location":"services/history/#use-cases","title":"Use Cases","text":""},{"location":"services/history/#re-download-lost-audio","title":"Re-download Lost Audio","text":"<pre><code>// Find item by text content\nresp, _ := client.History().List(ctx, nil)\nfor _, item := range resp.Items {\n    if strings.Contains(item.Text, \"specific phrase\") {\n        audio, _ := client.History().GetAudio(ctx, item.HistoryItemID)\n        // Save audio\n    }\n}\n</code></pre>"},{"location":"services/history/#track-usage-over-time","title":"Track Usage Over Time","text":"<pre><code>resp, _ := client.History().List(ctx, &amp;elevenlabs.HistoryListOptions{\n    PageSize: 100,\n})\n\nvar totalChars int\nfor _, item := range resp.Items {\n    totalChars += item.CharacterCount\n}\nfmt.Printf(\"Total characters used: %d\\n\", totalChars)\n</code></pre>"},{"location":"services/history/#clean-up-old-items","title":"Clean Up Old Items","text":"<pre><code>cutoff := time.Now().AddDate(0, -1, 0)  // 1 month ago\n\nresp, _ := client.History().List(ctx, nil)\nfor _, item := range resp.Items {\n    if time.Unix(item.DateUnix, 0).Before(cutoff) {\n        client.History().Delete(ctx, item.HistoryItemID)\n    }\n}\n</code></pre>"},{"location":"services/models/","title":"Models","text":"<p>List and select text-to-speech models.</p>"},{"location":"services/models/#list-available-models","title":"List Available Models","text":"<pre><code>models, err := client.Models().ListTTSModels(ctx)\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, m := range models {\n    fmt.Printf(\"%s: %s\\n\", m.ModelID, m.Name)\n    fmt.Printf(\"  Languages: %d\\n\", len(m.Languages))\n    fmt.Printf(\"  Can TTS: %v\\n\", m.CanDoTTS)\n}\n</code></pre>"},{"location":"services/models/#model-object","title":"Model Object","text":"Field Description <code>ModelID</code> Unique identifier <code>Name</code> Display name <code>Description</code> Model description <code>Languages</code> Supported languages <code>CanDoTTS</code> Supports text-to-speech <code>CanDoVoiceConversion</code> Supports voice conversion"},{"location":"services/models/#available-models","title":"Available Models","text":"Model ID Name Best For <code>eleven_multilingual_v2</code> Multilingual v2 Multiple languages, highest quality <code>eleven_monolingual_v1</code> English v1 English only, fast <code>eleven_turbo_v2</code> Turbo v2 Low latency <code>eleven_turbo_v2_5</code> Turbo v2.5 Lowest latency"},{"location":"services/models/#choosing-a-model","title":"Choosing a Model","text":""},{"location":"services/models/#for-quality","title":"For Quality","text":"<pre><code>// Best quality, supports 29 languages\nmodelID := \"eleven_multilingual_v2\"\n</code></pre>"},{"location":"services/models/#for-speed","title":"For Speed","text":"<pre><code>// Lowest latency for real-time applications\nmodelID := \"eleven_turbo_v2_5\"\n</code></pre>"},{"location":"services/models/#for-english-only","title":"For English Only","text":"<pre><code>// Optimized for English\nmodelID := \"eleven_monolingual_v1\"\n</code></pre>"},{"location":"services/models/#check-language-support","title":"Check Language Support","text":"<pre><code>models, _ := client.Models().ListTTSModels(ctx)\n\nfor _, m := range models {\n    for _, lang := range m.Languages {\n        if lang.LanguageID == \"es\" {  // Spanish\n            fmt.Printf(\"%s supports Spanish\\n\", m.Name)\n        }\n    }\n}\n</code></pre>"},{"location":"services/models/#default-model","title":"Default Model","text":"<p>The SDK uses <code>eleven_multilingual_v2</code> as the default:</p> <pre><code>elevenlabs.DefaultModelID  // \"eleven_multilingual_v2\"\n</code></pre>"},{"location":"services/music/","title":"Music","text":"<p>Generate music from text prompts.</p>"},{"location":"services/music/#basic-usage","title":"Basic Usage","text":"<pre><code>audio, err := client.Music().Simple(ctx, \"upbeat electronic music for a tech video\")\nif err != nil {\n    log.Fatal(err)\n}\n\nf, _ := os.Create(\"music.mp3\")\nio.Copy(f, audio)\n</code></pre>"},{"location":"services/music/#full-options","title":"Full Options","text":"<pre><code>resp, err := client.Music().Generate(ctx, &amp;elevenlabs.MusicRequest{\n    Prompt:            \"calm piano melody with soft strings\",\n    DurationMs:        30000,  // 30 seconds\n    ForceInstrumental: true,   // No vocals\n    Seed:              12345,  // For reproducibility\n})\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Song ID: %s\\n\", resp.SongID)\n\nf, _ := os.Create(\"calm_piano.mp3\")\nio.Copy(f, resp.Audio)\n</code></pre>"},{"location":"services/music/#instrumental-only","title":"Instrumental Only","text":"<p>Ensure the generated music has no vocals:</p> <pre><code>audio, err := client.Music().GenerateInstrumental(ctx,\n    \"epic orchestral music for movie trailer\",\n    60000,  // 60 seconds\n)\n</code></pre>"},{"location":"services/music/#streaming","title":"Streaming","text":"<p>For real-time playback:</p> <pre><code>resp, err := client.Music().GenerateStream(ctx, &amp;elevenlabs.MusicRequest{\n    Prompt:     \"lofi hip hop beats\",\n    DurationMs: 120000,  // 2 minutes\n})\n</code></pre>"},{"location":"services/music/#request-options","title":"Request Options","text":"Option Type Description <code>Prompt</code> string Text description of the music <code>DurationMs</code> int Duration in milliseconds (3000-600000) <code>ForceInstrumental</code> bool Ensure no vocals <code>Seed</code> int For reproducible generation"},{"location":"services/music/#response-structure","title":"Response Structure","text":"<pre><code>type MusicRequest struct {\n    Prompt            string\n    DurationMs        int\n    ForceInstrumental bool\n    Seed              int\n}\n\ntype MusicResponse struct {\n    Audio  io.Reader // Generated music\n    SongID string    // Unique identifier\n}\n</code></pre>"},{"location":"services/music/#duration-guidelines","title":"Duration Guidelines","text":"Duration Use Case 3-10 seconds Sound logos, jingles 10-30 seconds Intro/outro music 30-60 seconds Background music 1-5 minutes Full tracks 5-10 minutes Extended ambient"},{"location":"services/music/#prompt-examples","title":"Prompt Examples","text":""},{"location":"services/music/#by-genre","title":"By Genre","text":"<pre><code>// Electronic\n\"upbeat EDM with synthesizers and heavy bass drops\"\n\"ambient electronic music with soft pads\"\n\"retro 80s synthwave with arpeggios\"\n\n// Orchestral\n\"epic cinematic orchestra with brass and strings\"\n\"soft classical piano solo\"\n\"dramatic film score with timpani\"\n\n// Modern\n\"lofi hip hop beats to study to\"\n\"indie folk with acoustic guitar\"\n\"jazz trio with piano bass and drums\"\n\n// Ambient\n\"peaceful nature soundscape with birds\"\n\"space ambient with ethereal pads\"\n\"meditation music with singing bowls\"\n</code></pre>"},{"location":"services/music/#by-mood","title":"By Mood","text":"<pre><code>// Energetic\n\"high energy workout music with driving beat\"\n\"exciting action music for video games\"\n\"uplifting pop rock anthem\"\n\n// Calm\n\"relaxing spa music with soft piano\"\n\"gentle lullaby for sleep\"\n\"peaceful morning coffee music\"\n\n// Dramatic\n\"tense thriller soundtrack\"\n\"emotional sad piano piece\"\n\"triumphant victory fanfare\"\n</code></pre>"},{"location":"services/music/#by-use-case","title":"By Use Case","text":"<pre><code>// Video Content\n\"YouTube intro music, modern and catchy, 10 seconds\"\n\"podcast background music, subtle and professional\"\n\"tutorial video music, friendly and upbeat\"\n\n// Business\n\"corporate presentation background music\"\n\"hold music, pleasant and non-intrusive\"\n\"product launch reveal music\"\n\n// Gaming\n\"RPG exploration theme, adventurous\"\n\"boss battle music, intense and fast\"\n\"game menu music, mysterious ambient\"\n</code></pre>"},{"location":"services/music/#use-cases","title":"Use Cases","text":""},{"location":"services/music/#video-intro-music","title":"Video Intro Music","text":"<pre><code>intro, err := client.Music().Generate(ctx, &amp;elevenlabs.MusicRequest{\n    Prompt:            \"modern tech startup intro jingle, professional and innovative\",\n    DurationMs:        8000,  // 8 seconds\n    ForceInstrumental: true,\n})\n</code></pre>"},{"location":"services/music/#podcast-background","title":"Podcast Background","text":"<pre><code>background, err := client.Music().Generate(ctx, &amp;elevenlabs.MusicRequest{\n    Prompt:            \"subtle podcast background music, warm and conversational\",\n    DurationMs:        300000,  // 5 minutes\n    ForceInstrumental: true,\n})\n</code></pre>"},{"location":"services/music/#course-content","title":"Course Content","text":"<pre><code>// Intro music\nintro, _ := client.Music().GenerateInstrumental(ctx,\n    \"educational video intro, friendly and engaging\", 5000)\n\n// Transition music\ntransition, _ := client.Music().GenerateInstrumental(ctx,\n    \"soft transition sound, brief whoosh with melody\", 2000)\n\n// Background for explanations\nbackground, _ := client.Music().GenerateInstrumental(ctx,\n    \"thinking music, curious and light\", 60000)\n</code></pre>"},{"location":"services/music/#game-audio","title":"Game Audio","text":"<pre><code>// Menu theme\nmenuTheme, _ := client.Music().Generate(ctx, &amp;elevenlabs.MusicRequest{\n    Prompt:     \"fantasy RPG main menu theme, epic and adventurous\",\n    DurationMs: 120000,\n    Seed:       42,  // Reproducible for version control\n})\n\n// Battle music\nbattleMusic, _ := client.Music().Generate(ctx, &amp;elevenlabs.MusicRequest{\n    Prompt:            \"intense battle music, fast drums and aggressive strings\",\n    DurationMs:        90000,\n    ForceInstrumental: true,\n})\n</code></pre>"},{"location":"services/music/#reproducible-generation","title":"Reproducible Generation","text":"<p>Use seeds for consistent results:</p> <pre><code>// Generate same music twice\nseed := 12345\n\nmusic1, _ := client.Music().Generate(ctx, &amp;elevenlabs.MusicRequest{\n    Prompt:     \"calm acoustic guitar\",\n    DurationMs: 30000,\n    Seed:       seed,\n})\n\nmusic2, _ := client.Music().Generate(ctx, &amp;elevenlabs.MusicRequest{\n    Prompt:     \"calm acoustic guitar\",\n    DurationMs: 30000,\n    Seed:       seed,\n})\n\n// music1 and music2 will be identical\n</code></pre>"},{"location":"services/music/#composition-plans","title":"Composition Plans","text":"<p>For fine-grained control over song structure, generate a composition plan first:</p> <pre><code>// Generate a plan from a prompt\nplan, err := client.Music().GeneratePlan(ctx, &amp;elevenlabs.CompositionPlanRequest{\n    Prompt:     \"upbeat pop song about summer\",\n    DurationMs: 180000, // 3 minutes\n})\nif err != nil {\n    log.Fatal(err)\n}\n\n// Modify the plan if needed\nplan.Sections[0].Lines = []string{\"Custom lyrics for the intro\"}\nplan.PositiveGlobalStyles = append(plan.PositiveGlobalStyles, \"energetic\")\n\n// Generate music from the modified plan\nresp, err := client.Music().GenerateDetailed(ctx, &amp;elevenlabs.MusicDetailedRequest{\n    CompositionPlan: plan,\n    WithTimestamps:  true,\n})\n</code></pre>"},{"location":"services/music/#composition-plan-structure","title":"Composition Plan Structure","text":"<pre><code>type CompositionPlan struct {\n    PositiveGlobalStyles []string     // Styles present throughout\n    NegativeGlobalStyles []string     // Styles to avoid\n    Sections             []SongSection\n}\n\ntype SongSection struct {\n    SectionName         string   // \"intro\", \"verse\", \"chorus\"\n    DurationMs          int      // 3000-120000 per section\n    Lines               []string // Lyrics (max 200 chars per line)\n    PositiveLocalStyles []string // Styles for this section\n    NegativeLocalStyles []string // Styles to avoid in this section\n}\n</code></pre>"},{"location":"services/music/#detailed-generation","title":"Detailed Generation","text":"<p>Generate music with detailed options and metadata:</p> <pre><code>// With a simple prompt\nresp, err := client.Music().GenerateDetailed(ctx, &amp;elevenlabs.MusicDetailedRequest{\n    Prompt:            \"epic orchestral music\",\n    DurationMs:        60000,\n    ForceInstrumental: true,\n    WithTimestamps:    true,  // Get word timestamps\n})\n\n// With a composition plan (see above)\nresp, err := client.Music().GenerateDetailed(ctx, &amp;elevenlabs.MusicDetailedRequest{\n    CompositionPlan: plan,\n})\n</code></pre>"},{"location":"services/music/#stem-separation","title":"Stem Separation","text":"<p>Separate a song into individual stems (vocals, drums, bass, etc.):</p> <pre><code>f, _ := os.Open(\"song.mp3\")\ndefer f.Close()\n\nstems, err := client.Music().SeparateStems(ctx, &amp;elevenlabs.StemSeparationRequest{\n    File:     f,\n    Filename: \"song.mp3\",\n    // Options: \"two_stems_v1\" (vocals + music)\n    //          \"six_stems_v1\" (vocals, drums, bass, other - default)\n    StemVariation: \"six_stems_v1\",\n})\nif err != nil {\n    log.Fatal(err)\n}\n\n// Save the stems (returned as a zip file)\noutput, _ := os.Create(\"stems.zip\")\nio.Copy(output, stems)\n</code></pre>"},{"location":"services/music/#stem-variation-options","title":"Stem Variation Options","text":"Option Output <code>two_stems_v1</code> Vocals + instrumental <code>six_stems_v1</code> Vocals, drums, bass, and other (default)"},{"location":"services/music/#best-practices","title":"Best Practices","text":"<ol> <li>Be specific - \"upbeat jazz piano trio\" vs just \"jazz\"</li> <li>Include tempo hints - \"fast\", \"slow\", \"moderate tempo\"</li> <li>Specify instruments - \"acoustic guitar and violin\" for precise results</li> <li>Use ForceInstrumental - When you don't want any vocals</li> <li>Test with seeds - Find good seeds and save them for consistency</li> <li>Match duration to use case - Don't generate 5 minutes for a 10-second intro</li> <li>Use composition plans - For complex songs with multiple sections</li> <li>Stem separation - Extract vocals for remixing or karaoke</li> </ol>"},{"location":"services/projects/","title":"Projects (Studio)","text":"<p>Create long-form audio content organized into chapters - ideal for audiobooks, courses, and podcasts.</p>"},{"location":"services/projects/#overview","title":"Overview","text":"<p>Projects allow you to:</p> <ul> <li>Organize content into chapters</li> <li>Apply consistent voice settings across content</li> <li>Convert chapters individually or all at once</li> <li>Download completed audio as snapshots</li> </ul>"},{"location":"services/projects/#creating-a-project","title":"Creating a Project","text":""},{"location":"services/projects/#basic-project","title":"Basic Project","text":"<pre><code>project, err := client.Projects().Create(ctx, &amp;elevenlabs.CreateProjectRequest{\n    Name:        \"My Course\",\n    Description: \"Introduction to Go Programming\",\n    Language:    \"en\",\n})\n</code></pre>"},{"location":"services/projects/#with-voice-settings","title":"With Voice Settings","text":"<pre><code>project, err := client.Projects().Create(ctx, &amp;elevenlabs.CreateProjectRequest{\n    Name:                    \"My Course\",\n    DefaultModelID:          \"eleven_multilingual_v2\",\n    DefaultParagraphVoiceID: \"21m00Tcm4TlvDq8ikWAM\",\n    DefaultTitleVoiceID:     \"21m00Tcm4TlvDq8ikWAM\",\n    QualityPreset:           \"high\",\n    AutoConvert:             false,\n})\n</code></pre>"},{"location":"services/projects/#from-url","title":"From URL","text":"<pre><code>project, err := client.Projects().Create(ctx, &amp;elevenlabs.CreateProjectRequest{\n    Name:    \"My Article\",\n    FromURL: \"https://example.com/article\",\n})\n</code></pre>"},{"location":"services/projects/#listing-projects","title":"Listing Projects","text":"<pre><code>projects, err := client.Projects().List(ctx)\nfor _, p := range projects {\n    fmt.Printf(\"%s: %s\\n\", p.ProjectID, p.Name)\n}\n</code></pre>"},{"location":"services/projects/#project-object","title":"Project Object","text":"Field Description <code>ProjectID</code> Unique identifier <code>Name</code> Project name <code>Description</code> Project description <code>Author</code> Author name <code>Language</code> Two-letter language code <code>DefaultModelID</code> Default TTS model <code>DefaultParagraphVoiceID</code> Default voice for paragraphs <code>DefaultTitleVoiceID</code> Default voice for titles <code>CreatedAt</code> Creation timestamp <code>AccessLevel</code> Access permissions"},{"location":"services/projects/#working-with-chapters","title":"Working with Chapters","text":""},{"location":"services/projects/#list-chapters","title":"List Chapters","text":"<pre><code>chapters, err := client.Projects().ListChapters(ctx, projectID)\nfor _, ch := range chapters {\n    fmt.Printf(\"%s: %s (state: %s)\\n\", ch.ChapterID, ch.Name, ch.State)\n}\n</code></pre>"},{"location":"services/projects/#convert-a-chapter","title":"Convert a Chapter","text":"<pre><code>err := client.Projects().ConvertChapter(ctx, projectID, chapterID)\n</code></pre>"},{"location":"services/projects/#delete-a-chapter","title":"Delete a Chapter","text":"<pre><code>err := client.Projects().DeleteChapter(ctx, projectID, chapterID)\n</code></pre>"},{"location":"services/projects/#chapter-object","title":"Chapter Object","text":"Field Description <code>ChapterID</code> Unique identifier <code>Name</code> Chapter name <code>State</code> Current state <code>ConversionProgress</code> Progress percentage (0-100) <code>LastConversionError</code> Error message if failed"},{"location":"services/projects/#converting-projects","title":"Converting Projects","text":""},{"location":"services/projects/#convert-entire-project","title":"Convert Entire Project","text":"<pre><code>err := client.Projects().Convert(ctx, projectID)\n</code></pre>"},{"location":"services/projects/#check-conversion-status","title":"Check Conversion Status","text":"<pre><code>chapters, _ := client.Projects().ListChapters(ctx, projectID)\nfor _, ch := range chapters {\n    fmt.Printf(\"%s: %.0f%% complete\\n\", ch.Name, ch.ConversionProgress)\n}\n</code></pre>"},{"location":"services/projects/#snapshots","title":"Snapshots","text":"<p>Snapshots are frozen versions of converted audio.</p>"},{"location":"services/projects/#list-project-snapshots","title":"List Project Snapshots","text":"<pre><code>snapshots, err := client.Projects().ListSnapshots(ctx, projectID)\nfor _, snap := range snapshots {\n    fmt.Printf(\"%s: %s (created: %s)\\n\",\n        snap.ProjectSnapshotID, snap.Name, snap.CreatedAt)\n}\n</code></pre>"},{"location":"services/projects/#download-snapshot-archive","title":"Download Snapshot Archive","text":"<pre><code>reader, err := client.Projects().DownloadSnapshotArchive(ctx, projectID, snapshotID)\nif err != nil {\n    log.Fatal(err)\n}\n\nf, _ := os.Create(\"project.zip\")\ndefer f.Close()\nio.Copy(f, reader)\n</code></pre>"},{"location":"services/projects/#list-chapter-snapshots","title":"List Chapter Snapshots","text":"<pre><code>snapshots, err := client.Projects().ListChapterSnapshots(ctx, projectID, chapterID)\n</code></pre>"},{"location":"services/projects/#stream-chapter-audio","title":"Stream Chapter Audio","text":"<pre><code>audio, err := client.Projects().StreamChapterAudio(ctx, projectID, chapterID, snapshotID)\n</code></pre>"},{"location":"services/projects/#updating-projects","title":"Updating Projects","text":"<pre><code>err := client.Projects().Update(ctx, projectID, &amp;elevenlabs.UpdateProjectRequest{\n    Name:                    \"Updated Name\",\n    DefaultParagraphVoiceID: \"newVoiceID\",\n    DefaultTitleVoiceID:     \"newVoiceID\",\n})\n</code></pre>"},{"location":"services/projects/#deleting-projects","title":"Deleting Projects","text":"<pre><code>err := client.Projects().Delete(ctx, projectID)\n</code></pre>"},{"location":"services/projects/#quality-presets","title":"Quality Presets","text":"Preset Description <code>standard</code> 128kbps, 44.1kHz <code>high</code> 192kbps, 44.1kHz <code>ultra</code> 192kbps, enhanced <code>ultra lossless</code> 705.6kbps, lossless"},{"location":"services/projects/#workflow-example","title":"Workflow Example","text":"<pre><code>// 1. Create project\nproject, _ := client.Projects().Create(ctx, &amp;elevenlabs.CreateProjectRequest{\n    Name:     \"Go Programming Course\",\n    Language: \"en\",\n})\n\n// 2. List chapters (added via web UI or API)\nchapters, _ := client.Projects().ListChapters(ctx, project.ProjectID)\n\n// 3. Convert all chapters\nfor _, ch := range chapters {\n    client.Projects().ConvertChapter(ctx, project.ProjectID, ch.ChapterID)\n}\n\n// 4. Wait for conversion (poll status)\n// ...\n\n// 5. Download completed project\nsnapshots, _ := client.Projects().ListSnapshots(ctx, project.ProjectID)\nif len(snapshots) &gt; 0 {\n    reader, _ := client.Projects().DownloadSnapshotArchive(ctx,\n        project.ProjectID, snapshots[0].ProjectSnapshotID)\n\n    f, _ := os.Create(\"course.zip\")\n    io.Copy(f, reader)\n    f.Close()\n}\n</code></pre>"},{"location":"services/pronunciation/","title":"Pronunciation Dictionaries","text":"<p>Ensure correct pronunciation of technical terms, names, and domain-specific vocabulary.</p>"},{"location":"services/pronunciation/#why-use-pronunciation-dictionaries","title":"Why Use Pronunciation Dictionaries?","text":"<p>Without pronunciation rules, TTS may mispronounce:</p> <ul> <li>Acronyms: \"API\" as \"appy\" instead of \"A P I\"</li> <li>Technical terms: \"kubectl\" as \"kub-cuttle\"</li> <li>Brand names: \"nginx\" incorrectly</li> <li>Domain jargon: Industry-specific terms</li> </ul>"},{"location":"services/pronunciation/#creating-dictionaries","title":"Creating Dictionaries","text":""},{"location":"services/pronunciation/#from-a-map-simplest","title":"From a Map (Simplest)","text":"<pre><code>dict, err := client.Pronunciation().CreateFromMap(ctx, \"Tech Terms\", map[string]string{\n    \"ADK\":     \"Agent Development Kit\",\n    \"API\":     \"A P I\",\n    \"kubectl\": \"kube control\",\n    \"nginx\":   \"engine X\",\n    \"SQL\":     \"sequel\",\n})\n</code></pre>"},{"location":"services/pronunciation/#from-a-json-file","title":"From a JSON File","text":"<p>Create a JSON file (<code>terms.json</code>):</p> <pre><code>[\n  {\"grapheme\": \"ADK\", \"alias\": \"Agent Development Kit\"},\n  {\"grapheme\": \"API\", \"alias\": \"A P I\"},\n  {\"grapheme\": \"kubectl\", \"alias\": \"kube control\"},\n  {\"grapheme\": \"nginx\", \"phoneme\": \"\u02c8\u025bnd\u0292\u026an\u02c8\u025bks\"}\n]\n</code></pre> <p>Load and create:</p> <pre><code>dict, err := client.Pronunciation().CreateFromJSON(ctx, \"Tech Terms\", \"terms.json\")\n</code></pre>"},{"location":"services/pronunciation/#with-full-options","title":"With Full Options","text":"<pre><code>rules := elevenlabs.PronunciationRules{\n    {Grapheme: \"ADK\", Alias: \"Agent Development Kit\"},\n    {Grapheme: \"nginx\", Phoneme: \"\u02c8\u025bnd\u0292\u026an\u02c8\u025bks\"},\n}\n\ndict, err := client.Pronunciation().Create(ctx, &amp;elevenlabs.CreatePronunciationDictionaryRequest{\n    Name:        \"Tech Terms\",\n    Description: \"Technical vocabulary for developer courses\",\n    Rules:       rules,\n    Language:    \"en-US\",\n})\n</code></pre>"},{"location":"services/pronunciation/#rule-types","title":"Rule Types","text":""},{"location":"services/pronunciation/#alias-text-substitution","title":"Alias (Text Substitution)","text":"<p>The simpler option - specify replacement text:</p> <pre><code>{Grapheme: \"API\", Alias: \"A P I\"}\n// \"API\" will be read as \"A P I\"\n</code></pre>"},{"location":"services/pronunciation/#phoneme-ipa","title":"Phoneme (IPA)","text":"<p>For precise phonetic control using International Phonetic Alphabet:</p> <pre><code>{Grapheme: \"nginx\", Phoneme: \"\u02c8\u025bnd\u0292\u026an\u02c8\u025bks\"}\n</code></pre>"},{"location":"services/pronunciation/#managing-dictionaries","title":"Managing Dictionaries","text":""},{"location":"services/pronunciation/#list-all-dictionaries","title":"List All Dictionaries","text":"<pre><code>resp, err := client.Pronunciation().List(ctx, nil)\nfor _, dict := range resp.Dictionaries {\n    fmt.Printf(\"%s: %s (%d rules)\\n\", dict.ID, dict.Name, dict.RulesCount)\n}\n</code></pre>"},{"location":"services/pronunciation/#get-a-dictionary","title":"Get a Dictionary","text":"<pre><code>dict, err := client.Pronunciation().Get(ctx, dictionaryID)\n</code></pre>"},{"location":"services/pronunciation/#rename-a-dictionary","title":"Rename a Dictionary","text":"<pre><code>err := client.Pronunciation().Rename(ctx, dictionaryID, \"New Name\")\n</code></pre>"},{"location":"services/pronunciation/#remove-rules","title":"Remove Rules","text":"<pre><code>err := client.Pronunciation().RemoveRules(ctx, dictionaryID, []string{\"API\", \"SQL\"})\n</code></pre>"},{"location":"services/pronunciation/#archive-a-dictionary","title":"Archive a Dictionary","text":"<pre><code>err := client.Pronunciation().Archive(ctx, dictionaryID)\n</code></pre>"},{"location":"services/pronunciation/#download-pls-file","title":"Download PLS File","text":"<p>Download the PLS (Pronunciation Lexicon Specification) XML file for a dictionary:</p> <pre><code>// Download latest version\npls, err := client.Pronunciation().DownloadLatestPLS(ctx, dictionaryID)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Save to file\nf, _ := os.Create(\"dictionary.pls\")\nio.Copy(f, pls)\n\n// Or download a specific version\npls, err := client.Pronunciation().GetVersionPLS(ctx, dictionaryID, versionID)\n</code></pre>"},{"location":"services/pronunciation/#working-with-rules-locally","title":"Working with Rules Locally","text":""},{"location":"services/pronunciation/#load-from-json","title":"Load from JSON","text":"<pre><code>rules, err := elevenlabs.LoadRulesFromJSON(\"terms.json\")\n</code></pre>"},{"location":"services/pronunciation/#parse-from-json-string","title":"Parse from JSON String","text":"<pre><code>jsonData := `[{\"grapheme\": \"API\", \"alias\": \"A P I\"}]`\nrules, err := elevenlabs.ParseRulesFromJSON([]byte(jsonData))\n</code></pre>"},{"location":"services/pronunciation/#create-from-map","title":"Create from Map","text":"<pre><code>rules := elevenlabs.RulesFromMap(map[string]string{\n    \"API\": \"A P I\",\n    \"SQL\": \"sequel\",\n})\n</code></pre>"},{"location":"services/pronunciation/#generate-pls-xml","title":"Generate PLS XML","text":"<pre><code>rules := elevenlabs.PronunciationRules{\n    {Grapheme: \"API\", Alias: \"A P I\"},\n}\n\n// Get as string\nplsXML, err := rules.ToPLSString(\"en-US\")\n\n// Save to file\nerr = rules.SavePLS(\"terms.pls\", \"en-US\")\n</code></pre>"},{"location":"services/pronunciation/#view-rules","title":"View Rules","text":"<pre><code>fmt.Println(rules.String())\n// Output:\n// API \u2192 A P I\n// nginx \u2192 [\u02c8\u025bnd\u0292\u026an\u02c8\u025bks]\n\n// Get all graphemes\nterms := rules.Graphemes()  // [\"API\", \"nginx\"]\n</code></pre>"},{"location":"services/pronunciation/#json-file-format","title":"JSON File Format","text":"<pre><code>[\n  {\n    \"grapheme\": \"ADK\",\n    \"alias\": \"Agent Development Kit\"\n  },\n  {\n    \"grapheme\": \"API\",\n    \"alias\": \"A P I\"\n  },\n  {\n    \"grapheme\": \"nginx\",\n    \"phoneme\": \"\u02c8\u025bnd\u0292\u026an\u02c8\u025bks\"\n  }\n]\n</code></pre>"},{"location":"services/pronunciation/#best-practices","title":"Best Practices","text":"<ol> <li>Use aliases for simplicity - Phonemes only when needed</li> <li>Test pronunciations - Generate sample audio to verify</li> <li>Organize by domain - Separate dictionaries for different topics</li> <li>Version control your JSON - Track changes to pronunciation rules</li> <li>Document unusual terms - Add comments explaining why terms need rules</li> </ol>"},{"location":"services/sound-effects/","title":"Sound Effects","text":"<p>Generate sound effects from text descriptions.</p>"},{"location":"services/sound-effects/#basic-usage","title":"Basic Usage","text":"<pre><code>audio, err := client.SoundEffects().Simple(ctx, \"thunder and rain storm\")\nif err != nil {\n    log.Fatal(err)\n}\n\nf, _ := os.Create(\"thunder.mp3\")\nio.Copy(f, audio)\n</code></pre>"},{"location":"services/sound-effects/#full-control","title":"Full Control","text":"<pre><code>resp, err := client.SoundEffects().Generate(ctx, &amp;elevenlabs.SoundEffectRequest{\n    Text:            \"car engine starting and revving\",\n    DurationSeconds: 5.0,      // 0.5 to 30 seconds\n    PromptInfluence: 0.5,      // 0.0 to 1.0\n    OutputFormat:    \"mp3_44100_128\",\n})\n</code></pre>"},{"location":"services/sound-effects/#looping-sound-effects","title":"Looping Sound Effects","text":"<p>Create seamlessly looping audio for backgrounds:</p> <pre><code>audio, err := client.SoundEffects().GenerateLoop(ctx,\n    \"gentle rain on window\",\n    10.0,  // duration in seconds\n)\n</code></pre>"},{"location":"services/sound-effects/#request-options","title":"Request Options","text":"Option Range Description <code>Text</code> required Description of the sound effect <code>DurationSeconds</code> 0.5-30 Target duration (auto if not set) <code>PromptInfluence</code> 0.0-1.0 How closely to follow the prompt <code>Loop</code> bool Create seamless loop <code>OutputFormat</code> string Audio format"},{"location":"services/sound-effects/#prompt-influence","title":"Prompt Influence","text":"<ul> <li>Low (0.0-0.3): More variation, creative interpretation</li> <li>Medium (0.3-0.6): Balanced (default: 0.3)</li> <li>High (0.6-1.0): Strictly follows prompt</li> </ul>"},{"location":"services/sound-effects/#example-prompts","title":"Example Prompts","text":""},{"location":"services/sound-effects/#nature","title":"Nature","text":"<pre><code>\"gentle rain on a tin roof\"\n\"thunderstorm with distant lightning\"\n\"ocean waves on a beach\"\n\"wind blowing through trees\"\n\"birds chirping in a forest\"\n</code></pre>"},{"location":"services/sound-effects/#urban","title":"Urban","text":"<pre><code>\"busy city traffic\"\n\"car horn honking\"\n\"subway train arriving\"\n\"crowd murmuring in a cafe\"\n</code></pre>"},{"location":"services/sound-effects/#technology","title":"Technology","text":"<pre><code>\"computer keyboard typing\"\n\"notification chime\"\n\"sci-fi door opening\"\n\"robot powering up\"\n</code></pre>"},{"location":"services/sound-effects/#musictransitions","title":"Music/Transitions","text":"<pre><code>\"dramatic orchestral hit\"\n\"soft piano transition\"\n\"whoosh transition sound\"\n\"upbeat intro jingle\"\n</code></pre>"},{"location":"services/sound-effects/#use-cases","title":"Use Cases","text":""},{"location":"services/sound-effects/#course-production","title":"Course Production","text":"<pre><code>// Intro sound\nintro, _ := client.SoundEffects().Simple(ctx, \"professional podcast intro jingle\")\n\n// Transition\ntransition, _ := client.SoundEffects().Simple(ctx, \"soft whoosh transition\")\n\n// Background ambience (looping)\nambience, _ := client.SoundEffects().GenerateLoop(ctx, \"quiet office ambience\", 30)\n</code></pre>"},{"location":"services/sound-effects/#video-production","title":"Video Production","text":"<pre><code>// Action sounds\npunch, _ := client.SoundEffects().Simple(ctx, \"punch impact sound\")\n\n// Ambient backgrounds\nforest, _ := client.SoundEffects().GenerateLoop(ctx, \"peaceful forest ambience\", 60)\n</code></pre>"},{"location":"services/sound-effects/#best-practices","title":"Best Practices","text":"<ol> <li>Be specific - \"car engine starting cold\" vs just \"car\"</li> <li>Include context - \"footsteps on wooden floor\" vs \"footsteps\"</li> <li>Use loops for backgrounds - Enables seamless repetition</li> <li>Test prompt influence - Adjust based on desired creativity</li> </ol>"},{"location":"services/speech-to-speech/","title":"Speech-to-Speech","text":"<p>Voice conversion service that transforms speech from one voice to another while preserving the content.</p>"},{"location":"services/speech-to-speech/#overview","title":"Overview","text":"<p>The Speech-to-Speech service enables:</p> <ul> <li>Voice Conversion: Transform any voice to a target voice</li> <li>Content Preservation: Keep the original speech content</li> <li>Background Noise Removal: Clean up source audio</li> <li>Streaming: Real-time voice conversion</li> </ul>"},{"location":"services/speech-to-speech/#basic-usage","title":"Basic Usage","text":"<pre><code>// Open source audio file\nf, err := os.Open(\"source_audio.mp3\")\nif err != nil {\n    log.Fatal(err)\n}\ndefer f.Close()\n\n// Convert to target voice\nresp, err := client.SpeechToSpeech().Convert(ctx, &amp;elevenlabs.SpeechToSpeechRequest{\n    VoiceID: \"target-voice-id\",\n    Audio:   f,\n})\nif err != nil {\n    log.Fatal(err)\n}\n\n// Save converted audio\nout, _ := os.Create(\"converted.mp3\")\ndefer out.Close()\nio.Copy(out, resp.Audio)\n</code></pre>"},{"location":"services/speech-to-speech/#simple-conversion","title":"Simple Conversion","text":"<pre><code>// One-line conversion\nf, _ := os.Open(\"input.mp3\")\naudio, err := client.SpeechToSpeech().Simple(ctx, targetVoiceID, f)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Save output\nout, _ := os.Create(\"output.mp3\")\nio.Copy(out, audio)\n</code></pre>"},{"location":"services/speech-to-speech/#with-full-options","title":"With Full Options","text":"<pre><code>sourceFile, _ := os.Open(\"speaker_a.mp3\")\n\nresp, err := client.SpeechToSpeech().Convert(ctx, &amp;elevenlabs.SpeechToSpeechRequest{\n    // Target voice\n    VoiceID: \"21m00Tcm4TlvDq8ikWAM\",\n\n    // Source audio\n    Audio:         sourceFile,\n    AudioFilename: \"speaker_a.mp3\", // Helps with format detection\n\n    // Model selection\n    ModelID: \"eleven_english_sts_v2\",\n\n    // Voice settings\n    VoiceSettings: &amp;elevenlabs.VoiceSettings{\n        Stability:       0.5,\n        SimilarityBoost: 0.8,\n        Style:           0.0,\n        UseSpeakerBoost: true,\n    },\n\n    // Output format\n    OutputFormat: \"mp3_44100_128\",\n\n    // Remove background noise from source\n    RemoveBackgroundNoise: true,\n})\n</code></pre>"},{"location":"services/speech-to-speech/#streaming-conversion","title":"Streaming Conversion","text":"<p>For real-time voice conversion:</p> <pre><code>resp, err := client.SpeechToSpeech().ConvertStream(ctx, &amp;elevenlabs.SpeechToSpeechRequest{\n    VoiceID: targetVoiceID,\n    Audio:   sourceAudio,\n    OutputFormat: \"pcm_22050\",\n})\nif err != nil {\n    log.Fatal(err)\n}\n\n// Stream to audio player\nplayer := audio.NewPlayer(22050)\nio.Copy(player, resp.Audio)\n</code></pre>"},{"location":"services/speech-to-speech/#with-seed-audio","title":"With Seed Audio","text":"<p>Use seed audio for more consistent conversions:</p> <pre><code>sourceFile, _ := os.Open(\"input.mp3\")\nseedFile, _ := os.Open(\"seed_sample.mp3\")\n\nresp, err := client.SpeechToSpeech().Convert(ctx, &amp;elevenlabs.SpeechToSpeechRequest{\n    VoiceID: targetVoiceID,\n    Audio:   sourceFile,\n\n    // Seed audio influences the conversion style\n    SeedAudio:         seedFile,\n    SeedAudioFilename: \"seed_sample.mp3\",\n})\n</code></pre>"},{"location":"services/speech-to-speech/#request-options","title":"Request Options","text":"Field Type Required Description <code>VoiceID</code> string Yes Target voice ID <code>Audio</code> io.Reader Yes Source audio data <code>AudioFilename</code> string No Source filename hint <code>ModelID</code> string No Model (default: <code>eleven_english_sts_v2</code>) <code>VoiceSettings</code> *VoiceSettings No Voice parameters <code>OutputFormat</code> string No Output audio format <code>RemoveBackgroundNoise</code> bool No Clean source audio <code>SeedAudio</code> io.Reader No Reference audio for style <code>SeedAudioFilename</code> string No Seed filename hint"},{"location":"services/speech-to-speech/#output-formats","title":"Output Formats","text":"<p>Available output formats:</p> <p>MP3 Formats: - <code>mp3_44100_64</code> - 64kbps MP3 - <code>mp3_44100_96</code> - 96kbps MP3 - <code>mp3_44100_128</code> - 128kbps MP3 (recommended) - <code>mp3_44100_192</code> - 192kbps MP3</p> <p>PCM Formats (for streaming): - <code>pcm_16000</code> - 16kHz PCM - <code>pcm_22050</code> - 22.05kHz PCM - <code>pcm_24000</code> - 24kHz PCM - <code>pcm_44100</code> - 44.1kHz PCM</p>"},{"location":"services/speech-to-speech/#use-cases","title":"Use Cases","text":""},{"location":"services/speech-to-speech/#voice-dubbing","title":"Voice Dubbing","text":"<pre><code>// Convert foreign language audio to your voice library\nresp, err := client.SpeechToSpeech().Convert(ctx, &amp;elevenlabs.SpeechToSpeechRequest{\n    VoiceID:               englishVoiceID,\n    Audio:                 foreignAudio,\n    RemoveBackgroundNoise: true,\n})\n</code></pre>"},{"location":"services/speech-to-speech/#voice-anonymization","title":"Voice Anonymization","text":"<pre><code>// Convert voice for privacy\nresp, err := client.SpeechToSpeech().Convert(ctx, &amp;elevenlabs.SpeechToSpeechRequest{\n    VoiceID: anonymousVoiceID,\n    Audio:   originalRecording,\n})\n</code></pre>"},{"location":"services/speech-to-speech/#real-time-voice-changer","title":"Real-time Voice Changer","text":"<pre><code>// Stream microphone through voice conversion\nresp, err := client.SpeechToSpeech().ConvertStream(ctx, &amp;elevenlabs.SpeechToSpeechRequest{\n    VoiceID:      characterVoiceID,\n    Audio:        microphoneStream,\n    OutputFormat: \"pcm_22050\",\n})\n// Pipe to speakers\nio.Copy(speakers, resp.Audio)\n</code></pre>"},{"location":"services/speech-to-text/","title":"Speech-to-Text","text":"<p>Transcribe audio files with optional speaker diarization.</p>"},{"location":"services/speech-to-text/#basic-usage","title":"Basic Usage","text":"<pre><code>// Transcribe from URL\nresult, err := client.SpeechToText().TranscribeURL(ctx, \"https://example.com/audio.mp3\")\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Text: %s\\n\", result.Text)\nfmt.Printf(\"Language: %s\\n\", result.LanguageCode)\n</code></pre>"},{"location":"services/speech-to-text/#transcribe-with-file-upload","title":"Transcribe with File Upload","text":"<pre><code>file, _ := os.Open(\"audio.mp3\")\ndefer file.Close()\n\nresult, err := client.SpeechToText().Transcribe(ctx, &amp;elevenlabs.TranscriptionRequest{\n    File:     file,\n    Filename: \"audio.mp3\",\n    ModelID:  \"scribe_v1\",\n})\n</code></pre>"},{"location":"services/speech-to-text/#speaker-diarization","title":"Speaker Diarization","text":"<p>Identify different speakers in the audio:</p> <pre><code>result, err := client.SpeechToText().TranscribeWithDiarization(ctx, audioURL)\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, word := range result.Words {\n    fmt.Printf(\"[%s] %s (%.2fs - %.2fs)\\n\",\n        word.Speaker, word.Text, word.Start, word.End)\n}\n</code></pre>"},{"location":"services/speech-to-text/#full-options","title":"Full Options","text":"<pre><code>result, err := client.SpeechToText().Transcribe(ctx, &amp;elevenlabs.TranscriptionRequest{\n    File:              file,\n    Filename:          \"interview.mp3\",\n    ModelID:           \"scribe_v1\",\n    LanguageCode:      \"en\",           // ISO 639-1 code\n    Diarize:           true,           // Enable speaker detection\n    TagAudioEvents:    true,           // Tag laughter, music, etc.\n    NumSpeakers:       2,              // Expected number of speakers\n})\n</code></pre>"},{"location":"services/speech-to-text/#request-options","title":"Request Options","text":"Option Type Description <code>File</code> io.Reader Audio file to transcribe <code>Filename</code> string Name of the audio file <code>AudioURL</code> string URL to audio (alternative to file) <code>ModelID</code> string Transcription model (default: scribe_v1) <code>LanguageCode</code> string ISO 639-1 language code <code>Diarize</code> bool Enable speaker diarization <code>TagAudioEvents</code> bool Tag non-speech audio events <code>NumSpeakers</code> int Expected number of speakers"},{"location":"services/speech-to-text/#response-structure","title":"Response Structure","text":"<pre><code>type TranscriptionResponse struct {\n    Text         string              // Full transcription text\n    LanguageCode string              // Detected language\n    Words        []TranscriptionWord // Word-level timestamps\n}\n\ntype TranscriptionWord struct {\n    Text    string  // The word\n    Start   float64 // Start time in seconds\n    End     float64 // End time in seconds\n    Speaker string  // Speaker ID (if diarization enabled)\n}\n</code></pre>"},{"location":"services/speech-to-text/#use-cases","title":"Use Cases","text":""},{"location":"services/speech-to-text/#meeting-transcription","title":"Meeting Transcription","text":"<pre><code>result, err := client.SpeechToText().Transcribe(ctx, &amp;elevenlabs.TranscriptionRequest{\n    File:        meetingFile,\n    Filename:    \"meeting.mp3\",\n    Diarize:     true,\n    NumSpeakers: 4,\n})\n\n// Group by speaker\nspeakers := make(map[string][]string)\nfor _, word := range result.Words {\n    speakers[word.Speaker] = append(speakers[word.Speaker], word.Text)\n}\n</code></pre>"},{"location":"services/speech-to-text/#subtitle-generation","title":"Subtitle Generation","text":"<pre><code>result, err := client.SpeechToText().TranscribeURL(ctx, videoAudioURL)\n\n// Generate SRT format\nfor i, word := range result.Words {\n    fmt.Printf(\"%d\\n\", i+1)\n    fmt.Printf(\"%s --&gt; %s\\n\", formatTime(word.Start), formatTime(word.End))\n    fmt.Printf(\"%s\\n\\n\", word.Text)\n}\n</code></pre>"},{"location":"services/speech-to-text/#podcast-processing","title":"Podcast Processing","text":"<pre><code>// Transcribe podcast episode\nresult, err := client.SpeechToText().Transcribe(ctx, &amp;elevenlabs.TranscriptionRequest{\n    File:           podcastFile,\n    Filename:       \"episode.mp3\",\n    Diarize:        true,\n    TagAudioEvents: true,  // Detect music, laughter, etc.\n})\n</code></pre>"},{"location":"services/speech-to-text/#supported-audio-formats","title":"Supported Audio Formats","text":"<ul> <li>MP3</li> <li>WAV</li> <li>M4A</li> <li>FLAC</li> <li>OGG</li> <li>WEBM</li> </ul>"},{"location":"services/speech-to-text/#best-practices","title":"Best Practices","text":"<ol> <li>Use diarization for multi-speaker content - Interviews, meetings, podcasts</li> <li>Specify language when known for better accuracy</li> <li>Set expected speaker count for more accurate diarization</li> <li>Enable audio event tagging for richer metadata</li> </ol>"},{"location":"services/text-to-dialogue/","title":"Text-to-Dialogue","text":"<p>Generate multi-speaker conversations with different voices for each speaker.</p>"},{"location":"services/text-to-dialogue/#basic-usage","title":"Basic Usage","text":"<pre><code>audio, err := client.TextToDialogue().Simple(ctx, []elevenlabs.DialogueInput{\n    {Text: \"Hello, how are you today?\", VoiceID: \"voice1\"},\n    {Text: \"I'm doing great, thanks for asking!\", VoiceID: \"voice2\"},\n    {Text: \"That's wonderful to hear.\", VoiceID: \"voice1\"},\n})\nif err != nil {\n    log.Fatal(err)\n}\n\nf, _ := os.Create(\"dialogue.mp3\")\nio.Copy(f, audio)\n</code></pre>"},{"location":"services/text-to-dialogue/#full-options","title":"Full Options","text":"<pre><code>audio, err := client.TextToDialogue().Generate(ctx, &amp;elevenlabs.DialogueRequest{\n    Inputs: []elevenlabs.DialogueInput{\n        {Text: \"Welcome to the show!\", VoiceID: hostVoiceID},\n        {Text: \"Thanks for having me.\", VoiceID: guestVoiceID},\n    },\n    ModelID:      \"eleven_multilingual_v2\",\n    LanguageCode: \"en\",\n    Seed:         42,  // For reproducible output\n})\n</code></pre>"},{"location":"services/text-to-dialogue/#with-timestamps","title":"With Timestamps","text":"<p>Get timing information for each segment:</p> <pre><code>resp, err := client.TextToDialogue().GenerateWithTimestamps(ctx, &amp;elevenlabs.DialogueRequest{\n    Inputs: []elevenlabs.DialogueInput{\n        {Text: \"First speaker talks.\", VoiceID: voice1},\n        {Text: \"Second speaker responds.\", VoiceID: voice2},\n    },\n})\n\nfmt.Printf(\"Audio (base64): %s\\n\", resp.AudioBase64)\n\nfor _, seg := range resp.VoiceSegments {\n    fmt.Printf(\"Voice %s: %.2fs - %.2fs\\n\", seg.VoiceID, seg.StartTime, seg.EndTime)\n}\n</code></pre>"},{"location":"services/text-to-dialogue/#streaming","title":"Streaming","text":"<p>For real-time playback:</p> <pre><code>stream, err := client.TextToDialogue().GenerateStream(ctx, &amp;elevenlabs.DialogueRequest{\n    Inputs: dialogueInputs,\n})\n</code></pre>"},{"location":"services/text-to-dialogue/#response-structures","title":"Response Structures","text":"<pre><code>type DialogueInput struct {\n    Text    string // Text to speak\n    VoiceID string // Voice ID for this line\n}\n\ntype DialogueRequest struct {\n    Inputs       []DialogueInput\n    ModelID      string // TTS model\n    LanguageCode string // ISO 639-1 code\n    Seed         int    // For reproducibility\n}\n\ntype DialogueResponse struct {\n    AudioBase64   string         // Base64-encoded audio\n    VoiceSegments []VoiceSegment // Timing info\n}\n\ntype VoiceSegment struct {\n    VoiceID   string\n    StartTime float64\n    EndTime   float64\n}\n</code></pre>"},{"location":"services/text-to-dialogue/#use-cases","title":"Use Cases","text":""},{"location":"services/text-to-dialogue/#podcast-conversations","title":"Podcast Conversations","text":"<pre><code>hostVoice := \"21m00Tcm4TlvDq8ikWAM\"\nguestVoice := \"AZnzlk1XvdvUeBnXmlld\"\n\ndialogue := []elevenlabs.DialogueInput{\n    {Text: \"Welcome back to Tech Talk! Today we're discussing AI.\", VoiceID: hostVoice},\n    {Text: \"Thanks for having me. AI has really transformed everything.\", VoiceID: guestVoice},\n    {Text: \"Let's dive into the specifics. What excites you most?\", VoiceID: hostVoice},\n    {Text: \"Definitely the creative applications - music, art, writing.\", VoiceID: guestVoice},\n}\n\naudio, _ := client.TextToDialogue().Simple(ctx, dialogue)\n</code></pre>"},{"location":"services/text-to-dialogue/#educational-content","title":"Educational Content","text":"<pre><code>teacher := \"teacher-voice-id\"\nstudent := \"student-voice-id\"\n\nlesson := []elevenlabs.DialogueInput{\n    {Text: \"Today we'll learn about photosynthesis.\", VoiceID: teacher},\n    {Text: \"What exactly is photosynthesis?\", VoiceID: student},\n    {Text: \"It's how plants convert sunlight into energy.\", VoiceID: teacher},\n    {Text: \"So plants are like solar panels?\", VoiceID: student},\n    {Text: \"That's a great analogy! Let me explain further.\", VoiceID: teacher},\n}\n\naudio, _ := client.TextToDialogue().Simple(ctx, lesson)\n</code></pre>"},{"location":"services/text-to-dialogue/#audiobook-dialogues","title":"Audiobook Dialogues","text":"<pre><code>narrator := \"narrator-voice-id\"\ncharacter1 := \"character1-voice-id\"\ncharacter2 := \"character2-voice-id\"\n\nstory := []elevenlabs.DialogueInput{\n    {Text: \"The detective entered the room slowly.\", VoiceID: narrator},\n    {Text: \"I've been expecting you.\", VoiceID: character1},\n    {Text: \"Then you know why I'm here.\", VoiceID: character2},\n    {Text: \"The tension was palpable.\", VoiceID: narrator},\n}\n\naudio, _ := client.TextToDialogue().Simple(ctx, story)\n</code></pre>"},{"location":"services/text-to-dialogue/#customer-service-demos","title":"Customer Service Demos","text":"<pre><code>agent := \"agent-voice-id\"\ncustomer := \"customer-voice-id\"\n\ndemo := []elevenlabs.DialogueInput{\n    {Text: \"Thank you for calling support. How can I help?\", VoiceID: agent},\n    {Text: \"I'm having trouble with my account.\", VoiceID: customer},\n    {Text: \"I'd be happy to help. Can I have your account number?\", VoiceID: agent},\n    {Text: \"Sure, it's 12345.\", VoiceID: customer},\n    {Text: \"Perfect, I can see your account now.\", VoiceID: agent},\n}\n\naudio, _ := client.TextToDialogue().Simple(ctx, demo)\n</code></pre>"},{"location":"services/text-to-dialogue/#interview-simulation","title":"Interview Simulation","text":"<pre><code>// Get timestamps for video sync\nresp, _ := client.TextToDialogue().GenerateWithTimestamps(ctx, &amp;elevenlabs.DialogueRequest{\n    Inputs: interviewDialogue,\n})\n\n// Decode audio\naudioData, _ := base64.StdEncoding.DecodeString(resp.AudioBase64)\n\n// Use segments for visual indicators\nfor _, seg := range resp.VoiceSegments {\n    fmt.Printf(\"Show speaker %s avatar from %.2fs to %.2fs\\n\",\n        seg.VoiceID, seg.StartTime, seg.EndTime)\n}\n</code></pre>"},{"location":"services/text-to-dialogue/#voice-selection-tips","title":"Voice Selection Tips","text":"<ol> <li>Use contrasting voices - Different genders, accents, or tones help distinguish speakers</li> <li>Match voice to character - Select voices that fit the persona</li> <li>Test combinations - Some voice pairs work better together</li> </ol> <pre><code>// Get available voices\nvoices, _ := client.Voices().List(ctx)\n\n// Filter by characteristics\nvar maleVoices, femaleVoices []elevenlabs.Voice\nfor _, v := range voices {\n    if v.Labels[\"gender\"] == \"male\" {\n        maleVoices = append(maleVoices, v)\n    } else {\n        femaleVoices = append(femaleVoices, v)\n    }\n}\n</code></pre>"},{"location":"services/text-to-dialogue/#best-practices","title":"Best Practices","text":"<ol> <li>Keep turns natural - Avoid very long monologues</li> <li>Use appropriate voices - Match voice characteristics to roles</li> <li>Add pauses naturally - Include \"...\" or commas for natural pauses</li> <li>Test with timestamps - Verify timing for video sync use cases</li> <li>Use consistent voice IDs - Don't mix up which voice is which speaker</li> </ol>"},{"location":"services/text-to-speech/","title":"Text-to-Speech","text":"<p>The Text-to-Speech service converts text into natural-sounding speech.</p>"},{"location":"services/text-to-speech/#basic-usage","title":"Basic Usage","text":""},{"location":"services/text-to-speech/#simple-generation","title":"Simple Generation","text":"<pre><code>audio, err := client.TextToSpeech().Simple(ctx, voiceID, \"Your text here\")\nif err != nil {\n    log.Fatal(err)\n}\n\n// audio is an io.Reader - save or stream it\nf, _ := os.Create(\"output.mp3\")\nio.Copy(f, audio)\n</code></pre>"},{"location":"services/text-to-speech/#full-control","title":"Full Control","text":"<pre><code>resp, err := client.TextToSpeech().Generate(ctx, &amp;elevenlabs.TTSRequest{\n    VoiceID: \"21m00Tcm4TlvDq8ikWAM\",\n    Text:    \"Hello world!\",\n    ModelID: \"eleven_multilingual_v2\",\n    VoiceSettings: &amp;elevenlabs.VoiceSettings{\n        Stability:       0.5,\n        SimilarityBoost: 0.75,\n        Style:           0.0,\n        SpeakerBoost:    true,\n    },\n    OutputFormat: \"mp3_44100_128\",\n})\n</code></pre>"},{"location":"services/text-to-speech/#voice-settings","title":"Voice Settings","text":"Setting Range Description <code>Stability</code> 0.0-1.0 Higher = more consistent, lower = more expressive <code>SimilarityBoost</code> 0.0-1.0 Higher = closer to original voice <code>Style</code> 0.0-1.0 Style exaggeration (use sparingly) <code>SpeakerBoost</code> bool Enhance speaker similarity <code>Speed</code> 0.7-1.2 Speech speed multiplier"},{"location":"services/text-to-speech/#default-settings","title":"Default Settings","text":"<pre><code>settings := elevenlabs.DefaultVoiceSettings()\n// Stability: 0.5, SimilarityBoost: 0.75, Style: 0, SpeakerBoost: true\n</code></pre>"},{"location":"services/text-to-speech/#output-formats","title":"Output Formats","text":"Format Description <code>mp3_44100_128</code> MP3, 44.1kHz, 128kbps (default) <code>mp3_44100_192</code> MP3, 44.1kHz, 192kbps <code>pcm_16000</code> PCM, 16kHz <code>pcm_22050</code> PCM, 22.05kHz <code>pcm_24000</code> PCM, 24kHz <code>pcm_44100</code> PCM, 44.1kHz <code>ulaw_8000</code> u-law, 8kHz"},{"location":"services/text-to-speech/#models","title":"Models","text":"Model ID Best For <code>eleven_multilingual_v2</code> Multiple languages, highest quality <code>eleven_monolingual_v1</code> English only, fast <code>eleven_turbo_v2</code> Low latency applications <code>eleven_turbo_v2_5</code> Lowest latency"},{"location":"services/text-to-speech/#streaming","title":"Streaming","text":"<p>For real-time applications, use streaming:</p> <pre><code>resp, err := client.TextToSpeech().GenerateStream(ctx, &amp;elevenlabs.TTSRequest{\n    VoiceID: voiceID,\n    Text:    \"Long text to stream...\",\n})\nif err != nil {\n    log.Fatal(err)\n}\n\n// Stream audio chunks as they arrive\nfor chunk := range resp.Chunks {\n    // Process chunk\n}\n</code></pre>"},{"location":"services/text-to-speech/#error-handling","title":"Error Handling","text":"<pre><code>audio, err := client.TextToSpeech().Simple(ctx, voiceID, text)\nif err != nil {\n    if elevenlabs.IsRateLimitError(err) {\n        // Wait and retry\n        time.Sleep(time.Minute)\n    } else if elevenlabs.IsUnauthorizedError(err) {\n        // Check API key\n    }\n    return err\n}\n</code></pre>"},{"location":"services/text-to-speech/#best-practices","title":"Best Practices","text":"<ol> <li>Reuse the client - Create one client and reuse it</li> <li>Check character limits - Monitor <code>CharactersRemaining()</code> before generation</li> <li>Use appropriate models - <code>turbo</code> for speed, <code>multilingual_v2</code> for quality</li> <li>Batch when possible - Combine short texts to reduce API calls</li> </ol>"},{"location":"services/twilio/","title":"Twilio Integration","text":"<p>Phone call integration for ElevenLabs conversational AI agents.</p>"},{"location":"services/twilio/#overview","title":"Overview","text":"<p>The Twilio integration enables:</p> <ul> <li>Incoming Calls: Route Twilio calls to ElevenLabs agents</li> <li>Outbound Calls: Initiate calls from ElevenLabs agents</li> <li>SIP Trunks: Connect via SIP infrastructure</li> <li>Phone Number Management: Manage agent phone numbers</li> </ul>"},{"location":"services/twilio/#registering-incoming-calls","title":"Registering Incoming Calls","text":"<p>When Twilio receives a call, register it with ElevenLabs:</p> <pre><code>// In your Twilio webhook handler\nfunc handleIncomingCall(w http.ResponseWriter, r *http.Request) {\n    resp, err := client.Twilio().RegisterCall(ctx, &amp;elevenlabs.TwilioRegisterCallRequest{\n        AgentID: \"your-agent-id\",\n    })\n    if err != nil {\n        http.Error(w, err.Error(), 500)\n        return\n    }\n\n    // Return TwiML to Twilio\n    w.Header().Set(\"Content-Type\", \"application/xml\")\n    w.Write([]byte(resp.TwiML))\n}\n</code></pre>"},{"location":"services/twilio/#with-dynamic-variables","title":"With Dynamic Variables","text":"<p>Inject context into the agent conversation:</p> <pre><code>resp, err := client.Twilio().RegisterCall(ctx, &amp;elevenlabs.TwilioRegisterCallRequest{\n    AgentID: \"your-agent-id\",\n\n    // Dynamic variables for prompt injection\n    DynamicVariables: map[string]string{\n        \"caller_name\":    callerInfo.Name,\n        \"account_number\": callerInfo.AccountNumber,\n        \"call_reason\":    \"support\",\n    },\n\n    // Override first message\n    FirstMessage: fmt.Sprintf(\"Hello %s, how can I help you today?\", callerInfo.Name),\n\n    // Override system prompt\n    SystemPrompt: \"You are a helpful customer support agent...\",\n})\n</code></pre>"},{"location":"services/twilio/#making-outbound-calls","title":"Making Outbound Calls","text":"<p>Initiate calls from your ElevenLabs agent:</p> <pre><code>call, err := client.Twilio().OutboundCall(ctx, &amp;elevenlabs.TwilioOutboundCallRequest{\n    // Required fields\n    AgentID:            \"your-agent-id\",\n    AgentPhoneNumberID: \"phone-number-id\",\n    ToNumber:           \"+1234567890\",\n\n    // Optional overrides\n    FirstMessage: \"Hi, this is a call from your service.\",\n    DynamicVariables: map[string]string{\n        \"customer_name\": \"John\",\n        \"order_id\":      \"12345\",\n    },\n})\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Call SID: %s\\n\", call.CallSID)\nfmt.Printf(\"Conversation ID: %s\\n\", call.ConversationID)\n</code></pre>"},{"location":"services/twilio/#sip-trunk-outbound-calls","title":"SIP Trunk Outbound Calls","text":"<p>For SIP-based infrastructure:</p> <pre><code>call, err := client.Twilio().SIPOutboundCall(ctx, &amp;elevenlabs.SIPOutboundCallRequest{\n    AgentID:    \"your-agent-id\",\n    SIPTrunkID: \"sip-trunk-id\",\n    ToNumber:   \"+1234567890\",\n    FromNumber: \"+0987654321\", // Verified caller ID\n\n    DynamicVariables: map[string]string{\n        \"context\": \"outbound_campaign\",\n    },\n})\n</code></pre>"},{"location":"services/twilio/#phone-number-management","title":"Phone Number Management","text":""},{"location":"services/twilio/#list-phone-numbers","title":"List Phone Numbers","text":"<pre><code>numbers, err := client.PhoneNumbers().List(ctx)\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, num := range numbers {\n    fmt.Printf(\"%s: %s (%s)\\n\", num.Label, num.PhoneNumber, num.Status)\n}\n</code></pre>"},{"location":"services/twilio/#get-phone-number-details","title":"Get Phone Number Details","text":"<pre><code>number, err := client.PhoneNumbers().Get(ctx, \"phone-number-id\")\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Number: %s\\n\", number.PhoneNumber)\nfmt.Printf(\"Agent: %s\\n\", number.AgentID)\nfmt.Printf(\"Provider: %s\\n\", number.Provider)\n</code></pre>"},{"location":"services/twilio/#update-phone-number","title":"Update Phone Number","text":"<pre><code>updated, err := client.PhoneNumbers().Update(ctx, \"phone-number-id\",\n    &amp;elevenlabs.UpdatePhoneNumberRequest{\n        Label:   \"Customer Support Line\",\n        AgentID: \"new-agent-id\",\n    })\n</code></pre>"},{"location":"services/twilio/#delete-phone-number","title":"Delete Phone Number","text":"<pre><code>err := client.PhoneNumbers().Delete(ctx, \"phone-number-id\")\n</code></pre>"},{"location":"services/twilio/#request-types","title":"Request Types","text":""},{"location":"services/twilio/#twilioregistercallrequest","title":"TwilioRegisterCallRequest","text":"Field Type Required Description <code>AgentID</code> string Yes ElevenLabs agent ID <code>AgentPhoneNumberID</code> string No Phone number ID <code>DynamicVariables</code> map[string]string No Prompt variables <code>FirstMessage</code> string No Override first message <code>SystemPrompt</code> string No Override system prompt <code>CustomLLMExtraBody</code> map[string]any No Extra LLM data"},{"location":"services/twilio/#twiliooutboundcallrequest","title":"TwilioOutboundCallRequest","text":"Field Type Required Description <code>AgentID</code> string Yes ElevenLabs agent ID <code>AgentPhoneNumberID</code> string Yes From phone number ID <code>ToNumber</code> string Yes Destination (E.164 format) <code>DynamicVariables</code> map[string]string No Prompt variables <code>FirstMessage</code> string No Override first message <code>SystemPrompt</code> string No Override system prompt"},{"location":"services/twilio/#sipoutboundcallrequest","title":"SIPOutboundCallRequest","text":"Field Type Required Description <code>AgentID</code> string Yes ElevenLabs agent ID <code>SIPTrunkID</code> string Yes SIP trunk ID <code>ToNumber</code> string Yes Destination (E.164 format) <code>FromNumber</code> string No Caller ID (must be verified) <code>DynamicVariables</code> map[string]string No Prompt variables"},{"location":"services/twilio/#example-full-integration","title":"Example: Full Integration","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"log\"\n    \"net/http\"\n\n    elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n)\n\nvar client *elevenlabs.Client\n\nfunc main() {\n    var err error\n    client, err = elevenlabs.NewClient()\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    http.HandleFunc(\"/twilio/incoming\", handleIncoming)\n    http.HandleFunc(\"/api/call\", handleOutbound)\n\n    log.Println(\"Starting server on :8080\")\n    log.Fatal(http.ListenAndServe(\":8080\", nil))\n}\n\nfunc handleIncoming(w http.ResponseWriter, r *http.Request) {\n    ctx := r.Context()\n\n    // Get caller info from Twilio parameters\n    callerNumber := r.FormValue(\"From\")\n\n    resp, err := client.Twilio().RegisterCall(ctx, &amp;elevenlabs.TwilioRegisterCallRequest{\n        AgentID: \"your-agent-id\",\n        DynamicVariables: map[string]string{\n            \"caller_number\": callerNumber,\n        },\n    })\n    if err != nil {\n        log.Printf(\"register call error: %v\", err)\n        http.Error(w, \"error\", 500)\n        return\n    }\n\n    w.Header().Set(\"Content-Type\", \"application/xml\")\n    w.Write([]byte(resp.TwiML))\n}\n\nfunc handleOutbound(w http.ResponseWriter, r *http.Request) {\n    ctx := r.Context()\n    toNumber := r.URL.Query().Get(\"to\")\n\n    call, err := client.Twilio().OutboundCall(ctx, &amp;elevenlabs.TwilioOutboundCallRequest{\n        AgentID:            \"your-agent-id\",\n        AgentPhoneNumberID: \"phone-number-id\",\n        ToNumber:           toNumber,\n    })\n    if err != nil {\n        http.Error(w, err.Error(), 500)\n        return\n    }\n\n    w.Write([]byte(\"Call initiated: \" + call.CallSID))\n}\n</code></pre>"},{"location":"services/user/","title":"User","text":"<p>Access user information and subscription details.</p>"},{"location":"services/user/#get-user-info","title":"Get User Info","text":"<pre><code>user, err := client.User().GetInfo(ctx)\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"User ID: %s\\n\", user.UserID)\nfmt.Printf(\"First Name: %s\\n\", user.FirstName)\n</code></pre>"},{"location":"services/user/#user-object","title":"User Object","text":"Field Description <code>UserID</code> Unique identifier <code>FirstName</code> User's first name <code>IsNewUser</code> Whether user is new <code>CanUseDelayedPaymentMethods</code> Payment options available"},{"location":"services/user/#get-subscription","title":"Get Subscription","text":"<pre><code>sub, err := client.User().GetSubscription(ctx)\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Tier: %s\\n\", sub.Tier)\nfmt.Printf(\"Characters Used: %d\\n\", sub.CharacterCount)\nfmt.Printf(\"Character Limit: %d\\n\", sub.CharacterLimit)\nfmt.Printf(\"Remaining: %d\\n\", sub.CharactersRemaining())\n</code></pre>"},{"location":"services/user/#subscription-object","title":"Subscription Object","text":"Field Description <code>Tier</code> Subscription tier <code>CharacterCount</code> Characters used this period <code>CharacterLimit</code> Maximum characters allowed <code>Status</code> Subscription status <code>NextBillingDate</code> Next billing date <code>Currency</code> Billing currency <code>InvoiceInfo</code> Invoice details"},{"location":"services/user/#check-characters-remaining","title":"Check Characters Remaining","text":"<pre><code>sub, _ := client.User().GetSubscription(ctx)\n\nremaining := sub.CharactersRemaining()\nif remaining &lt; 1000 {\n    fmt.Println(\"Warning: Low character balance!\")\n}\n</code></pre>"},{"location":"services/user/#subscription-tiers","title":"Subscription Tiers","text":"Tier Characters/Month Free 10,000 Starter 30,000 Creator 100,000 Pro 500,000 Scale 2,000,000 Enterprise Custom"},{"location":"services/user/#pre-generation-check","title":"Pre-Generation Check","text":"<p>Always check before generating audio:</p> <pre><code>func generateSafely(client *elevenlabs.Client, text string) error {\n    sub, err := client.User().GetSubscription(context.Background())\n    if err != nil {\n        return err\n    }\n\n    charCount := len(text)\n    if sub.CharactersRemaining() &lt; charCount {\n        return fmt.Errorf(\"insufficient characters: need %d, have %d\",\n            charCount, sub.CharactersRemaining())\n    }\n\n    // Safe to generate\n    _, err = client.TextToSpeech().Simple(context.Background(), voiceID, text)\n    return err\n}\n</code></pre>"},{"location":"services/user/#monitor-usage","title":"Monitor Usage","text":"<pre><code>func printUsageReport(client *elevenlabs.Client) {\n    sub, _ := client.User().GetSubscription(context.Background())\n\n    used := sub.CharacterCount\n    limit := sub.CharacterLimit\n    remaining := sub.CharactersRemaining()\n    pct := float64(used) / float64(limit) * 100\n\n    fmt.Printf(\"Usage Report\\n\")\n    fmt.Printf(\"============\\n\")\n    fmt.Printf(\"Tier: %s\\n\", sub.Tier)\n    fmt.Printf(\"Used: %d / %d (%.1f%%)\\n\", used, limit, pct)\n    fmt.Printf(\"Remaining: %d\\n\", remaining)\n}\n</code></pre>"},{"location":"services/voice-design/","title":"Voice Design","text":"<p>Generate custom AI voices with specific characteristics like gender, age, and accent.</p>"},{"location":"services/voice-design/#basic-usage","title":"Basic Usage","text":"<pre><code>// Generate a voice preview\nresp, err := client.VoiceDesign().Simple(ctx,\n    elevenlabs.VoiceGenderFemale,\n    elevenlabs.VoiceAgeYoung,\n    elevenlabs.VoiceAccentAmerican,\n    \"This is a preview of the generated voice. It should be at least one hundred characters long for the best quality results.\",\n)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Listen to the preview\nf, _ := os.Create(\"voice_preview.mp3\")\nio.Copy(f, resp.Audio)\n</code></pre>"},{"location":"services/voice-design/#full-options","title":"Full Options","text":"<pre><code>resp, err := client.VoiceDesign().GeneratePreview(ctx, &amp;elevenlabs.VoiceDesignRequest{\n    Gender:         elevenlabs.VoiceGenderFemale,\n    Age:            elevenlabs.VoiceAgeYoung,\n    Accent:         elevenlabs.VoiceAccentBritish,\n    AccentStrength: 1.5,  // 0.3 to 2.0\n    Text:           \"This is a preview text that must be between one hundred and one thousand characters long for optimal voice generation quality.\",\n})\n</code></pre>"},{"location":"services/voice-design/#save-generated-voice","title":"Save Generated Voice","text":"<p>Once you like a preview, save it to your voice library:</p> <pre><code>// Generate preview\npreview, _ := client.VoiceDesign().GeneratePreview(ctx, &amp;elevenlabs.VoiceDesignRequest{\n    Gender: elevenlabs.VoiceGenderMale,\n    Age:    elevenlabs.VoiceAgeMiddleAged,\n    Accent: elevenlabs.VoiceAccentBritish,\n    Text:   sampleText,\n})\n\n// Save to library\nvoice, err := client.VoiceDesign().SaveVoice(ctx, &amp;elevenlabs.SaveVoiceRequest{\n    GeneratedVoiceID: preview.GeneratedVoiceID,\n    VoiceName:        \"British Narrator\",\n    VoiceDescription: \"Professional British male voice for narration\",\n    Labels: map[string]string{\n        \"use_case\": \"narration\",\n        \"style\":    \"professional\",\n    },\n})\n\nfmt.Printf(\"Saved voice ID: %s\\n\", voice.VoiceID)\n</code></pre>"},{"location":"services/voice-design/#voice-options","title":"Voice Options","text":""},{"location":"services/voice-design/#gender","title":"Gender","text":"<pre><code>elevenlabs.VoiceGenderFemale\nelevenlabs.VoiceGenderMale\n</code></pre>"},{"location":"services/voice-design/#age","title":"Age","text":"<pre><code>elevenlabs.VoiceAgeYoung       // Young adult\nelevenlabs.VoiceAgeMiddleAged  // Middle-aged\nelevenlabs.VoiceAgeOld         // Elderly\n</code></pre>"},{"location":"services/voice-design/#accent","title":"Accent","text":"<pre><code>elevenlabs.VoiceAccentAmerican\nelevenlabs.VoiceAccentBritish\nelevenlabs.VoiceAccentAustralian\nelevenlabs.VoiceAccentIndian\nelevenlabs.VoiceAccentAfrican\n</code></pre>"},{"location":"services/voice-design/#accent-strength","title":"Accent Strength","text":"Value Effect 0.3 Subtle accent 1.0 Normal (default) 1.5 Strong accent 2.0 Very strong accent"},{"location":"services/voice-design/#request-structure","title":"Request Structure","text":"<pre><code>type VoiceDesignRequest struct {\n    Gender         VoiceGender  // Required\n    Age            VoiceAge     // Required\n    Accent         VoiceAccent  // Required\n    AccentStrength float64      // 0.3 to 2.0 (default: 1.0)\n    Text           string       // 100-1000 characters\n}\n\ntype VoiceDesignResponse struct {\n    Audio            io.Reader // Preview audio\n    GeneratedVoiceID string    // ID to save the voice\n}\n\ntype SaveVoiceRequest struct {\n    GeneratedVoiceID string            // From preview response\n    VoiceName        string            // Name for saved voice\n    VoiceDescription string            // Optional description\n    Labels           map[string]string // Optional metadata\n}\n</code></pre>"},{"location":"services/voice-design/#use-cases","title":"Use Cases","text":""},{"location":"services/voice-design/#create-character-voices","title":"Create Character Voices","text":"<pre><code>characters := []struct {\n    Name   string\n    Gender elevenlabs.VoiceGender\n    Age    elevenlabs.VoiceAge\n    Accent elevenlabs.VoiceAccent\n}{\n    {\"Hero\", elevenlabs.VoiceGenderMale, elevenlabs.VoiceAgeYoung, elevenlabs.VoiceAccentAmerican},\n    {\"Mentor\", elevenlabs.VoiceGenderMale, elevenlabs.VoiceAgeOld, elevenlabs.VoiceAccentBritish},\n    {\"Sidekick\", elevenlabs.VoiceGenderFemale, elevenlabs.VoiceAgeYoung, elevenlabs.VoiceAccentAustralian},\n}\n\nsampleText := \"This is a sample of how this character will sound in the story. The text needs to be long enough for quality generation.\"\n\nfor _, char := range characters {\n    preview, _ := client.VoiceDesign().Simple(ctx, char.Gender, char.Age, char.Accent, sampleText)\n\n    // Save if satisfied\n    voice, _ := client.VoiceDesign().SaveVoice(ctx, &amp;elevenlabs.SaveVoiceRequest{\n        GeneratedVoiceID: preview.GeneratedVoiceID,\n        VoiceName:        char.Name,\n        Labels:           map[string]string{\"project\": \"audiobook\"},\n    })\n\n    fmt.Printf(\"Created %s voice: %s\\n\", char.Name, voice.VoiceID)\n}\n</code></pre>"},{"location":"services/voice-design/#ab-test-voices","title":"A/B Test Voices","text":"<pre><code>// Generate multiple previews with same parameters\nvar previews []*elevenlabs.VoiceDesignResponse\n\nfor i := 0; i &lt; 3; i++ {\n    preview, _ := client.VoiceDesign().GeneratePreview(ctx, &amp;elevenlabs.VoiceDesignRequest{\n        Gender: elevenlabs.VoiceGenderFemale,\n        Age:    elevenlabs.VoiceAgeYoung,\n        Accent: elevenlabs.VoiceAccentAmerican,\n        Text:   sampleText,\n    })\n    previews = append(previews, preview)\n\n    // Save preview audio for comparison\n    f, _ := os.Create(fmt.Sprintf(\"preview_%d.mp3\", i))\n    io.Copy(f, preview.Audio)\n    f.Close()\n}\n\n// Listen to all previews and save the best one\n</code></pre>"},{"location":"services/voice-design/#brand-voice-creation","title":"Brand Voice Creation","text":"<pre><code>// Define brand voice characteristics\nbrandVoice := elevenlabs.VoiceDesignRequest{\n    Gender:         elevenlabs.VoiceGenderFemale,\n    Age:            elevenlabs.VoiceAgeMiddleAged,\n    Accent:         elevenlabs.VoiceAccentAmerican,\n    AccentStrength: 0.5,  // Subtle accent for professionalism\n    Text:           \"Welcome to our service. We're here to help you succeed. Our team is dedicated to providing the best experience possible for all our customers.\",\n}\n\npreview, _ := client.VoiceDesign().GeneratePreview(ctx, &amp;brandVoice)\n\nvoice, _ := client.VoiceDesign().SaveVoice(ctx, &amp;elevenlabs.SaveVoiceRequest{\n    GeneratedVoiceID: preview.GeneratedVoiceID,\n    VoiceName:        \"Brand Voice - Main\",\n    VoiceDescription: \"Official brand voice for customer communications\",\n    Labels: map[string]string{\n        \"brand\":    \"true\",\n        \"approved\": \"true\",\n        \"use_case\": \"customer_service\",\n    },\n})\n</code></pre>"},{"location":"services/voice-design/#text-requirements","title":"Text Requirements","text":"<p>The preview text must be:</p> <ul> <li>Minimum: 100 characters</li> <li>Maximum: 1,000 characters</li> <li>Content: Representative of intended use</li> </ul> <p>Good preview text: <pre><code>text := `This is a sample of how this voice will sound when reading longer content.\nThe text should be representative of the actual content you plan to generate,\nincluding the style, tone, and type of vocabulary you'll be using.`\n</code></pre></p>"},{"location":"services/voice-design/#best-practices","title":"Best Practices","text":"<ol> <li>Use representative text - Preview text should match your intended use case</li> <li>Generate multiple previews - Each generation is unique; try several</li> <li>Test accent strength - Adjust for natural-sounding results</li> <li>Add descriptive labels - Makes organizing voices easier</li> <li>Save good voices immediately - Generated voice IDs may expire</li> </ol>"},{"location":"services/voices/","title":"Voices","text":"<p>The Voices service manages voice selection and settings.</p>"},{"location":"services/voices/#list-all-voices","title":"List All Voices","text":"<pre><code>voices, err := client.Voices().List(ctx)\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, v := range voices {\n    fmt.Printf(\"%s: %s (%s)\\n\", v.VoiceID, v.Name, v.Category)\n}\n</code></pre>"},{"location":"services/voices/#get-a-specific-voice","title":"Get a Specific Voice","text":"<pre><code>voice, err := client.Voices().Get(ctx, \"21m00Tcm4TlvDq8ikWAM\")\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Name: %s\\n\", voice.Name)\nfmt.Printf(\"Category: %s\\n\", voice.Category)\nfmt.Printf(\"Description: %s\\n\", voice.Description)\nfmt.Printf(\"Labels: %v\\n\", voice.Labels)\n</code></pre>"},{"location":"services/voices/#voice-object","title":"Voice Object","text":"Field Type Description <code>VoiceID</code> string Unique identifier <code>Name</code> string Display name <code>Category</code> string <code>premade</code>, <code>cloned</code>, <code>generated</code> <code>Description</code> string Voice description <code>Labels</code> map Metadata (accent, age, gender, etc.) <code>PreviewURL</code> string URL to preview audio"},{"location":"services/voices/#get-voice-settings","title":"Get Voice Settings","text":"<pre><code>settings, err := client.Voices().GetSettings(ctx, voiceID)\nif err != nil {\n    log.Fatal(err)\n}\n\nfmt.Printf(\"Stability: %f\\n\", settings.Stability)\nfmt.Printf(\"Similarity Boost: %f\\n\", settings.SimilarityBoost)\n</code></pre>"},{"location":"services/voices/#get-default-settings","title":"Get Default Settings","text":"<pre><code>defaults, err := client.Voices().GetDefaultSettings(ctx)\n</code></pre>"},{"location":"services/voices/#popular-pre-made-voices","title":"Popular Pre-made Voices","text":"Voice ID Name Description <code>21m00Tcm4TlvDq8ikWAM</code> Rachel Calm, narration <code>AZnzlk1XvdvUeBnXmlld</code> Domi Strong, confident <code>EXAVITQu4vr4xnSDxMaL</code> Bella Soft, gentle <code>ErXwobaYiN019PkySvjV</code> Antoni Well-rounded <code>MF3mGyEYCl7XYWbV9V6O</code> Elli Emotional range"},{"location":"services/voices/#finding-the-right-voice","title":"Finding the Right Voice","text":"<pre><code>voices, _ := client.Voices().List(ctx)\n\n// Filter by category\nfor _, v := range voices {\n    if v.Category == \"premade\" {\n        // Pre-made voices\n    }\n}\n\n// Filter by labels\nfor _, v := range voices {\n    if accent, ok := v.Labels[\"accent\"]; ok &amp;&amp; accent == \"american\" {\n        // American accent voices\n    }\n}\n</code></pre>"},{"location":"services/voices/#voice-selection-tips","title":"Voice Selection Tips","text":"<ol> <li>For narration: Use calm, neutral voices (Rachel, Antoni)</li> <li>For characters: Match voice personality to character</li> <li>For multilingual: Check voice language support</li> <li>Test first: Use preview URLs before committing</li> </ol>"},{"location":"services/websocket-stt/","title":"WebSocket STT","text":"<p>Real-time speech-to-text streaming via WebSocket for live transcription.</p>"},{"location":"services/websocket-stt/#overview","title":"Overview","text":"<p>The WebSocket STT service enables real-time audio transcription with:</p> <ul> <li>Partial Results: Get interim transcripts for responsive UIs</li> <li>Word Timing: Word-level timestamps and confidence scores</li> <li>Language Detection: Automatic language identification</li> <li>Low Latency: Stream audio as it's captured</li> </ul>"},{"location":"services/websocket-stt/#basic-usage","title":"Basic Usage","text":"<pre><code>// Connect to WebSocket STT\nconn, err := client.WebSocketSTT().Connect(ctx, nil)\nif err != nil {\n    log.Fatal(err)\n}\ndefer conn.Close()\n\n// Send audio chunks\ngo func() {\n    for {\n        audioChunk := captureAudio() // Your audio capture function\n        if err := conn.SendAudio(audioChunk); err != nil {\n            return\n        }\n    }\n}()\n\n// Receive transcripts\nfor transcript := range conn.Transcripts() {\n    if transcript.IsFinal {\n        fmt.Println(\"Final:\", transcript.Text)\n    } else {\n        fmt.Println(\"Partial:\", transcript.Text)\n    }\n}\n</code></pre>"},{"location":"services/websocket-stt/#with-options","title":"With Options","text":"<pre><code>opts := &amp;elevenlabs.WebSocketSTTOptions{\n    // Scribe model for transcription\n    ModelID: \"scribe_v1\",\n\n    // Audio settings\n    SampleRate: 16000,\n    Encoding:   \"pcm_s16le\",\n\n    // Enable partial/interim results\n    EnablePartials: true,\n\n    // Get word-level timing\n    EnableWordTimestamps: true,\n\n    // Specify language (or leave empty for auto-detect)\n    LanguageCode: \"en\",\n}\n\nconn, err := client.WebSocketSTT().Connect(ctx, opts)\n</code></pre>"},{"location":"services/websocket-stt/#streaming-from-microphone","title":"Streaming from Microphone","text":"<pre><code>// Connect to STT\nconn, err := client.WebSocketSTT().Connect(ctx, &amp;elevenlabs.WebSocketSTTOptions{\n    SampleRate:           16000,\n    Encoding:             \"pcm_s16le\",\n    EnablePartials:       true,\n    EnableWordTimestamps: true,\n})\nif err != nil {\n    log.Fatal(err)\n}\ndefer conn.Close()\n\n// Stream microphone audio\ngo func() {\n    for {\n        chunk, err := microphone.Read()\n        if err != nil {\n            conn.EndStream()\n            return\n        }\n        conn.SendAudio(chunk)\n    }\n}()\n\n// Display transcripts\nfor transcript := range conn.Transcripts() {\n    if transcript.IsFinal {\n        fmt.Printf(\"\\n[FINAL] %s\\n\", transcript.Text)\n    } else {\n        fmt.Printf(\"\\r[...] %s\", transcript.Text)\n    }\n}\n</code></pre>"},{"location":"services/websocket-stt/#using-streamaudio-helper","title":"Using StreamAudio Helper","text":"<pre><code>// Create audio input channel\naudioStream := make(chan []byte)\n\n// Start streaming (handles EndStream automatically)\ntranscriptOut, errOut := conn.StreamAudio(ctx, audioStream)\n\n// Send audio chunks\ngo func() {\n    defer close(audioStream)\n    for {\n        chunk := captureAudio()\n        audioStream &lt;- chunk\n    }\n}()\n\n// Receive transcripts\nfor transcript := range transcriptOut {\n    fmt.Println(transcript.Text)\n}\n\n// Check for errors\nif err := &lt;-errOut; err != nil {\n    log.Printf(\"streaming error: %v\", err)\n}\n</code></pre>"},{"location":"services/websocket-stt/#word-level-timing","title":"Word-Level Timing","text":"<pre><code>for transcript := range conn.Transcripts() {\n    if transcript.IsFinal &amp;&amp; len(transcript.Words) &gt; 0 {\n        fmt.Printf(\"Transcript: %s\\n\", transcript.Text)\n        fmt.Printf(\"Language: %s\\n\", transcript.LanguageCode)\n        fmt.Printf(\"Confidence: %.2f\\n\", transcript.Confidence)\n\n        for _, word := range transcript.Words {\n            fmt.Printf(\"  '%s': %.3fs - %.3fs (conf: %.2f)\\n\",\n                word.Word,\n                word.Start,\n                word.End,\n                word.Confidence)\n        }\n    }\n}\n</code></pre>"},{"location":"services/websocket-stt/#error-handling","title":"Error Handling","text":"<pre><code>// Monitor errors\ngo func() {\n    for err := range conn.Errors() {\n        log.Printf(\"WebSocket STT error: %v\", err)\n    }\n}()\n</code></pre>"},{"location":"services/websocket-stt/#options-reference","title":"Options Reference","text":"Option Type Default Description <code>ModelID</code> string <code>scribe_v1</code> Transcription model <code>SampleRate</code> int 16000 Audio sample rate in Hz <code>Encoding</code> string <code>pcm_s16le</code> Audio encoding format <code>LanguageCode</code> string \"\" Expected language (auto-detect if empty) <code>EnablePartials</code> bool true Enable interim results <code>EnableWordTimestamps</code> bool true Include word timing <code>MaxAlternatives</code> int 0 Number of alternative transcripts"},{"location":"services/websocket-stt/#transcript-fields","title":"Transcript Fields","text":"Field Type Description <code>Text</code> string Transcribed text <code>IsFinal</code> bool True if final result <code>Confidence</code> float64 Overall confidence (0-1) <code>Words</code> []STTWord Word-level details <code>LanguageCode</code> string Detected language <code>StartTime</code> float64 Start time in seconds <code>EndTime</code> float64 End time in seconds"},{"location":"services/websocket-stt/#audio-formats","title":"Audio Formats","text":"<p>Supported audio encodings:</p> <ul> <li><code>pcm_s16le</code> - 16-bit signed little-endian PCM (recommended)</li> <li><code>pcm_mulaw</code> - 8-bit mu-law PCM (telephony)</li> </ul> <p>Common sample rates:</p> <ul> <li>8000 Hz - Telephony</li> <li>16000 Hz - Voice (recommended)</li> <li>22050 Hz - High quality voice</li> <li>44100 Hz - CD quality</li> </ul>"},{"location":"services/websocket-tts/","title":"WebSocket TTS","text":"<p>Real-time text-to-speech streaming via WebSocket for low-latency voice synthesis.</p>"},{"location":"services/websocket-tts/#overview","title":"Overview","text":"<p>The WebSocket TTS service enables streaming text to speech in real-time, making it ideal for:</p> <ul> <li>LLM Integration: Stream text from language models as it's generated</li> <li>Interactive Applications: Voice assistants, chatbots, real-time narration</li> <li>Low Latency: Get audio output before the full text is available</li> </ul>"},{"location":"services/websocket-tts/#basic-usage","title":"Basic Usage","text":"<pre><code>// Connect to WebSocket TTS\nconn, err := client.WebSocketTTS().Connect(ctx, voiceID, nil)\nif err != nil {\n    log.Fatal(err)\n}\ndefer conn.Close()\n\n// Send text\nconn.SendText(\"Hello, \")\nconn.SendText(\"this is streaming \")\nconn.SendText(\"text to speech!\")\n\n// Flush to finalize\nconn.Flush()\n\n// Receive audio chunks\nfor audio := range conn.Audio() {\n    // Play or save audio chunks\n    player.Write(audio)\n}\n</code></pre>"},{"location":"services/websocket-tts/#with-options","title":"With Options","text":"<pre><code>opts := &amp;elevenlabs.WebSocketTTSOptions{\n    // Use turbo model for lowest latency\n    ModelID: \"eleven_turbo_v2_5\",\n\n    // PCM format for real-time playback\n    OutputFormat: \"pcm_16000\",\n\n    // Latency optimization (0-4, higher = faster but lower quality)\n    OptimizeStreamingLatency: 3,\n\n    // Enable SSML parsing\n    EnableSSMLParsing: true,\n\n    // Voice settings\n    VoiceSettings: &amp;elevenlabs.VoiceSettings{\n        Stability:       0.5,\n        SimilarityBoost: 0.75,\n    },\n}\n\nconn, err := client.WebSocketTTS().Connect(ctx, voiceID, opts)\n</code></pre>"},{"location":"services/websocket-tts/#streaming-from-llm","title":"Streaming from LLM","text":"<pre><code>// Connect to TTS\nconn, err := client.WebSocketTTS().Connect(ctx, voiceID, &amp;elevenlabs.WebSocketTTSOptions{\n    ModelID:                  \"eleven_turbo_v2_5\",\n    OutputFormat:             \"pcm_16000\",\n    OptimizeStreamingLatency: 3,\n})\nif err != nil {\n    log.Fatal(err)\n}\ndefer conn.Close()\n\n// Stream LLM output to TTS\ngo func() {\n    for chunk := range llmOutputStream {\n        if err := conn.SendText(chunk); err != nil {\n            log.Printf(\"send error: %v\", err)\n            return\n        }\n    }\n    conn.Flush()\n}()\n\n// Play audio as it arrives\nfor audio := range conn.Audio() {\n    audioPlayer.Write(audio)\n}\n</code></pre>"},{"location":"services/websocket-tts/#using-streamtext-helper","title":"Using StreamText Helper","text":"<pre><code>// Create a channel of text chunks\ntextStream := make(chan string)\n\n// Start streaming (this handles flushing automatically)\naudioOut, errOut := conn.StreamText(ctx, textStream)\n\n// Send text chunks\ngo func() {\n    defer close(textStream)\n    textStream &lt;- \"Hello, \"\n    textStream &lt;- \"world!\"\n}()\n\n// Receive audio\nfor audio := range audioOut {\n    // Process audio\n}\n\n// Check for errors\nif err := &lt;-errOut; err != nil {\n    log.Printf(\"streaming error: %v\", err)\n}\n</code></pre>"},{"location":"services/websocket-tts/#word-alignments","title":"Word Alignments","text":"<pre><code>// Receive word-level timing\ngo func() {\n    for align := range conn.Alignments() {\n        for i, char := range align.Characters {\n            fmt.Printf(\"%s: %.3fs - %.3fs\\n\",\n                char,\n                align.CharacterStart[i],\n                align.CharacterEnd[i])\n        }\n    }\n}()\n</code></pre>"},{"location":"services/websocket-tts/#error-handling","title":"Error Handling","text":"<pre><code>// Monitor errors\ngo func() {\n    for err := range conn.Errors() {\n        log.Printf(\"WebSocket error: %v\", err)\n    }\n}()\n</code></pre>"},{"location":"services/websocket-tts/#options-reference","title":"Options Reference","text":"Option Type Default Description <code>ModelID</code> string <code>eleven_turbo_v2_5</code> TTS model to use <code>OutputFormat</code> string <code>pcm_16000</code> Audio format <code>VoiceSettings</code> *VoiceSettings nil Voice parameters <code>OptimizeStreamingLatency</code> int 3 Latency vs quality (0-4) <code>EnableSSMLParsing</code> bool false Parse SSML in text <code>LanguageCode</code> string \"\" ISO language code <code>ChunkLengthSchedule</code> []int nil Custom chunking <code>InactivityTimeout</code> int 20 Timeout in seconds"},{"location":"services/websocket-tts/#output-formats","title":"Output Formats","text":"<p>For real-time playback, PCM formats are recommended:</p> <ul> <li><code>pcm_16000</code> - 16kHz PCM (lowest latency)</li> <li><code>pcm_22050</code> - 22.05kHz PCM</li> <li><code>pcm_24000</code> - 24kHz PCM</li> <li><code>pcm_44100</code> - 44.1kHz PCM (highest quality)</li> </ul> <p>MP3 formats are also available but add encoding latency:</p> <ul> <li><code>mp3_44100_64</code> - 64kbps MP3</li> <li><code>mp3_44100_128</code> - 128kbps MP3</li> <li><code>mp3_44100_192</code> - 192kbps MP3</li> </ul>"},{"location":"utilities/retryhttp/","title":"Retry HTTP Transport","text":"<p>The <code>retryhttp</code> package provides an HTTP RoundTripper with exponential backoff retry logic, designed to work seamlessly with the ElevenLabs client and any other HTTP client.</p> <p>This package is part of mogo and can be used with any HTTP client.</p>"},{"location":"utilities/retryhttp/#installation","title":"Installation","text":"<pre><code>import \"github.com/grokify/mogo/net/http/retryhttp\"\n</code></pre>"},{"location":"utilities/retryhttp/#quick-start","title":"Quick Start","text":""},{"location":"utilities/retryhttp/#basic-usage","title":"Basic Usage","text":"<pre><code>import (\n    elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n    \"github.com/grokify/mogo/net/http/retryhttp\"\n)\n\n// Create retry transport with defaults\nrt := retryhttp.New()\n\n// Use with ElevenLabs client\nclient, _ := elevenlabs.NewClient(\n    elevenlabs.WithHTTPClient(rt.Client()),\n)\n\n// API calls now automatically retry on rate limits\naudio, err := client.TextToSpeech().Simple(ctx, voiceID, \"Hello world\")\n</code></pre>"},{"location":"utilities/retryhttp/#with-custom-options","title":"With Custom Options","text":"<pre><code>rt := retryhttp.NewWithOptions(\n    retryhttp.WithMaxRetries(5),\n    retryhttp.WithInitialBackoff(500*time.Millisecond),\n    retryhttp.WithMaxBackoff(30*time.Second),\n    retryhttp.WithBackoffMultiplier(2.0),\n    retryhttp.WithJitter(0.1),\n)\n</code></pre>"},{"location":"utilities/retryhttp/#configuration-options","title":"Configuration Options","text":"Option Default Description <code>WithMaxRetries(n)</code> 3 Maximum retry attempts <code>WithInitialBackoff(d)</code> 1s Initial backoff duration <code>WithMaxBackoff(d)</code> 30s Maximum backoff duration <code>WithBackoffMultiplier(m)</code> 2.0 Backoff multiplier per retry <code>WithJitter(j)</code> 0.1 Jitter factor (0.0-1.0) <code>WithTransport(t)</code> http.DefaultTransport Underlying transport <code>WithRetryableStatusCodes(codes)</code> 429, 500, 502, 503, 504 Status codes to retry <code>WithShouldRetry(fn)</code> - Custom retry decision function <code>WithOnRetry(fn)</code> - Callback before each retry <code>WithLogger(l)</code> nil (silent) Injectable <code>*slog.Logger</code> for error logging"},{"location":"utilities/retryhttp/#features","title":"Features","text":""},{"location":"utilities/retryhttp/#exponential-backoff","title":"Exponential Backoff","text":"<p>Backoff increases exponentially with each retry:</p> <pre><code>Attempt 0: 1s\nAttempt 1: 2s (1s \u00d7 2)\nAttempt 2: 4s (2s \u00d7 2)\nAttempt 3: 8s (4s \u00d7 2)\n...capped at MaxBackoff\n</code></pre>"},{"location":"utilities/retryhttp/#jitter","title":"Jitter","text":"<p>Random jitter prevents thundering herd when multiple clients retry simultaneously:</p> <pre><code>rt := retryhttp.NewWithOptions(\n    retryhttp.WithJitter(0.2), // \u00b120% randomness\n)\n</code></pre>"},{"location":"utilities/retryhttp/#retry-after-header","title":"Retry-After Header","text":"<p>The transport automatically respects <code>Retry-After</code> headers from the server:</p> <pre><code>// If server returns:\n// HTTP/1.1 429 Too Many Requests\n// Retry-After: 60\n//\n// The transport will wait 60 seconds before retrying\n</code></pre>"},{"location":"utilities/retryhttp/#retry-callback","title":"Retry Callback","text":"<p>Monitor retry behavior with a callback:</p> <pre><code>rt := retryhttp.NewWithOptions(\n    retryhttp.WithOnRetry(func(attempt int, req *http.Request, resp *http.Response, err error, backoff time.Duration) {\n        log.Printf(\"Retry %d: status=%d, waiting %v\", attempt, resp.StatusCode, backoff)\n    }),\n)\n</code></pre>"},{"location":"utilities/retryhttp/#custom-retry-logic","title":"Custom Retry Logic","text":"<p>Override the default retry decision:</p> <pre><code>rt := retryhttp.NewWithOptions(\n    retryhttp.WithShouldRetry(func(resp *http.Response, err error) bool {\n        if err != nil {\n            return true // Retry connection errors\n        }\n        // Custom logic: retry on specific error codes\n        return resp.StatusCode == 429 || resp.StatusCode &gt;= 500\n    }),\n)\n</code></pre>"},{"location":"utilities/retryhttp/#logging","title":"Logging","text":"<p>Inject a <code>*slog.Logger</code> to capture internal errors (e.g., response body drain failures):</p> <pre><code>import \"log/slog\"\n\nrt := retryhttp.NewWithOptions(\n    retryhttp.WithMaxRetries(3),\n    retryhttp.WithLogger(slog.Default()),\n)\n</code></pre> <p>If no logger is provided, internal errors are silently discarded using a null logger.</p>"},{"location":"utilities/retryhttp/#wrapping-existing-clients","title":"Wrapping Existing Clients","text":"<p>Wrap an existing <code>*http.Client</code> with retry logic:</p> <pre><code>existingClient := &amp;http.Client{\n    Timeout: 30 * time.Second,\n}\n\nretryClient := retryhttp.WrapClient(existingClient,\n    retryhttp.WithMaxRetries(3),\n)\n\n// Preserves Timeout, CheckRedirect, and Jar from original\n</code></pre>"},{"location":"utilities/retryhttp/#default-retryable-status-codes","title":"Default Retryable Status Codes","text":"<p>By default, these status codes trigger a retry:</p> <ul> <li>429 - Too Many Requests (rate limited)</li> <li>500 - Internal Server Error</li> <li>502 - Bad Gateway</li> <li>503 - Service Unavailable</li> <li>504 - Gateway Timeout</li> </ul>"},{"location":"utilities/retryhttp/#complete-example","title":"Complete Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"log\"\n    \"net/http\"\n    \"time\"\n\n    elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n    \"github.com/agentplexus/go-elevenlabs/voices\"\n    \"github.com/grokify/mogo/net/http/retryhttp\"\n)\n\nfunc main() {\n    // Create retry transport\n    rt := retryhttp.NewWithOptions(\n        retryhttp.WithMaxRetries(3),\n        retryhttp.WithInitialBackoff(1*time.Second),\n        retryhttp.WithOnRetry(func(attempt int, req *http.Request, resp *http.Response, err error, backoff time.Duration) {\n            log.Printf(\"Retry %d after %v\", attempt, backoff)\n        }),\n    )\n\n    // Create client with retry support\n    client, _ := elevenlabs.NewClient(\n        elevenlabs.WithHTTPClient(rt.Client()),\n    )\n\n    ctx := context.Background()\n\n    // API calls automatically retry on transient failures\n    audio, err := client.TextToSpeech().Simple(ctx, voices.Rachel, \"Hello!\")\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // Use audio...\n}\n</code></pre>"},{"location":"utilities/retryhttp/#architecture","title":"Architecture","text":"<p>The package implements <code>http.RoundTripper</code>, making it composable with any HTTP client:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ElevenLabs      \u2502\n\u2502 Client          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 http.Client     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 RetryTransport  \u2502 \u25c4\u2500\u2500 Handles retries\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 http.Default    \u2502\n\u2502 Transport       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"utilities/retryhttp/#compatibility","title":"Compatibility","text":"<p>The package implements Go's standard <code>http.RoundTripper</code> interface, making it compatible with any HTTP client:</p> SDK Generator Usage ogen <code>elevenlabs.WithHTTPClient(rt.Client())</code> OpenAPI-Generator <code>cfg.HTTPClient = rt.Client()</code> oapi-codegen <code>api.WithHTTPClient(rt.Client())</code> go-swagger Transport configuration Any <code>*http.Client</code> Set <code>Transport</code> field"},{"location":"utilities/retryhttp/#best-practices","title":"Best Practices","text":"<ol> <li>Set appropriate timeouts - Use context timeouts to prevent infinite retry loops</li> <li>Monitor retries - Use <code>WithOnRetry</code> to log retry attempts for debugging</li> <li>Tune backoff - Adjust <code>InitialBackoff</code> and <code>MaxBackoff</code> based on API characteristics</li> <li>Use jitter - Keep jitter enabled to prevent synchronized retries across clients</li> <li>Enable logging in production - Use <code>WithLogger</code> to capture internal errors</li> </ol>"},{"location":"utilities/ttsscript/","title":"TTS Script Package","text":"<p>The <code>ttsscript</code> package provides a structured format for authoring multilingual TTS scripts.</p>"},{"location":"utilities/ttsscript/#installation","title":"Installation","text":"<p>The package is included with go-elevenlabs:</p> <pre><code>import \"github.com/agentplexus/go-elevenlabs/ttsscript\"\n</code></pre>"},{"location":"utilities/ttsscript/#package-overview","title":"Package Overview","text":"<pre><code>ttsscript/\n\u251c\u2500\u2500 script.go      # Script, Slide, Segment types\n\u251c\u2500\u2500 compiler.go    # Compiler with pronunciation handling\n\u251c\u2500\u2500 ssml.go        # SSML formatter\n\u251c\u2500\u2500 elevenlabs.go  # ElevenLabs formatter\n\u2514\u2500\u2500 doc.go         # Package documentation\n</code></pre>"},{"location":"utilities/ttsscript/#types","title":"Types","text":""},{"location":"utilities/ttsscript/#script","title":"Script","text":"<pre><code>type Script struct {\n    Title           string\n    Description     string\n    DefaultLanguage string\n    DefaultVoices   map[string]string            // lang -&gt; voiceID\n    Pronunciations  map[string]map[string]string // term -&gt; lang -&gt; replacement\n    Slides          []Slide\n}\n</code></pre>"},{"location":"utilities/ttsscript/#slide","title":"Slide","text":"<pre><code>type Slide struct {\n    Title    string\n    Notes    string\n    Segments []Segment\n}\n</code></pre>"},{"location":"utilities/ttsscript/#segment","title":"Segment","text":"<pre><code>type Segment struct {\n    Text           map[string]string            // lang -&gt; text\n    Voice          map[string]string            // lang -&gt; voiceID (override)\n    PauseBefore    string                       // e.g., \"500ms\"\n    PauseAfter     string\n    Emphasis       string                       // \"strong\", \"moderate\", \"reduced\"\n    Rate           string                       // \"slow\", \"medium\", \"fast\"\n    Pitch          string                       // \"low\", \"medium\", \"high\"\n    Pronunciations map[string]map[string]string // segment-level overrides\n}\n</code></pre>"},{"location":"utilities/ttsscript/#compiledsegment","title":"CompiledSegment","text":"<pre><code>type CompiledSegment struct {\n    SlideIndex    int\n    SegmentIndex  int\n    SlideTitle    string\n    Text          string  // With pronunciations applied\n    OriginalText  string\n    VoiceID       string\n    Language      string\n    PauseBeforeMs int\n    PauseAfterMs  int\n    Emphasis      string\n    Rate          string\n    Pitch         string\n}\n</code></pre>"},{"location":"utilities/ttsscript/#functions","title":"Functions","text":""},{"location":"utilities/ttsscript/#loading-scripts","title":"Loading Scripts","text":"<pre><code>// Load from file\nscript, err := ttsscript.LoadScript(\"script.json\")\n\n// Parse from bytes\nscript, err := ttsscript.ParseScript(jsonData)\n\n// Save to file\nerr := script.Save(\"output.json\")\n</code></pre>"},{"location":"utilities/ttsscript/#script-methods","title":"Script Methods","text":"<pre><code>// Get all languages used\nlangs := script.Languages() // []string{\"en\", \"es\", \"fr\"}\n\n// Count slides and segments\nslideCount := script.SlideCount()\nsegmentCount := script.SegmentCount()\n\n// Validate the script\nissues := script.Validate() // []string of issues\n</code></pre>"},{"location":"utilities/ttsscript/#compiler","title":"Compiler","text":"<pre><code>// Create compiler\ncompiler := ttsscript.NewCompiler()\n\n// Configure defaults\ncompiler.DefaultPauseAfterSlide = \"800ms\"\ncompiler.DefaultPauseAfterSegment = \"200ms\"\n\n// Add pronunciations\ncompiler.AddPronunciation(\"API\", \"en\", \"A P I\")\ncompiler.AddPronunciations(\"en\", map[string]string{\n    \"SDK\": \"S D K\",\n    \"CLI\": \"C L I\",\n})\n\n// Compile for a language\nsegments, err := compiler.Compile(script, \"en\")\n</code></pre>"},{"location":"utilities/ttsscript/#ssml-formatter","title":"SSML Formatter","text":"<pre><code>formatter := ttsscript.NewSSMLFormatter()\nformatter.Version = \"1.1\"\nformatter.IncludeComments = true\nformatter.IndentSpaces = 2\n\n// Format compiled segments\nssml := formatter.Format(segments, \"en\")\n\n// Or format directly from script\nssml, err := formatter.FormatScript(script, \"en\")\n</code></pre>"},{"location":"utilities/ttsscript/#elevenlabs-formatter","title":"ElevenLabs Formatter","text":"<pre><code>formatter := ttsscript.NewElevenLabsFormatter()\nformatter.UsePauseMarkers = false\n\n// Format compiled segments\njobs := formatter.Format(segments)\n\n// Group by voice for batch processing\ngroups := formatter.GroupByVoice(jobs)\n\n// Combine for single request (loses voice control)\ntext := formatter.CombineForSingleRequest(jobs)\n</code></pre>"},{"location":"utilities/ttsscript/#batch-processing","title":"Batch Processing","text":"<pre><code>// Create batch config\nconfig := ttsscript.NewBatchConfig(\"./output\")\nconfig.FilePrefix = \"course\"\nconfig.IncludeLanguageInFilename = true\n\n// Generate filenames\nfilename := config.GenerateFilename(job, \"en\")\n// \"./output/course_slide01_seg01_en.mp3\"\n\n// Generate manifest\nmanifest := ttsscript.GenerateManifest(jobs, config, \"en\")\n</code></pre>"},{"location":"utilities/ttsscript/#utility-functions","title":"Utility Functions","text":"<pre><code>// Parse duration string to milliseconds\nms := ttsscript.ParseDuration(\"500ms\") // 500\nms := ttsscript.ParseDuration(\"1.5s\")  // 1500\n\n// Format milliseconds to string\ns := ttsscript.FormatDuration(500)  // \"500ms\"\ns := ttsscript.FormatDuration(2000) // \"2s\"\n\n// Group segments\nbyVoice := ttsscript.GroupByVoice(segments)\nbySlide := ttsscript.GroupBySlide(segments)\n\n// Combine text with pause markers\ntext := ttsscript.CombineText(segments)\n</code></pre>"},{"location":"utilities/ttsscript/#ssml-helpers","title":"SSML Helpers","text":"<pre><code>// Generate SSML elements\nbreak := ttsscript.SSMLBreak(\"500ms\")\n// &lt;break time=\"500ms\"/&gt;\n\nprosody := ttsscript.SSMLProsody(\"text\", \"slow\", \"+10%\", \"\")\n// &lt;prosody rate=\"slow\" pitch=\"+10%\"&gt;text&lt;/prosody&gt;\n\nemphasis := ttsscript.SSMLEmphasis(\"important\", \"strong\")\n// &lt;emphasis level=\"strong\"&gt;important&lt;/emphasis&gt;\n\nsayAs := ttsscript.SSMLSayAs(\"123-456-7890\", \"telephone\", \"\")\n// &lt;say-as interpret-as=\"telephone\"&gt;123-456-7890&lt;/say-as&gt;\n\nphoneme := ttsscript.SSMLPhoneme(\"tomato\", \"ipa\", \"t\u0259\u02c8me\u026ato\u028a\")\n// &lt;phoneme alphabet=\"ipa\" ph=\"t\u0259\u02c8me\u026ato\u028a\"&gt;tomato&lt;/phoneme&gt;\n\nsub := ttsscript.SSMLSub(\"API\", \"A P I\")\n// &lt;sub alias=\"A P I\"&gt;API&lt;/sub&gt;\n\n// Escape special characters\nescaped := ttsscript.EscapeSSML(\"Tom &amp; Jerry\")\n// \"Tom &amp;amp; Jerry\"\n</code></pre>"},{"location":"utilities/ttsscript/#example-complete-workflow","title":"Example: Complete Workflow","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"io\"\n    \"os\"\n\n    elevenlabs \"github.com/agentplexus/go-elevenlabs\"\n    \"github.com/agentplexus/go-elevenlabs/ttsscript\"\n)\n\nfunc main() {\n    // Load script\n    script, _ := ttsscript.LoadScript(\"course.json\")\n\n    // Create compiler with pronunciations\n    compiler := ttsscript.NewCompiler()\n    compiler.AddPronunciations(\"en\", map[string]string{\n        \"API\": \"A P I\",\n        \"SDK\": \"S D K\",\n    })\n\n    // Compile for English\n    segments, _ := compiler.Compile(script, \"en\")\n\n    // Format for ElevenLabs\n    formatter := ttsscript.NewElevenLabsFormatter()\n    jobs := formatter.Format(segments)\n\n    // Generate audio\n    client, _ := elevenlabs.NewClient()\n    ctx := context.Background()\n\n    os.MkdirAll(\"./output\", 0755)\n\n    for i, job := range jobs {\n        audio, _ := client.TextToSpeech().Simple(ctx, job.VoiceID, job.Text)\n\n        f, _ := os.Create(fmt.Sprintf(\"./output/segment_%02d.mp3\", i+1))\n        io.Copy(f, audio)\n        f.Close()\n\n        fmt.Printf(\"Generated: segment_%02d.mp3\\n\", i+1)\n    }\n}\n</code></pre>"},{"location":"utilities/ttsscript/#see-also","title":"See Also","text":"<ul> <li>TTS Script Authoring Guide - Detailed authoring guide</li> <li>LMS/Udemy Courses - Using ttsscript for courses</li> </ul>"},{"location":"utilities/voices/","title":"Voice Reference","text":"<p>The <code>voices</code> package provides reference information for ElevenLabs pre-made voices.</p>"},{"location":"utilities/voices/#installation","title":"Installation","text":"<pre><code>import \"github.com/agentplexus/go-elevenlabs/voices\"\n</code></pre>"},{"location":"utilities/voices/#quick-start","title":"Quick Start","text":""},{"location":"utilities/voices/#use-voice-constants","title":"Use Voice Constants","text":"<pre><code>import \"github.com/agentplexus/go-elevenlabs/voices\"\n\n// Use constants instead of hard-coded IDs\naudio, err := client.TextToSpeech().Simple(ctx, voices.Rachel, \"Hello world\")\n\n// Other popular voices\naudio, err := client.TextToSpeech().Simple(ctx, voices.Adam, \"Deep male voice\")\naudio, err := client.TextToSpeech().Simple(ctx, voices.George, \"British accent\")\n</code></pre>"},{"location":"utilities/voices/#look-up-voice-metadata","title":"Look Up Voice Metadata","text":"<pre><code>// Get voice by ID\nv := voices.GetVoice(voices.Rachel)\nfmt.Printf(\"Name: %s\\n\", v.Name)           // \"Rachel\"\nfmt.Printf(\"Gender: %s\\n\", v.Gender)       // \"female\"\nfmt.Printf(\"Accent: %s\\n\", v.Accent)       // \"American\"\nfmt.Printf(\"Use Case: %s\\n\", v.UseCase)    // \"Narration, audiobooks\"\n\n// Get voice by name (case-insensitive)\nv := voices.GetVoiceByName(\"rachel\")\n</code></pre>"},{"location":"utilities/voices/#filter-voices","title":"Filter Voices","text":"<pre><code>// Find female voices\nfemales := voices.FilterByGender(\"female\")\n\n// Find British voices\nbritish := voices.FilterByAccent(\"British\")\n\n// Find young voices\nyoung := voices.FilterByAge(\"young\")\n</code></pre>"},{"location":"utilities/voices/#pre-made-voice-constants","title":"Pre-made Voice Constants","text":""},{"location":"utilities/voices/#female-voices","title":"Female Voices","text":"Constant Name Description Accent Age <code>Rachel</code> Rachel Calm and composed American Young <code>Domi</code> Domi Strong and confident American Young <code>Bella</code> Bella Soft and warm American Young <code>Elli</code> Elli Emotional and expressive American Young <code>Nicole</code> Nicole Soft and whispery American Young <code>Emily</code> Emily Calm and professional American Young <code>Freya</code> Freya Expressive and clear American Young <code>Gigi</code> Gigi Childlike and playful American Young <code>Grace</code> Grace Southern and sweet American Southern Young <code>Dorothy</code> Dorothy Pleasant and refined British Young <code>Charlotte</code> Charlotte Seductive and sophisticated Swedish Middle-aged <code>Matilda</code> Matilda Warm and friendly American Middle-aged <code>Lily</code> Lily Raspy British British Middle-aged <code>Serena</code> Serena Pleasant and calm American Middle-aged <code>Glinda</code> Glinda Theatrical witch-like American Middle-aged"},{"location":"utilities/voices/#male-voices","title":"Male Voices","text":"Constant Name Description Accent Age <code>Antoni</code> Antoni Well-rounded and professional American Young <code>Josh</code> Josh Deep and authoritative American Young <code>Sam</code> Sam Raspy and casual American Young <code>Ethan</code> Ethan Energetic and youthful American Young <code>Jeremy</code> Jeremy Conversational and natural American Young <code>Harry</code> Harry Anxious energy American Young <code>Liam</code> Liam Articulate and clear American Young <code>Dave</code> Dave Conversational British-Essex British Young <code>Arnold</code> Arnold Crisp and confident American Middle-aged <code>Adam</code> Adam Deep and warm American Middle-aged <code>Brian</code> Brian Deep narrator quality American Middle-aged <code>Drew</code> Drew Well-rounded and versatile American Middle-aged <code>Paul</code> Paul Professional reporter style American Middle-aged <code>Chris</code> Chris Casual and relaxed American Middle-aged <code>Clyde</code> Clyde Gruff war veteran American Middle-aged <code>Callum</code> Callum Intense and dramatic Transatlantic Middle-aged <code>George</code> George Warm and refined British Middle-aged <code>Joseph</code> Joseph Authoritative British British Middle-aged <code>Michael</code> Michael Wise and grandfatherly American Old <code>Jessie</code> Jessie Raspy and weathered American Old <code>Fin</code> Fin Weathered Irish sailor Irish Old <code>James</code> James Warm Australian Australian Old"},{"location":"utilities/voices/#non-binary-voices","title":"Non-Binary Voices","text":"Constant Name Description Accent Age <code>River</code> River Modern and inclusive American Young"},{"location":"utilities/voices/#voice-type","title":"Voice Type","text":"<pre><code>type Voice struct {\n    ID          string // Unique voice identifier\n    Name        string // Display name\n    Description string // Voice characteristics\n    Gender      string // male, female, non-binary\n    Age         string // young, middle-aged, old\n    Accent      string // American, British, etc.\n    UseCase     string // Suggested use cases\n    Category    string // premade, cloned, designed\n}\n</code></pre>"},{"location":"utilities/voices/#functions","title":"Functions","text":""},{"location":"utilities/voices/#get-all-voices","title":"Get All Voices","text":"<pre><code>allVoices := voices.PremadeVoices()\nfor _, v := range allVoices {\n    fmt.Printf(\"%s (%s): %s\\n\", v.Name, v.ID, v.Description)\n}\n</code></pre>"},{"location":"utilities/voices/#look-up-by-id","title":"Look Up by ID","text":"<pre><code>v := voices.GetVoice(\"21m00Tcm4TlvDq8ikWAM\")\nif v != nil {\n    fmt.Printf(\"Found: %s\\n\", v.Name)\n}\n</code></pre>"},{"location":"utilities/voices/#look-up-by-name","title":"Look Up by Name","text":"<pre><code>v := voices.GetVoiceByName(\"Rachel\") // Case-insensitive\nv := voices.GetVoiceByName(\"rachel\") // Also works\n</code></pre>"},{"location":"utilities/voices/#filter-by-attribute","title":"Filter by Attribute","text":"<pre><code>// By gender\nfemales := voices.FilterByGender(\"female\")\nmales := voices.FilterByGender(\"male\")\n\n// By accent (partial match)\nbritish := voices.FilterByAccent(\"British\")\namerican := voices.FilterByAccent(\"American\")\n\n// By age\nyoung := voices.FilterByAge(\"young\")\nmiddleAged := voices.FilterByAge(\"middle-aged\")\nold := voices.FilterByAge(\"old\")\n</code></pre>"},{"location":"utilities/voices/#use-case-recommendations","title":"Use Case Recommendations","text":""},{"location":"utilities/voices/#narration-audiobooks","title":"Narration &amp; Audiobooks","text":"<ul> <li>Rachel - Calm, young female</li> <li>Adam - Deep, warm male</li> <li>Brian - Deep narrator quality</li> <li>George - Refined British male</li> </ul>"},{"location":"utilities/voices/#business-education","title":"Business &amp; Education","text":"<ul> <li>Antoni - Professional, warm</li> <li>Matilda - Friendly, approachable</li> <li>Emily - Professional female</li> <li>Liam - Articulate, clear</li> </ul>"},{"location":"utilities/voices/#podcasts-casual-content","title":"Podcasts &amp; Casual Content","text":"<ul> <li>Bella - Warm and friendly</li> <li>Jeremy - Conversational</li> <li>Sam - Casual, raspy</li> <li>Dave - British conversational</li> </ul>"},{"location":"utilities/voices/#character-voices-gaming","title":"Character Voices &amp; Gaming","text":"<ul> <li>Clyde - Gruff war veteran</li> <li>Glinda - Theatrical witch</li> <li>Fin - Irish sailor</li> <li>Harry - Anxious character</li> </ul>"},{"location":"utilities/voices/#documentaries-news","title":"Documentaries &amp; News","text":"<ul> <li>Josh - Authoritative</li> <li>Joseph - British authority</li> <li>Paul - Reporter style</li> <li>Callum - Dramatic narration</li> </ul>"},{"location":"utilities/voices/#integration-with-ttsscript","title":"Integration with ttsscript","text":"<pre><code>import (\n    \"github.com/agentplexus/go-elevenlabs/ttsscript\"\n    \"github.com/agentplexus/go-elevenlabs/voices\"\n)\n\nscript := &amp;ttsscript.Script{\n    DefaultVoices: map[string]string{\n        \"en\": voices.Rachel,\n        \"es\": voices.Bella,\n    },\n    // ...\n}\n</code></pre>"},{"location":"utilities/voices/#json-reference","title":"JSON Reference","text":"<p>The package includes a <code>voices.json</code> file with the same data for use in other tools:</p> <pre><code>{\n  \"voices\": [\n    {\n      \"id\": \"21m00Tcm4TlvDq8ikWAM\",\n      \"name\": \"Rachel\",\n      \"description\": \"Calm and composed\",\n      \"gender\": \"female\",\n      \"age\": \"young\",\n      \"accent\": \"American\",\n      \"use_case\": \"Narration, audiobooks\"\n    }\n  ]\n}\n</code></pre>"},{"location":"utilities/voices/#note","title":"Note","text":"<p>Voice IDs and availability may change over time. For the authoritative list of voices available to your account, use:</p> <pre><code>voices, err := client.Voices().List(ctx)\n</code></pre> <p>The constants in this package are based on commonly available pre-made voices and are provided for convenience.</p>"}]}